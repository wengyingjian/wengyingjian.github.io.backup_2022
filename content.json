[{"title":"IDEA 2016 最新版 激活 破解","date":"2016-11-28T10:23:12.000Z","path":"2016/11/28/idea-license/","text":"文Activate new license with选择 License server 地址填入: 1http://idea.eatbaidu.xyz 点击Activate即可 图 ————翁英健 本文地址：http://wengyingjian.github.io/2016/11/28/idea-license/ -End-","tags":[{"name":"idea","slug":"idea","permalink":"http://yoursite.com/tags/idea/"}]},{"title":"Nginx－虚拟主机、反向代理、负载均衡","date":"2016-03-09T16:37:53.000Z","path":"2016/03/10/nginx-usage-list/","text":"假定nginx已经安装完了，并且正常运行。 虚拟主机需求现在我的Nginx是作为Gitlab服务器在使用:http://gitlab.wengyingjian.com/，我希望在不影响Gitlab正常使用的情况下添加一个文件下载站的功能。 即访问http://download.wengyingjian.com/找到的还是这台Nginx服务器，但且此时提供的功能是文件下载而非Gitlab。 解决方法添加一条server的配置，为server_name是download.wengyingjian.com的请求分配对应的处理方案。 配置server配置文件新建vhosts文件夹（以后的虚拟主机都存放到此处），添加download模块的配置文件 123mkdir /etc/nginx/vhostscd /etc/nginx/vhostsvim download.wengyingjian.com #文件名随意，此处命名纯粹为了可读性。此文件即server配置文件 download.wengyingjian.com文件中加入如下内容： 12345678server &#123; listen 80; #同样监听80端口 server_name download.wengyingjian.com; #此处指定server_name，对于请求会进来 location / &#123; #对于download的请求，会去找到/usr/share/nginx/download.wengyingjian.com/文件目录 root /usr/share/nginx/download.wengyingjian.com; &#125;&#125; root处理目录新建root目录，添加下载资源 1234mkdir -p /usr/share/nginx/download.wengyingjian.comcd /usr/share/nginx/download.wengyingjian.com#在根目录放置index.html用于测试是否成功cat &quot;aa&quot; &gt; index.html nginx.conf中添加配置1vim /etc/nginx/nginx.conf 在http配置}结束前加入include /etc/nginx/vhosts/* 设置置域名解析，指向nginx所在服务器反向代理负载均衡配置先来4个虚拟主机 1234567891011121314151617181920server&#123; listen 10001; server_name 127.0.0.1; root /data/www/test/t1;&#125;server&#123; listen 10002; server_name 127.0.0.1; root /data/www/test/t2;&#125;server&#123; listen 10003; server_name 127.0.0.1; root /data/www/test/t3;&#125;server&#123; listen 10004; server_name 127.0.0.1; root /data/www/test/t4;&#125; 在4个虚拟主机的root目录放好index.html文件，并且写上不同的内容，方便区分。 12345678mkdir -p /data/www/test/t1mkdir -p /data/www/test/t2mkdir -p /data/www/test/t3mkdir -p /data/www/test/t4echo &quot;1111&quot; &gt; /data/www/test/t1/index.htmlecho &quot;2222&quot; &gt; /data/www/test/t2/index.htmlecho &quot;3333&quot; &gt; /data/www/test/t3/index.htmlecho &quot;4444&quot; &gt; /data/www/test/t4/index.html 负载均衡 1234567891011121314upstream test.load_balance &#123; server 127.0.0.1:10001; server 127.0.0.1:10002; server 127.0.0.1:10003; server 127.0.0.1:10004;&#125;server&#123; server_name 120.27.97.242; root /data/www/test/loadbalance; location / &#123; proxy_pass http://test.load_balance; &#125;&#125; 访问测试http://120.27.97.242 负载均衡的分配策略。。。 ————翁英健 本文地址：http://wengyingjian.github.io/2016/03/10/nginx-usage-list/ -End-","tags":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"},{"name":"服务器","slug":"服务器","permalink":"http://yoursite.com/tags/服务器/"},{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/tags/nginx/"}]},{"title":"微信公众号开发","date":"2016-02-20T13:23:56.000Z","path":"2016/02/20/wechat-develop/","text":"最近在搞微信公众（个人订阅）号。虽然功能有限，但是与以往的项目有些不一样，所以决定纪录一下。 说明环境需求：一台公网能够访问的服务器、后台开发能力 后台用的是springboot项目加上自己的kylin依赖以及kylin-archetype脚手架，整个项目搭建起来用了2秒钟左右。。 项目地址：http://github.com/wengyingjian/weixin/ 签名验证在启用开发者模式之前需要先进行token校验，如果校验不通过则不让开启。 但是在第一次开启了以后，再次开启不用验证。 配置Url首先是url，必须以http://或https://开头，分别支持80端口和443端口。那就需要Tomcat配置端口号为80，或者是使用Nginx代理。 Token就是一个校验的符号，这里填啥到时候服务器端逻辑处理的时候能够对上即可。 密钥怕麻烦，所以直接用明文了。 验证 填写完信息以后，微信会发送一个get请求到指定的url，带有一些参数，只有当正确返回的时候校验才算通过。 Controller代码： 123456789101112131415161718/** * 微信校验 * * @param signature * @param timestamp * @param nonce * @param echostr * @return */@RequestMapping(name = &quot;call_back&quot;, method = RequestMethod.GET)public String checkSignature(String signature,//微信加密签名，signature结合了开发者填写的token参数和请求中的timestamp参数、nonce参数。 String timestamp,//时间戳 String nonce,//随机数 String echostr) &#123;//随机字符串 logger.info(&quot;checkSignature at &#123;&#125;&quot;, timestamp); return signatureService.doCheckSignature(signature, timestamp, nonce, echostr) ? echostr : &quot;&quot;;&#125; Service代码： 12345678910111213141516171819202122232425262728/** * 开发者通过检验signature对请求进行校验（下面有校验方式）。若确认此次GET请求来自微信服务器，请原样返回echostr参数内容，则接入生效，成为开发者成功，否则接入失败。 * &lt;p&gt; * 加密/校验流程如下： * 1. 将token、timestamp、nonce三个参数进行字典序排序 * 2. 将三个参数字符串拼接成一个字符串进行sha1加密 * 3. 开发者获得加密后的字符串可与signature对比，标识该请求来源于微信 * * @param signature * @param timestamp * @param nonce * @param echostr * @return */public boolean doCheckSignature(String signature, String timestamp, String nonce, String echostr) &#123; String[] strs = &#123;TOKEN, timestamp, nonce&#125;; Arrays.sort(strs); String newStr = strs[0] + strs[1] + strs[2]; String sha1 = EncryptUtil.SHA1(newStr); if (sha1.equals(signature)) &#123; logger.info(&quot;check signature success !&quot;); return true; &#125; logger.info(&quot;check signature failed !&quot;); return false;&#125; 接收并回复文本信息接收消息自己开发应用的时候，一般都是一个业务逻辑对应一个controller方法。但是微信这个不同，我们需要并且只能填写一个url供微信回调，所以所有的业务都是往这个Controller里面走的。 签名校验走的是Get请求，其它消息走的是Post请求。 所以Controller这么写的： 1234567891011/** * 接收(并回复)消息 * * @param request * @return */@RequestMapping(name = &quot;call_back&quot;, method = RequestMethod.POST)public String receiveMessage(HttpServletRequest request) &#123; ...&#125; 从Post请求中获取到消息这个请求是不带参数的，所以需要从request的inputStream中去读。 123456789101112131415public String read(HttpServletRequest request) &#123; BufferedReader in = null; StringBuffer buffer = new StringBuffer(); try &#123; in = new BufferedReader(new InputStreamReader(request.getInputStream())); String line = null; while ((line = in.readLine()) != null) &#123; buffer.append(line); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); logger.error(&quot;request post message parse error:&#123;&#125;&quot;, e.getMessage()); &#125; return buffer.toString(); &#125; 将获取到的消息进行解析微信发送过来的消息是XML格式的，而且对于不同的消息类型，格式有所都是不一样的。 比如文本消息，格式如下： 12345678&lt;xml&gt; &lt;ToUserName&gt;&lt;![CDATA[toUser]]&gt;&lt;/ToUserName&gt; &lt;FromUserName&gt;&lt;![CDATA[fromUser]]&gt;&lt;/FromUserName&gt; &lt;CreateTime&gt;1348831860&lt;/CreateTime&gt; &lt;MsgType&gt;&lt;![CDATA[text]]&gt;&lt;/MsgType&gt; &lt;Content&gt;&lt;![CDATA[this is a test]]&gt;&lt;/Content&gt; &lt;MsgId&gt;1234567890123456&lt;/MsgId&gt; &lt;/xml&gt; 为了确定是文本消息，可以取MsgType为text的。 获取MsgType标签内容我这里用的是Xpath，将Xml内容转化为Java对象用的是Xstream。 对消息进行回复准备好需要回复的内容，然后转化成Xml格式即可。这里还是先init出一个Java对象，然后利用XStream转化为Xml文本。 ————翁英健 本文地址：http://wengyingjian.github.io/2016/02/20/wechat-develop/ -End-","tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"}]},{"title":"Centos7 Gitlab 环境搭建","date":"2016-02-08T10:31:48.000Z","path":"2016/02/08/server-gitlab-init/","text":"配置ssh免密码登录（新买的服务器）一直输密码麻烦。 客户机12ssh-keygen -t rsa #生成公钥scp ~/.ssh/id_rsa.pub root@host:. #公钥拷贝至服务器 服务器12mkdir ~/.sshcat ~/id_rsa.pub &gt; ~/.ssh/authorized_keys yum源设置为了提高安装速度，设置为阿里云开源镜像 1wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo 必要软件包1yum -y install libicu-devel patch gcc-c++ readline-devel zlib-devel libffi-devel openssl-devel make autoconf automake libtool bison libxml2-devel libxslt-devel libyaml-devel zlib-devel openssl-devel cpio expat-devel gettext-devel curl-devel perl-ExtUtils-CBuilder perl-ExtUtils-MakeMaker Git检查版本1git --version 升级小于1.7.10则升级 卸载1yum remove git 安装1234567mkdir -p /tmp/soft/git &amp;&amp; cd /tmp/soft/gitwget -O git-src.zip https://github.com/git/git/archive/master.zipunzip git-src.zipcd git-srcmake prefix=/usr/local allmake prefix=/usr/local installln -fs /usr/local/bin/git* /usr/bin/ Ruby下载安装：12345mkdir -p /tmp/soft/ruby &amp;&amp; cd /tmp/soft/rubycurl --progress ftp://ftp.ruby-lang.org/pub/ruby/ruby-2.1.5.tar.gz | tar xzcd ruby-2.1.5./configure --disable-install-rdocmake &amp;&amp; make install 配置：1234567ln -s /usr/local/bin/ruby /usr/bin/rubyln -s /usr/local/bin/gem /usr/bin/gemln -s /usr/local/bin/bundle /usr/bin/bundlegem source -r https://rubygems.org/ #设置ruby gem源为淘宝gem source -a https://ruby.taobao.org/gem install bundler --no-ri --no-rdoc Mysql安装1.检查mariadb包 1rpm -qa | grep mariadb 2.卸载mariadb 1rpm -e --nodeps mariadb-* 3.安装mysql 12345678mkdir -p /tmp/soft/mysql &amp;&amp; cd /tmp/soft/mysqlwget http://dev.mysql.com/get/Downloads/MySQL-5.6/MySQL-5.6.21-1.el7.x86_64.rpm-bundle.tartar -xvf MySQL-5.6.21-1.el7.x86_64.rpm-bundle.tarrpm -ivh MySQL-server-5.6.21-1.el7.x86_64.rpm #password&gt; cat /root/.mysql_secretrpm -ivh MySQL-shared-5.6.21-1.el7.x86_64.rpmrpm -ivh MySQL-client-5.6.21-1.el7.x86_64.rpmrpm -ivh MySQL-devel-5.6.21-1.el7.x86_64.rpm 4.启动 1service mysql start 5.修改root密码 1mysql&gt; set password = PASSWORD(&apos;root&apos;); 创建数据库123mysql&gt; CREATE USER &apos;gitlab&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;gitlab&apos;;mysql&gt; CREATE DATABASE IF NOT EXISTS `gitlabhq_production` DEFAULT CHARACTER SET `utf8` COLLATE `utf8_unicode_ci`;mysql&gt; GRANT SELECT, INSERT, UPDATE, DELETE, CREATE, DROP, INDEX, ALTER ON `gitlabhq_production`.* TO &apos;gitlab&apos;@&apos;localhost&apos;; Redis安装 1yum -y install redis 设置后台开启 123vim /etc/redis.conf#修改以下daemonize yes 启动 12#/etc/init.d/redis startredis-server /etc/redis.conf 添加用户git添加用户+sudo12useradd --comment &apos;GitLab&apos; gitecho &quot;git ALL=(ALL) NOPASSWD: ALL&quot; &gt;&gt;/etc/sudoers sudo添加/usr/local/bin123visudo #修改以下文件内容Defaults secure_path = /sbin:/bin:/usr/sbin:/usr/bin:/usr/local/bin Gitlab安装 1234cd /home/gitsudo -u git -H git clone https://gitlab.com/gitlab-org/gitlab-ce.git -b 7-8-stable gitlabcd /home/git/gitlabsudo -u git -H cp config/gitlab.yml.example config/gitlab.yml 编辑git路径, gitlab的host:port 123456$ vim config/gitlab.yml// bin_path: /usr/local/bin/git// host: localhost// port: 80 //email_from :_your_email_ #与git config一致 // 给文件夹添加相应的权限 1234$ chown -R git log/$ chown -R git tmp/$ chmod -R u+rwx log/$ chmod -R u+rwx tmp/ // 创建必要的文件夹，以及复制配置文件 12345678910$ sudo -u git -H mkdir /home/git/gitlab-satellites$ sudo chmod u+rwx,g=rx,o-rwx /home/git/gitlab-satellites$ sudo -u git -H mkdir tmp/pids/$ sudo -u git -H mkdir tmp/sockets/$ sudo -u git -H mkdir public/uploads$ sudo chmod -R u+rwX tmp/pids/$ sudo chmod -R u+rwX tmp/sockets/$ sudo chmod -R u+rwX public/uploads$ sudo -u git -H cp config/unicorn.rb.example config/unicorn.rb$ sudo -u git -H cp config/initializers/rack_attack.rb.example config/initializers/rack_attack.rb // 配置数据库连接信息 123456$ sudo -u git cp config/database.yml.mysql config/database.yml$ sudo -u git -H vim config/database.yml$ vim config/database.yml// production:// username: gitlab// password: &quot;gitlab&quot; GitLab-Shell1234cd /home/gitsudo -u git -H git clone https://gitlab.com/gitlab-org/gitlab-shell.git -b v2.6.0cd gitlab-shell/sudo -u git -H cp config.yml.example config.yml // 编辑配置文件, 设置gitlab_url, redis-cli, log-level… 123vim config.yml// gitlab_url: &quot;http://localhost/&quot;// /usr/bin/redis-cli #指定redis的redis-cli 目录 // 安装git-shell 1sudo -u git -H ./bin/install 安装需要ruby的gems12345678910111213141516171819202122232425262728293031323334353637383940$ cd /home/git/gitlab# 先修改当前目录下的 Gemfile 文件$ vim Gemfile source &apos;https://ruby.taobao.org/&apos; #将源指向到淘宝的源 # 不修改源是不能执行成功的。$ sudo -u git -H bundle install --deployment --without development test postgres aws如果上边命令出现如下错误：Gem::Ext::BuildError: ERROR: Failed to build gem native extension. /usr/local/bin/ruby extconf.rbchecking for cmake... noERROR: CMake is required to build Rugged.*** extconf.rb failed ***Could not create Makefile due to some reason, probably lack of necessarylibraries and/or headers. Check the mkmf.log file for more details. You mayneed configuration options.Provided configuration options: --with-opt-dir --without-opt-dir --with-opt-include --without-opt-include=$&#123;opt-dir&#125;/include --with-opt-lib --without-opt-lib=$&#123;opt-dir&#125;/lib --with-make-prog --without-make-prog --srcdir=. --curdir --ruby=/usr/local/bin/rubyextconf failed, exit code 1Gem files will remain installed in /home/git/gitlab/vendor/bundle/ruby/2.1.0/gems/rugged-0.21.2 for inspection.Results logged to /home/git/gitlab/vendor/bundle/ruby/2.1.0/extensions/x86_64-linux/2.1.0-static/rugged-0.21.2/gem_make.outAn error occurred while installing rugged (0.21.2), and Bundler cannot continue.Make sure that `gem install rugged -v &apos;0.21.2&apos;` succeeds before bundling.有以上错误时：执行命令：$ yum install -y cmake 初始化数据库(创建GitLab相关表) 1$ sudo -u git -H bundle exec rake gitlab:setup RAILS_ENV=production 安装启动文件以及日志切割文件123cp lib/support/init.d/gitlab /etc/init.d/gitlabcp lib/support/init.d/gitlab.default.example /etc/default/gitlabcp lib/support/logrotate/gitlab /etc/logrotate.d/gitlab 设置git帐号信息–全局用户和邮件1234$ sudo -u git -H git config --global user.name &quot;GitLab&quot;##### email与config/gitlab.yml中的一致$ sudo -u git -H git config --global user.email &quot;example@example.com&quot; $ sudo -u git -H git config --global core.autocrlf input 安装Nginx安装1yum -y install nginx 配置1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253$ vim /etc/nginx/nginx.confuser root git;worker_processes 2;pid /var/run/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include /etc/nginx/mime.types; default_type application/octet-stream; log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos;&apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos;&apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;;# GITLAB# Maintainer: @randx# App Version: 5.0upstream gitlab &#123; server unix:/home/git/gitlab/tmp/sockets/gitlab.socket;&#125;server &#123; listen *:80 default_server; # e.g., listen 192.168.1.1:80; In most cases *:80 is a good idea server_name YOUR_SERVER_FQDN; # e.g., server_name source.example.com; server_tokens off; # don&apos;t show the version number, a security best practice root /home/git/gitlab/public; # Set value of client_max_body_size to at least the value of git.max_size in gitlab.yml client_max_body_size 5m; # individual nginx logs for this gitlab vhost access_log /var/log/nginx/gitlab_access.log; #必须有/var/log/nginx/ error_log /var/log/nginx/gitlab_error.log; #必须有/var/log/nginx/ location / &#123; # serve static files from defined root folder;.# @gitlab is a named location for the upstream fallback, see below try_files $uri$uri/index.html $uri.html @gitlab; &#125; # if a file, which is not found in the root folder is requested,# then the proxy pass the request to the upsteam (gitlab unicorn) location @gitlab &#123; proxy_read_timeout 300; # https://github.com/gitlabhq/gitlabhq/issues/694 proxy_connect_timeout 300; # https://github.com/gitlabhq/gitlabhq/issues/694 proxy_redirect off; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://localhost:8080; &#125;&#125;&#125; 更改权限，启动nginx123$ nginx -t #检查配置文件是否正常$ chown -R git:git /var/log/nginx/ #文件文件目录权限$ nginx 启动Gitlab下载服务脚本1234$ wget -O /etc/init.d/gitlab https://gitlab.com/gitlab-org/gitlab-recipes/raw/master/init/sysvinit/centos/gitlab-unicorn$ chmod +x /etc/init.d/gitlab$ chkconfig --add gitlab$ chkconfig gitlab on 检测当前环境12$ cd /home/git/gitlab$ sudo -u git -H bundle exec rake gitlab:env:info RAILS_ENV=production 拉取gitlab静态资源文件1$ sudo -u git -H bundle exec rake assets:precompile RAILS_ENV=production 启动gitlab1$ /etc/init.d/gitlab start 检测各个组件是否正常工作1$ sudo -u git -H bundle exec rake gitlab:check RAILS_ENV=production 登录Gitlab用户名：root密码：5iveL!fe ————翁英健 本文地址：http://wengyingjian.github.io/2016/02/08/server-gitlab-init/ -End-","tags":[{"name":"服务器","slug":"服务器","permalink":"http://yoursite.com/tags/服务器/"}]},{"title":"Spring源码（一）－读取xml配置","date":"2016-02-06T07:33:55.000Z","path":"2016/02/06/spring-source-load-xml/","text":"分析以下代码： 1BeanFactory beanFactory = new XmlBeanFactory(new ClassPathResource(&quot;beanFactoryTest.xml&quot;)); 预知 封装配置文件 加载、解析配置文件 注册beanDefinition 封装配置文件贴代码1new ClassPathResource(&quot;beanFactoryTest.xml&quot;) Resource接口说明Resource接口封装了一些资源文件的信息。 通过提供的方法就能够知道到这个接口的作用。 代码解析此处用的是ClassPathResource类，Resource接口的实现类。 构造方法如下： 123456789public ClassPathResource(String path, ClassLoader classLoader) &#123; Assert.notNull(path, &quot;Path must not be null&quot;); String pathToUse = StringUtils.cleanPath(path); if (pathToUse.startsWith(&quot;/&quot;)) &#123; pathToUse = pathToUse.substring(1); &#125; this.path = pathToUse; this.classLoader = (classLoader != null ? classLoader : ClassUtils.getDefaultClassLoader()); &#125; 总之，就是将资源文件封装成了一个ClassPathResource对象。 加载配置文件:XmlBeanDefinitionReader加载beanDefinition123456789101112131415161718192021222324252627282930313233343536public int loadBeanDefinitions(EncodedResource encodedResource) throws BeanDefinitionStoreException &#123; ... //Set&lt;EncodedResource&gt;存在于当前类的threadLocal之中 Set&lt;EncodedResource&gt; currentResources = this.resourcesCurrentlyBeingLoaded.get(); if (currentResources == null) &#123; currentResources = new HashSet&lt;EncodedResource&gt;(4); this.resourcesCurrentlyBeingLoaded.set(currentResources); &#125; if (!currentResources.add(encodedResource)) &#123; throw new BeanDefinitionStoreException( &quot;Detected cyclic loading of &quot; + encodedResource + &quot; - check your import definitions!&quot;); &#125; try &#123; //读取resource的inputstream InputStream inputStream = encodedResource.getResource().getInputStream(); try &#123; //org.xml.sax.InputSource InputSource inputSource = new InputSource(inputStream); if (encodedResource.getEncoding() != null) &#123; inputSource.setEncoding(encodedResource.getEncoding()); &#125; //读取实现方法 //TODO return doLoadBeanDefinitions(inputSource, encodedResource.getResource()); &#125; finally &#123; ... &#125; &#125; catch (IOException ex) &#123; ... &#125; finally &#123; ... &#125; &#125; 将encodedResource放入到threadLocal之中 将资源再次转换，变成inputSource对象，把最终的解析工作委托给doLoadBeanDefinitions 123456789protected int doLoadBeanDefinitions(InputSource inputSource, Resource resource) throws BeanDefinitionStoreException &#123; try &#123; //加载XML文件，并得到对应的Document(获取对XMl文件的验证模式) //最终通过DefaultDocumentLoader的loadDocument方法实现 Document doc = doLoadDocument(inputSource, resource); //根据返回Document注册Bean信息//TODO return registerBeanDefinitions(doc, resource); &#125;... 对资源再一次封装，变成Document对象 注册BeanDefinition 注册beanDefinition12345678910111213public int registerBeanDefinitions(Document doc, Resource resource) throws BeanDefinitionStoreException &#123; //1.实例化BeanDefinitionDocumentReader，使用DefaultBeanDefinitionDocumentReader BeanDefinitionDocumentReader BeanDefinitionDocumentReader documentReader = createBeanDefinitionDocumentReader(); //2.记录注册bean的数量 int countBefore = getRegistry().getBeanDefinitionCount(); //3.注册bean documentReader.registerBeanDefinitions(doc, createReaderContext(resource)); //4.计算此次注册了多少个新的bean，并返回 return getRegistry().getBeanDefinitionCount() - countBefore; &#125; 注册bean的过程委托给了DefaultBeanDefinitionDocumentReader.registerBeanDefinitions()实现。 注册BeanDefinition:DefaultBeanDefinitionDocumentReader默认标签与自定义标签省去中间的一些判断以及预留的接口，最最后来到主要的实现： 123456789101112131415161718192021222324252627282930313233protected void parseBeanDefinitions(Element root, BeanDefinitionParserDelegate delegate) &#123; //对beans的处理 //1.对默认的bean声明进行读取和解析 //&lt;bean id= &quot;test&quot; class=&quot;test.TestBean&quot;/&gt; //delegate.isDefaultNamespace(root) --&gt; //--&gt; node.getNamespaceURI与固定命名空间&quot;http://www.springframework.org/schema/beans&quot;对比 //--&gt; 一致＝默认 --&gt; true if (delegate.isDefaultNamespace(root)) &#123; NodeList nl = root.getChildNodes(); for (int i = 0; i &lt; nl.getLength(); i++) &#123; Node node = nl.item(i); if (node instanceof Element) &#123; Element ele = (Element) node; if (delegate.isDefaultNamespace(ele)) &#123; //3.默认标签的解析 //对bean的处理//TODO parseDefaultElement(ele, delegate); &#125; else &#123; //4.自定义标签的解析 //对bean的处理 delegate.parseCustomElement(ele); &#125; &#125; &#125; &#125; //2.对自定义的beans进行解析 //&lt;tx:annotation-driven/&gt; else &#123; delegate.parseCustomElement(root); &#125; &#125; 默认标签的解析这里继续深入默认标签的解析： 123456789101112131415161718192021222324private void parseDefaultElement(Element ele, BeanDefinitionParserDelegate delegate) &#123; //&quot;import&quot; if (delegate.nodeNameEquals(ele, IMPORT_ELEMENT)) &#123; //TODO:3.3 importBeanDefinitionResource(ele); &#125; //&quot;alias&quot; else if (delegate.nodeNameEquals(ele, ALIAS_ELEMENT)) &#123; //TODO:3.2 processAliasRegistration(ele); &#125; //&quot;bean&quot; else if (delegate.nodeNameEquals(ele, BEAN_ELEMENT)) &#123; //TODO:3.1 processBeanDefinition(ele, delegate); &#125; //&quot;beans&quot; else if (delegate.nodeNameEquals(ele, NESTED_BEANS_ELEMENT)) &#123; // recurse //TODO:3.4：与单独的配置文件并没有太大的差别，无非是递归调用beans的解析过程。 doRegisterBeanDefinitions(ele); &#125; &#125; 选择bean的实现继续跟踪： 12345678910111213141516171819202122232425262728293031323334353637protected void processBeanDefinition(Element ele, BeanDefinitionParserDelegate delegate) &#123; //1.委托BeanDefinitionParserDelegate类的parseBeanDefinitionElement方法进行元素解析， //返回BeanDefinitionHolder类型的实例bdHolder, //经过这个方法后，bdHolder实例已经包含我们配置文件中配置的各种属性了，例如class,name,id,alias之类的属性//TODO BeanDefinitionHolder bdHolder = delegate.parseBeanDefinitionElement(ele); //2.当返回的bdHolder不为空(期间无error)的情况下 //若存在默认标签的子节点下再有自定义属性，还需要再次对自定义标签进行解析 if (bdHolder != null) &#123; /** * 在descorateBeanDefinitionIfRequired中看到默认的标签是直接略过的（因为已经解析过了）， * 这里只对 自定义的标签活着说对bean的自定义属性感兴趣。&lt;br/&gt; * 在方法中实现了寻找自定义标签并根据自定义标签寻找命名空间处理器，并进一步的解析。 */ //-3.1.3如果需要的话，对beanDefinition进行装饰，适用： // &lt;bean id=&quot;test&quot; class=&quot;test.MyClass&quot;&gt; // &lt;mybean:user username=&quot;aaa&quot;/&gt; // &lt;/bean&gt; //TODO bdHolder = delegate.decorateBeanDefinitionIfRequired(ele, bdHolder); try &#123; // Register the final decorated instance. //3.解析完成后，需要对解析后的bdHolder进行注册， //同样，注册操作委托给了BeanDefinitionReaderUtils的registerBeanDefinition方法。 //TODO BeanDefinitionReaderUtils.registerBeanDefinition(bdHolder, getReaderContext().getRegistry()); &#125; catch (BeanDefinitionStoreException ex) &#123; getReaderContext().error(&quot;Failed to register bean definition with name &apos;&quot; + bdHolder.getBeanName() + &quot;&apos;&quot;, ele, ex); &#125; // Send registration event. //4.最后发出响应事件，通知相关的监听器，这个bean已经加载完成了 //3.1.5通知监听器解析及注册完成. //这里的实现只为扩展，当程序开发人员需要对注册beanDefinition事件进行监听时可以通过注册监听器的方式并将处理逻辑写入监听器中，目前在Sping中并没有对此事件做任何逻辑处理。 getReaderContext().fireComponentRegistered(new BeanComponentDefinition(bdHolder)); &#125; &#125; 跟踪BeanDefinitionReaderUtils.registerBeanDefinition(bdHolder, getReaderContext().getRegistry()) BeanDefinitionReaderUtils123456789101112131415161718192021public static void registerBeanDefinition( BeanDefinitionHolder definitionHolder, BeanDefinitionRegistry registry) throws BeanDefinitionStoreException &#123; //使用beanName做唯一标识注册 // Register bean definition under primary name. String beanName = definitionHolder.getBeanName(); //1.通过beanName注册 //TODO-&gt;DefaultListableBeanFactory registry.registerBeanDefinition(beanName, definitionHolder.getBeanDefinition()); //注册所有的别名 // Register aliases for bean name, if any. String[] aliases = definitionHolder.getAliases(); if (aliases != null) &#123; for (String alias : aliases) &#123; //2.通过别名注册beanDefinition //TODO--&gt;SimpleAliasRegistry registry.registerAlias(beanName, alias); &#125; &#125; &#125; 解析的beanDefinition都会被注册到BeanDefnitionRegistry类型的实例registry中，而对于beanDefinition的注册分为了两部分：通过beanName的注册以及通过别名的注册。 继续：registry.registerBeanDefinition(beanName, definitionHolder.getBeanDefinition());–&gt;DefaultListableBeanFactory DefaultListableBeanDefinition 对AbstractBeanDefinition的校验。针对于MethodOverrides 对beanName已经注册的情况的处理。如果是指明为不可覆盖的，则抛异常 加入map缓存 清除解析之前列下的对应beanName的缓存 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980@Override public void registerBeanDefinition(String beanName, BeanDefinition beanDefinition) throws BeanDefinitionStoreException &#123; Assert.hasText(beanName, &quot;Bean name must not be empty&quot;); Assert.notNull(beanDefinition, &quot;BeanDefinition must not be null&quot;); if (beanDefinition instanceof AbstractBeanDefinition) &#123; try &#123; /** * 注册前的最后一次校验，这里的校验不同于前面的xml校验。&lt;br/&gt; * 主要是对于AbstractBeanDefinition属性中的methodOverrides校验&lt;br/&gt; * 校验methodOverrides是否与工厂方法并存或者methodOverrides对于的方法根本不存在 * */ ((AbstractBeanDefinition) beanDefinition).validate(); &#125; catch (BeanDefinitionValidationException ex) &#123; throw new BeanDefinitionStoreException(beanDefinition.getResourceDescription(), beanName, &quot;Validation of bean definition failed&quot;, ex); &#125; &#125; BeanDefinition oldBeanDefinition; oldBeanDefinition = this.beanDefinitionMap.get(beanName); //1.处理已经注册的beanName情况 if (oldBeanDefinition != null) &#123; //如果beanName已经被注册了而且在配置中设置了不可覆盖，则抛出异常 if (!isAllowBeanDefinitionOverriding()) &#123; throw new BeanDefinitionStoreException(beanDefinition.getResourceDescription(), beanName, &quot;Cannot register bean definition [&quot; + beanDefinition + &quot;] for bean &apos;&quot; + beanName + &quot;&apos;: There is already [&quot; + oldBeanDefinition + &quot;] bound.&quot;); &#125; //比较老/新bean的优先级，给出提示 else if (oldBeanDefinition.getRole() &lt; beanDefinition.getRole()) &#123; ... &#125; else if (!beanDefinition.equals(oldBeanDefinition)) &#123; ... &#125; else &#123; ... &#125; this.beanDefinitionMap.put(beanName, beanDefinition); &#125; //2.再处理未注册bean的情况 else &#123; //如果bean已经在构建中了 if (hasBeanCreationStarted()) &#123; // Cannot modify startup-time collection elements anymore (for stable iteration) synchronized (this.beanDefinitionMap) &#123; this.beanDefinitionMap.put(beanName, beanDefinition); List&lt;String&gt; updatedDefinitions = new ArrayList&lt;String&gt;(this.beanDefinitionNames.size() + 1); updatedDefinitions.addAll(this.beanDefinitionNames); updatedDefinitions.add(beanName); this.beanDefinitionNames = updatedDefinitions; if (this.manualSingletonNames.contains(beanName)) &#123; Set&lt;String&gt; updatedSingletons = new LinkedHashSet&lt;String&gt;(this.manualSingletonNames); updatedSingletons.remove(beanName); this.manualSingletonNames = updatedSingletons; &#125; &#125; &#125; else &#123; //注册beanDefinition // Still in startup registration phase this.beanDefinitionMap.put(beanName, beanDefinition); //记录beanName this.beanDefinitionNames.add(beanName); this.manualSingletonNames.remove(beanName); &#125; this.frozenBeanDefinitionNames = null; &#125; if (oldBeanDefinition != null || containsSingleton(beanName)) &#123; //重置所有beanName对应的缓存 resetBeanDefinition(beanName); &#125; &#125; this.beanDefinitionMap.put(beanName, beanDefinition) 这个是我们要的：将封装好的BeanDefinition对象与名字以键值对的形式保存到了DefaultListableBeanDefinition的beanDefinitionMap对象中。 一些类的说明 XmlBeanDefinitionReader:xml配置文件读取器，已废弃 BeanDefinition：封装了一系列信息，可以把它想象成是一个对象的各项属性获取器。 DefaultBeanDefinitionDocumentReader：document解析器，负责一些逻辑的判断与处理 BeanDefinitionParserDelegate:bean解析器，存放了各种标签的定义，专门用来解析spring xml配置，负责将Element对象转化为BeanDefinitionHolder ————翁英健 本文地址：http://wengyingjian.github.io/2016/02/06/spring-source-load-xml/ -End-","tags":[{"name":"spring","slug":"spring","permalink":"http://yoursite.com/tags/spring/"}]},{"title":"Maven Archetype编写（二）","date":"2016-02-04T08:32:25.000Z","path":"2016/02/04/maven-archetype-bugfix/","text":"项目地址https://github.com/wengyingjian/kylin-archetype.git 多模块聚合聚合的优势在公司里面用到的maven项目通常都是由common、api、service三个模块聚合而成的。common存放一些公用类以及接口。api存放controller层往下的类。service存放dao往上的类；打成jar包可作为依赖，打成war包可提供服务。 这样不管开发还是分层都比较方便。 所以用maven-archetype直接生成多个模块聚合的项目能够简便开发工作。 聚合Archetype的编写资源存放所有的资源都还是存放在src/main/resources/archetype-resources/目录下就像是这样： archetype-metadata.xml原先单个模块的项目，fileSet等属性是放在外面的；现在多个模块的项目，只需要把原先的配置移到modules里面即可。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&lt;archetype-descriptor name=&quot;$&#123;artifactId&#125;&quot;&gt; &lt;modules&gt; &lt;module id=&quot;$&#123;rootArtifactId&#125;-api&quot; dir=&quot;__rootArtifactId__-api&quot; name=&quot;$&#123;rootArtifactId&#125;-api&quot;&gt; &lt;fileSets&gt; &lt;fileSet filtered=&quot;true&quot; packaged=&quot;true&quot; encoding=&quot;UTF-8&quot;&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;/fileSet&gt; &lt;fileSet filtered=&quot;true&quot; encoding=&quot;UTF-8&quot;&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;/fileSet&gt; &lt;fileSet filtered=&quot;true&quot; packaged=&quot;true&quot; encoding=&quot;UTF-8&quot;&gt; &lt;directory&gt;src/test/java&lt;/directory&gt; &lt;/fileSet&gt; &lt;fileSet filtered=&quot;true&quot; encoding=&quot;UTF-8&quot;&gt; &lt;directory&gt;src/test/resources&lt;/directory&gt; &lt;/fileSet&gt; &lt;/fileSets&gt; &lt;/module&gt; &lt;module id=&quot;$&#123;rootArtifactId&#125;-common&quot; dir=&quot;__rootArtifactId__-common&quot; name=&quot;$&#123;rootArtifactId&#125;-common&quot;&gt; &lt;fileSets&gt; &lt;fileSet filtered=&quot;true&quot; packaged=&quot;true&quot; encoding=&quot;UTF-8&quot;&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;/fileSet&gt; &lt;/fileSets&gt; &lt;/module&gt; &lt;module id=&quot;$&#123;rootArtifactId&#125;-service&quot; dir=&quot;__rootArtifactId__-service&quot; name=&quot;$&#123;rootArtifactId&#125;-service&quot;&gt; &lt;fileSets&gt; &lt;fileSet filtered=&quot;true&quot; packaged=&quot;true&quot; encoding=&quot;UTF-8&quot;&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;/fileSet&gt; &lt;fileSet filtered=&quot;true&quot; encoding=&quot;UTF-8&quot;&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;*.properties&lt;/include&gt; &lt;include&gt;*.yml&lt;/include&gt; &lt;/includes&gt; &lt;/fileSet&gt; &lt;fileSet filtered=&quot;true&quot; packaged=&quot;true&quot; encoding=&quot;UTF-8&quot;&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;/fileSet&gt; &lt;fileSet filtered=&quot;true&quot; packaged=&quot;true&quot; encoding=&quot;UTF-8&quot;&gt; &lt;directory&gt;src/test/java&lt;/directory&gt; &lt;/fileSet&gt; &lt;fileSet filtered=&quot;true&quot; encoding=&quot;UTF-8&quot;&gt; &lt;directory&gt;src/test/resources&lt;/directory&gt; &lt;/fileSet&gt; &lt;/fileSets&gt; &lt;/module&gt; &lt;/modules&gt;&lt;/archetype-descriptor&gt; mapper.xml文件无法找到问题1org.apache.ibatis.binding.BindingException: Invalid bound statement (not found): 问题太纠结，直接上结论： 不知道看出来了没有：一个是resources/dao.mapper一个是resources/dao/mapper，在idea里面的显示竟然是一样的。所以mapper.xml无法找到的原因应该就明了了。 不怪谁，就怪idea，就是它！定位这个问题都花了我好几天的时间，隐藏的太深的问题了。 至于我怎么发现的，是通过target/classes下的文件发现的。正常能运行的：mapper.xml与mapper.class接口类打包在同一个目录下。出现上述问题的：mapper.xml所在的目录与mapper.class接口类所在的目录看上去一样（还得怪idea）。但是前者是classes/a.b.c.mapper.xml，后者是classes/a/b/c/mapper.class。 mapper.xml字符替换问题在mybatis配置文件中，必然会用到#{ }这种符号，但是这个符号在被过滤的时候会被吃掉。 解决方案：maven－archetyoe用的是Velocity引擎，在下面的地址有说明：http://maven.apache.org/archetype/archetype-models/archetype-descriptor/archetype-descriptor.html 所以通过查看Velocity语法即可知道如何使用里面的一些“关键字”。 比如说要输出id = #{ id }首先在文件的开头加入以下三行： 123#set( $pound = &apos;#&apos; )#set( $brace_b = &apos;&#123;&apos; )#set( $brace_e = &apos;&#125;&apos; ) 然后再在需要的地方添上id = $pound$brace_b id $brace_e archetype-metadata.xml&lt;fileSet filtered=&quot;true&quot; encoding=&quot;UTF-8&quot;&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;*.properties&lt;/include&gt; &lt;include&gt;*.yml&lt;/include&gt; &lt;/includes&gt; &lt;/fileSet&gt; &lt;fileSet filtered=&quot;true&quot; packaged=&quot;true&quot; encoding=&quot;UTF-8&quot;&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;/fileSet&gt; 解释：filtered:对应文件中涉及到的通配符字符串是否需要由Velocity来过滤解析。packaged:是否将对应的文件放置于包路径下，在例子中所有的*.xml文件会被放倒${package}路径下，原先resources/dao/mapper/A.xml的文件会变成resources/com/a/dao/mapper/A.xml ————翁英健 本文地址：http://wengyingjian.github.io/2016/02/04/maven-archetype-bugfix/ -End-","tags":[{"name":"maven","slug":"maven","permalink":"http://yoursite.com/tags/maven/"}]},{"title":"Maven Archetype编写（一）","date":"2016-01-31T13:08:35.000Z","path":"2016/01/31/maven-archetype-init/","text":"一、链接献上参考的一个指导：http://marosmars.weebly.com/blog/maven-archetype-tutorial官网－关于archetype-metadata.xml 配置文件的说明：http://maven.apache.org/archetype/archetype-models/archetype-descriptor/archetype-descriptor.html demo项目地址：http://github.com/wengyingjian/maven-archetype-kylin 二、开始搞1.创建项目新建一个普通的maven项目（手动搞比较靠谱）pom.xml文件里面就放一些必须的配置，像我的就这样写： 12345&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.wengyingjian.kylin&lt;/groupId&gt; &lt;artifactId&gt;kylin-archetype&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; 2.定义生成项目时的一些设置这些配置保存在archetype-metadata.xml文件中，位于src/main/resources/META-INF/maven/目录下。 主要通过fileSet以及requiredProperty对模板文件进行一个过滤，将其中一些字符进行替换。 1).fileSet123456789101112131415161718192021222324&lt;!--文件集定义--&gt; &lt;fileSets&gt; &lt;!--以&quot;__property__&quot;模式定义的变量会被对于的property值所替换--&gt; &lt;!--filtered boolean 默认false,表示保持文件原样不被替换--&gt; &lt;fileSet filtered=&quot;true&quot; packaged=&quot;false&quot; encoding=&quot;UTF-8&quot;&gt; &lt;!--文件所在(archetype-resources目录下)同时也是生成路径--&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.**&lt;/include&gt; &lt;/includes&gt; &lt;/fileSet&gt; &lt;fileSet filtered=&quot;true&quot; packaged=&quot;false&quot; encoding=&quot;UTF-8&quot;&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.**&lt;/include&gt; &lt;/includes&gt; &lt;/fileSet&gt; &lt;fileSet filtered=&quot;true&quot; packaged=&quot;false&quot; encoding=&quot;UTF-8&quot;&gt; &lt;directory&gt;src/test/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.**&lt;/include&gt; &lt;/includes&gt; &lt;/fileSet&gt; &lt;/fileSets&gt; 2).requiredProperty1234567&lt;!--利用此archetype生成项目必须的属性--&gt; &lt;requiredProperties&gt; &lt;!--由于是由Velocity引擎生成的,所以key不能带有&quot;.&quot;--&gt; &lt;requiredProperty key=&quot;groupId&quot;&gt; &lt;defaultValue&gt;com.wengyingjian&lt;/defaultValue&gt; &lt;/requiredProperty&gt; &lt;/requiredProperties&gt; 3).module下回用到了再将 3.定义模版文件也就是通过这个archetype，生成的项目是怎么样的。这些文件位于src/main/resources/archetype-resources/目录下。可以看到，文件的目录结构是这样的： 生成项目的根目录 == src/main/resources/archetype-resources/ 这里所有的文件，会通过archetype-metadata.xml的配置，进行过滤，对一些字符串进行替换。所以，pom.xml文件的写法就是这样的： 12345&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;$&#123;groupId&#125;&lt;/groupId&gt; &lt;artifactId&gt;$&#123;artifactId&#125;&lt;/artifactId&gt; &lt;version&gt;$&#123;version&#125;&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; 4.安装archetype1mvn install 5.使用archetype生成项目123456mvn archetype:generate \\-DarchetypeGroupId=com.wengyingjian.kylin \\-DarchetypeArtifactId=kylin-archetype \\-DarchetypeVersion=1.0-SNAPSHOT \\-DgroupId=&lt;your-groupId-here&gt; \\-DartifactId=&lt;your-artifactId-here&gt;\\ 三、一些问题项目生成的时候特别的慢： 在这个地方会卡很久： 其实它是去到中央仓库找catalog去了，那边的速度慢的，有些时候真的想哭，而且这个文件也蛮大，所以要点时间。比较好的解决方法就是我们把这个catalog下载下来，然后指定使用本地的这个，就像这样： 没错，下载了4分钟，如果不放到本地，每次新建项目需要等待这么久。 顺便贴下命令： 1wget http://repo1.maven.org/maven2/archetype-catalog.xml 将自己的archetype加入到此catalog中： 123456&lt;archetype&gt; &lt;groupId&gt;com.wengyingjian.kylin&lt;/groupId&gt; &lt;artifactId&gt;kylin-archetype&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;description&gt;Blank Project for kylin&lt;/description&gt; &lt;/archetype&gt; 将该文件移动到~/.m2/路径下，然后再执行命令的时候指定-DarchetypeCatalog=local即可。 对于IDEA编译器，只需要在maven命令中添加一个参数即可，就像这样： ————翁英健 本文地址：http://wengyingjian.github.io/2016/01/31/maven-archetype-init/ -End-","tags":[{"name":"maven","slug":"maven","permalink":"http://yoursite.com/tags/maven/"}]},{"title":"Maven Autoconf打包问题","date":"2016-01-23T13:13:55.000Z","path":"2016/01/23/maven-autoconf-fix/","text":"背景最近又把毕业设计的项目拿出来，重新做。 一来为了好对之前的项目“重构”，毕竟之前写的零零散散太乱了；二来也熟悉熟悉IDEA开发环境。 从Eclipse转向IDEA，maven项目可以一个里面套多个了，所以现在将毕业设计所需要的一些模块都放到了一起，就像是这样： 这里就需要自己新建项目。之前在公司写的项目大多是已经搭建好了的，难得有个从0到1的项目记得还是找的一个模板改改用的。 所以这次在autoconfig的时候就遇到了问题，而且搞了好几个小时才找到问题所在。 项目地址log4j2:https://github.com/wengyingjian/kylin/tree/1c649e2391ff02d31e9a531c285849f719e488ae demo-kyliy:https://github.com/wengyingjian/demo-kylin/tree/66000f28327acc259ed4ad20e8bcffc182a23563 问题说明再补充下背景项目要边写边测试，先来的是最简单的 log4j2模块：只负责打印，收集日志。对应的也只需要配置文件，而无任何的java代码。 既然要配置文件，这里就要用到autoconf。 问题出现将log4j2模块打包以后，用另外一个项目demo-kylin来使用。 在打包demo-kylin项目的时候直接跳过了自动配置，就像是这样： 都已经去找了配置文件，结果配置文件没找到，再一看，竟然没有东西需要配置。说明autoconf这个插件没有找到让它来自动配置的相关文件。 查找问题测试项目方面查找从测试项目demo-kylin方面来看。就是点开External Libraries这个依赖看看log4j2到底长成啥样了。一看吓一跳： 整个展开以后未看到autoconf相关的文件，如auto-conf.xml、*.vm。 那看来在log4j2这边就已经出了问题。 被依赖项目方面查找首先，展开log4j2项目来看，它也表示很“无辜”：该有的文件基本都有了啊： 然后再打包一次看看，日志的显示如下： 总之就是在表示它们都没看到*.xml、*.vm这2个文件。 问题分析那肯定是autoconf相关的文件放错位置了，导致程序找不到。想想也是没有找到问题所在。 特意去看了之前的开发环境：的确是放在src/main/webapp/META-INF/autoconf目录下的，也都可行。 也瞄了一眼http://openwebx.org/docs/autoconfig.html#d0e17306看似比较权威的说明，好像也没问题。 再看看网上的一些博客，都是说放到META-INF/autoconf目录下的。 问题解决google没有找到问题所在，只好回到baidu。没想到baidu更穷，提供的全是一些博客，甚至点去内容都是一样的。 看来还是老问题啊：犯了比较傻的错误，以致都没什么人犯过，所以网上都搜不到。 所以决定沉下气来再仔细看看那篇看似比较权威的文档：http://openwebx.org/docs/autoconfig.html#d0e17306 找到问题在上面那张图下面，就是这个： 恍然大悟，我的这个是jar包啊，哪来的webapp！之前项目是war项目，所以它们能够运行！ 解决问题给文件搬家即可 log4j2项目上看： 从依赖上看： 最后，在demo-kylin项目打包的时候，跳出如下提示： ————翁英健 本文地址：http://wengyingjian.github.io/2016/01/23/maven-autoconf-fix/ -End-","tags":[{"name":"maven","slug":"maven","permalink":"http://yoursite.com/tags/maven/"}]},{"title":"Docker是什么","date":"2016-01-19T00:15:13.000Z","path":"2016/01/19/docker-what-is/","text":"Docker？之前有听说过docker这个东西，印象比较深的一次就是在耗子的微博里面看到其对docker有非常高的评价。从此便觉得docker是个牛逼的东西。 但是这牛逼的东西到底是用来干啥的呢？由于docker的出场方式通常是”docker容器“，所以我知道它是一个容器。而且docker出现的地方都会配个图，就是那种几个长方体叠在一起的图，看到它就会让我想到网络模型、android架构等一系列的、牛逼的图。 所以在我的印象中，docker应该是一个非常底层而又深奥的容器，跟”Tomcat容器“应该是没法比的。 docker很厉害的样子，但是跟我又有什么关系呢，在我目前所接触的Java领域甚至还没听说过这个东西－－等我哪天厉害了我可以再考虑考虑回来研究研究docker。。 最近公司里面用到了spring-cloud，里面又出现了“docker”这个词，所以，至少我应该知道docker是干啥的吧！ 那么，docker是什么借用官方的说明： Docker是一个开源的引擎，可以轻松的为任何应用创建一个轻量级的、可移植的、自给自足的容器。开发者在笔记本上编译测试通过的容器可以批量地在生产环境中部署，包括VMs（虚拟机）、bare metal、OpenStack 集群和其他的基础应用平台。 然而对于我来说，看了等于没看。虽然等我学完了docker可能会觉得这讲的很有道理，但是很遗憾，现在功力不足。 所以现在最好的办法就是：动手试试 Hello world安装ubuntu： sudo apt-get update sudo apt-get install -y docker.io sudo ln -sf /usr/bin/docker.io /usr/local/bin/docker sudo sed -i &apos;$acomplete -F _docker docker&apos; /etc/bash_completion.d/docker.io 此时docker已安装完成，可以通过docker --version查看。 获取镜像？第一次看到这个条目的时候，我就懵了，这里的“获取镜像”又是啥！ 获取镜像乖乖的按步骤来看看： 从Docker Hub仓库下载一个Ubuntu12.04操作系统的镜像。 sudo docker pull ubuntu:12.04 执行完该条命令以后只需等待镜像下载完毕即可。 说明该命令实际上相当于 $ sudo docker pull registry.hub.docker.com/ubuntu:12.04命令，即从注册服务器 registry.hub.docker.com中的 ubuntu 仓库来下载标记为 12.04 的镜像。 这个命令也类似于Git操作：从仓库里面pull出我要的东西来。 获取完了就能用？sudo docker run -t -i ubuntu:12.04 /bin/bash 执行完以上命令后进入到一个新的终端－－就是docker之中。 原来docker就是一个虚拟机啊！ 一些操作查看已有的镜像sudo docker images 说明在ubuntu仓库有一个标签为12.04、ID为bad926a6fb50、五个星期前创建的、大小为137M的一个镜像。 docker容器启动一个docker容器解释一下之前的命令sudo docker run -t -i ubuntu:12.04 /bin/bash 开启一个新的容器，其镜像位于ubuntu仓库，标签号为12.04。如果未指定12.04，则默认为latest。 开启容器后启动一个 bash 终端，允许用户进行交互。 其中，-t选项让Docker分配一个伪终端（pseudo-tty）并绑定到容器的标准输入上， -i则让容器的标准输入保持打开。 后台启动容器sudo docker -idt ubuntu:12.04 多了一个-d（Daemonized)选项，说明后台启动。 查看docker运行中的容器sudo docker ps 说明一个有ID为add4bd1abadf的容器：开启并启动于一个小时前，它的名字为berserk_mestorf。 查看所有的docker容器sudo docker ps -a 进入容器sudo docker attach container_id/names 中间好像阻塞了，不过可以看到，最后的实例由iZ2855ufp2yZ变成了add4bd1abadf，说明进入docker容器成功了。 总结谈谈目前的理解 docker是什么docker容器，这个容器原来就是虚拟机，而且这个虚拟机非常的轻量－－通过ps命令可以看到它只启动了一些我们用到的进程。 docker有什么用虚拟机又有什么用 ————翁英健 本文地址：http://wengyingjian.github.io/2016/01/19/docker-what-is/ -End-","tags":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/tags/docker/"}]},{"title":"Nginx学习笔记（三）－Nginx作为反向代理","date":"2016-01-10T07:44:51.000Z","path":"2016/01/10/nginx-note-reverse-proxy/","text":"反向代理简介概述Nginx能够作为一个反向代理来终结来自客户端的请求，并且向上游服务器打开一个新的请求。在这个处理的过程中，为了更好地响应客户端请求，该请求可以根据它的URI、客户端参数或者一些其他的逻辑进行拆分。通过代理服务器，请求的原始URL中的任何部分能够以这种方式进行转换。 代理到上有服务器的配置中，最重要的是proxy_pass指令。该指令有一个参数，URL请求将会被转换，带有URI部分的proxy_pass指令将会使用该URI替代request_uri部分。 url转换下面的例子中的/proxy_pass，在请求传递到上游服务器时将会被替代为 location /proxy_pass { proxy_pass http://121.42.32.99:8080/nginxserver/proxy_pass/request_from; } 测试步骤 开启一个客户端，修改$NGINX_HOME/conf/nginx.conf文件：在server域中加入以上的location代码块。 重新加载nginx配置文件，使用nginx -s reload命令。 访问http://host:80/proxy_pass。 理论上讲，此时应该访问到的应该是http://121.42.32.99:8080/nginxserver/proxy_pass/request_from 的内容。所以我们需要写一个java服务端，用来监测客户端的访问。由于测试时候部署频繁，所以安利一下本人的全家桶系列之自动化部署工具。 效果演示 分析其中，服务端java代码如下： @RestController @RequestMapping(&quot;proxy_pass&quot;) public class ProxyPassController { @RequestMapping(&quot;test_proxy_pass&quot;) public Object proxyPass() { return &quot;proxy pass success&quot;; } @RequestMapping(&quot;request_from&quot;) public Object requestFrom(HttpServletRequest request) { return String.format(&quot;%s\\n%s\\n%s&quot;, request.getRequestURI(), request.getRemoteAddr(), request.getRemoteHost()); } } 说明两件事情： 请求被代理了，转发到了目标的地址。 请求被终结了，java代码处获得的uri为nginx服务器的地址。 url转换特殊情况location处定义了正则表达式以下的配置中，真正转发到的地址是http://121.42.32.99:8080/nginxserver/proxy_pass/test_proxy_pass，而非http://121.42.32.99:8080/proxy： location ~ ^/nginxserver/proxy_pass/test_proxy_pass { proxy_pass http://121.42.32.99:8080/proxy; } 事实上，现在的nginx版本如果还这样配置的话是会报错的：如果location处设置了正则表达式，不允许proxy_pass处指定路径。 location内有rewrite改变了uri如果在location内有rewrite改变了URI，那么Nginx使用这个URI处理这个请求，不再发生转换。 在下面的例子中，URI传递到上游服务器的将会是/index.php?page=&lt;match&gt;，这个&lt;match&gt;会是来自括号内捕获的参数，而不是预期的/index(proxy_pass指令指示的部分)。 location / { rewrite /(.*)$/index.php?page=$1 break; proxy_pass http://localhost:8080/index; } 注意：在rewrite指令中，break标记用于立即停止rewrite模块的所有指令。 ————翁英健 本文地址：http://wengyingjian.github.io/2016/01/10/nginx-note-reverse-proxy/ -End-","tags":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"},{"name":"服务器","slug":"服务器","permalink":"http://yoursite.com/tags/服务器/"},{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/tags/nginx/"}]},{"title":"Nginx学习笔记（二）－配置指南","date":"2016-01-10T04:42:12.000Z","path":"2016/01/10/nginx-note-config/","text":"基本配置格式基本的Nginx配置文件由若干部分组成。每一个部分都是通过下列方法定义的。 &lt;section&gt; { &lt;directive&gt; &lt;parameters&gt;; } 说明： 每一个指令行都由分号;结束，这标记着一行的结束。大括号{}实际上表示一个新上下文（context），但是大多数情况下我们将他们作为“节、部分（section）”来读。 Nginx全局配置参数全局配置部分被用于配置对整个server都有效的参数和前一个章节中的例外格式。全局部分可能包含配置指令，例如user和worker_processes，这里没有大括号{}包围全局部分。 全局配置指令： 简短的例子(nginx.conf)： #使用用户www来运行 user www; #1个工作线程 worker_processes 1; #显式指定error log日志存放路径 #error_log logs/error.log; #error_log logs/error.log notice; #error_log logs/error.log info; #显式指定pid文件存放路径 #pid logs/nginx.pid; #为events模块配置一个新的上下文 events { #最大连接数 worker_connections 1024; } 使用include文件在Nginx配置文件中，include文件可以在任何地方。只要保证被include的文件符合正确的Nginx语法（即配置指令和块），然后指定这些文件的路径即可。 demo(nginx.conf)： include mine.types; 以上的mine.types是相对路径的表示方法，则依据主配置文件nginx.conf路径进行搜索。 nginx.conf文件的绝对路径为/opt/nginx/conf/nginx.conf，则以上配置等价于： include /opt/nginx/conf/mine.types; 通配符在路径中出现通配符可以表示多个配置文件。 demo: include /opt/nginx/conf/*.types; 测试配置文件要想测试配置文件（包括include内容）语法是否正确，可用以下命令进行测试： nginx -t -c &lt;path-to-nginx.conf&gt; Http的server部分概述在Http中，server部分或者是Http配置context都是可用的，除非在编译安装Nginx时没有包含Http模块（--without-http）。这部分控制了Http模块的方方面面，是使用最多的一个部分。 本部分的指令用于处理Http连接，因此该模块提供了相当数量的指令。为了更容易理解这些指令，我们将它们划分为不同的类型来讲述。 客户端指令这一组指令用于处理客户端连接本身的各个方面，以及不同类型的客户端。 文件I/O指令这些指令用于控制Nginx如何投递静态文件，以及如何管理文件描述符。 Hash指令这组hash指令控制Nginx分配给某些变量多大的静态内存。 在启动和重新配置时，Nginx会计算需要的最小值。在Nginx发出警告时，你几乎只需要调整一个*_hash_max_size 指令的参数就可以达到效果。*_hash_bucket_size变量被设置了默认值，以便满足多处理器缓存行降低检索需要的检索查找，因此基本不需要改变，格外更详细的内容参考http://nginx.org/en/docs/hash.html Socket指令这些指令描述了Nginx如何设置创建TCP套接字的变量选项。 示例配置文件demo： http { include mime.types; default_type application/octet-stream; sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; server_names_hash_max_size 1024; } 在nginx.conf文件中上面的这部分内容跟随在全局配置指令之后。 虚拟服务器部分概述任何由关键字server开始的部分都被称作“虚拟服务器”部分。它描述的是一组根据server_name指令逻辑分割的资源，这些虚拟服务器响应Http请求，因此它们都包含在http部分中。 一个虚拟服务器由listen和server_name指令组合定义。 listen指令listen指令定义了一个IP地址/端口组合或者是UNIX域套接字路径。 listen address[:port]; listen port; listen unix:path; listen指令还有一些其他的可选参数 listen指令的参数 server_name指令server_name指令可以用来解决一些配置问题。 默认值它的默认值为&quot;&quot;，这意味着server部分没有server_name指令，对于没有设置Host头字段的请求将会匹配该server处理。我们就可以设置这个server来丢弃这种缺乏Host头的请求： server { listen 80; return 444; } 这里是用Http非标准代码444使得Nginx立即关闭一个连接。 通配符 通配符可以替代部分子域名：*.example.com。 通配符可以替代顶级域部分：www.example.*。 一种特殊形式将匹配子域或域本身。 .example.com匹配*.example.com也包括example.com 正则表达式通过在域名前面加上波浪号（~），正则表达式可以被作为参数应用于server_name： server_name~^www\\.example\\.com$; server_name~^www(\\d+).example\\.(com)$; 后一种形式是利用捕获，可以在以后引用中进一步设置（用$1,$2等）指令中使用。 服务器绑定遵循逻辑对于一个特定的请求，确定哪些虚拟服务器提供该请求的服务时，应该遵循以下的逻辑： 匹配IP地址和listen指令指定的端口。 将Host头字段作为一个字符串匹配server_name指令。 将Host头字段与server_name指令值字符串的开始部分做匹配。 将Host头字段与server_name指令值字符串的尾部分做匹配。 将Host头字段与server_name指令值进行正则表达式匹配。 如果所有Host头匹配失败，那么将会转向listen指令标记的default_server。 如果所有的Host头匹配失败，并且没有default_server，那么将会转向第一个server的listen指令，以满足第一步。 逻辑图： default_serverdefault_server被用于处理其他方式没有处理的请求。因此推荐总是明确地设置default_server，以便这些没有被处理的请求通过这种定义的方式处理。 出了这个用法以外，default_server也可以使用同样的listen指令配置若干个虚拟服务器。这里设置的任何指令都将会在匹配的server区段有效。 Locations-where,when,how概述location指令可以用在虚拟服务器server部分，并且意味着提供来自客户端的URI或者内部重定向访问。除少数情况外，location也可以被嵌套使用，它们被称作为特定的配置尽可能地处理请求。 location定义location [modifier] uri { ... } 或者是命名location: location @name { ... } 命令location仅对内部访问重定向，在进入一个location之前它会保留被请求的URI部分。命名location只能够在server级别定义。 修饰符(modifier) location匹配当一个请求进入时，URI将会被检测匹配一个最佳的location。 没有正则表达式的location被作为最佳的匹配，独立于含有正则表达式的location顺序。 在配置文件中按照查找顺序进行正则表达式匹配，在查找第一个正则表达式匹配之后结束查找，那么就由这个最佳的location提供请求处理。 这里比较匹配描述的是解码URI，例如，在URI中的%20，将会匹配location中的（空格）。 命名location仅可以在location中使用。 指令仅用于location中的指令 其它指令另外，http部分的其他指令也可以在location中指定。 try_files指令try_files可以用在server部分，但是最常见的还是在location部分中。try_files指令将会按照给定它的参数列出的顺序进行尝试，第一个被匹配的将会被使用。 它经常被用于从一个变量去匹配另一个可能的文件，然后将处理传递到一个命名location，看下面的例子： location / { try_files $url $url/ @mongrel; } location @mongrel { proxy_pass http://appserver; } 这里有一个隐含的目录索引，如果给定的URI作为一个文件没有被找到，那么处理将会通过代理被传递到appserver。 location嵌套除了以下前缀外，locations可以被嵌套。 具有=前缀 命名location 最佳时间表明正则表达式location被嵌套在基于字符串的location，看下面的例子： #首先进入根路径 location / { #符合/css路径的最佳匹配位置 location ^~ /css { #匹配正则 location~* /css/.*\\.css$ { } } } 完整的示例配置文件以下示例是一个样本配置文件： user www; worker_processes 12; error_log /var/log/nginx/error.log; pid /var/run/nginx.pid; events { use /dev/poll; worker_connections 2048; } http { include mime.types; default_type application/octet-stream; sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; server_name_hash_max_size 1024; server { listen 80; return 444; } server { listen 80; server_name www.example.com; location / { try_files $url $url/ @mongrel; } location @mongrel { proxy_pass http://127.0.0.1:8080; } } } 总结在本章中，我们看到了如何构建Nginx的配置文件。模块化的本质值得思考，从某种意义上讲，Nginx本身也是模块化的。全局的配置区段负责各个方面，对于Nginx来说是一个整体。Nginx负责处理的每一种协议单独成为一个部分。我们还可以通过在这些协议配置内（http或者mail）指定server来定义每一个请求如何被处理，以便请求被路由到特定的IP地址和端口上。在http区段中，使用locations来匹配URI请求，这些locations可以嵌套使用，或者按照其他顺序使用，以确保请求被路由到正确的文件系统区域或者应用程序服务器。 本章没有涵盖编译到二进制Nginx命令中各种模块提供的配置选项，这些额外的指令将会遍及本书的始终，因此特定的模块被用于解决一个问题。对于Nginx配置中的变量也没有解释，这些变量也将会在后边的内容中讨论。 ————翁英健 本文地址：http://wengyingjian.github.io/2016/01/10/nginx-note-config/ -End-","tags":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"},{"name":"服务器","slug":"服务器","permalink":"http://yoursite.com/tags/服务器/"},{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/tags/nginx/"}]},{"title":"Debian用户管理","date":"2016-01-09T06:49:26.000Z","path":"2016/01/09/debian-users/","text":"添加用户添加用户组groupadd group-name 添加用户useradd -g group-name user-name 设置密码passwd user-name 删除用户userdel user-name 查看用户查看指定用户信息id user-name 查看所有用户信息cat /etc/passwd 设置sudo权限visudo 找到root ALL=(ALL:ALL) ALL下面添加user-name ALL=(ALL:ALL) ALL sudo无需密码改成user-name ALL=NOPASSWD:ALL ————翁英健 本文地址：http://wengyingjian.github.io/2016/01/09/debian-users/ -End-","tags":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"}]},{"title":"Nginx学习笔记（一）－Nginx及第三方模块安装","date":"2016-01-09T05:33:33.000Z","path":"2016/01/09/nginx-note-install/","text":"说明学习资料参考《精通Nginx》－－Dimitri Aivaliotis，陶利军译。如有问题请联系wengyingjian@foxmail.com 安装Nginx使用包管理器安装NginxLinux(debian) sudo apt-get install nginx Linux(rpm) sudo yum install nginx FreeBSD sudo pkg_install -r nginx Centos1.创建文件添加yum配置 sudo vi /etc/yum.repos.d/nginx.repo [nginx] name=nginx repo baseurl=http://nginx.org/package/centos/6/$basearch/ gpgcheck=0 enabled=1 2.执行命令安装nginx sudo yum install nginx 由于笔者用的是debian(ubuntu)，所以对于centos的安装方法并没有测试过。。。只是搬的书上的。 Debian1.通过从http://nginx.org/keys/nginx_signing.key下载Nginx并安装签名key，将该签名添加到系统的apt keying 中。 sudo apt-key add nginx_signing.key 2.将nginx.org仓库追加到/etc/apts/sources.list文件末尾。 cat &quot;deb http://nginx.org/packages/debian/ squeeze nginx&quot; &gt;&gt; sources.list cat &quot;deb-src http://nginx.org/packages/debian/ squeeze nginx&quot; &gt;&gt; sources.list 3.执行命令安装 sudo apt-get update sudo apt-get install nginx 如果以上的方法无法安装成功，可以尝试用源代码安装。 从源代码编安装Nginx获取nginx源代码下载http://nginx.org/en/download.html cd ~ &amp;&amp; mkdir build/ cd build &amp;&amp; wget http://nginx.org/download/nginx-1.8.0.tar.gz 解压tar -zxvf nginx-1.8.0.tar.gz 编译构建目录为当前目录~/build/nginx-1.8.0，nginx安装路径为/opt/nginx cd nginx-1.8.0 &amp;&amp; ./configure --prefix=/opt/nginx 此时报错，因为一些模块未安装。需要先安装模块，或者是指定模块的源代码、或者是跳过该模块的安装。 安装make &amp;&amp; sudo make install 其它环境的支持PCREPCRE : Perl Compatible Regular Expressions PCRE下载地址：ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/ wget ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/pcre-8.37.tar.gz tar zxf pcre-8.37.tar.gz cd pcre-8.37 &amp;&amp; ./configure make &amp;&amp; sudo make install 再去编译nginx，其他问题： zlibsudo apt-get install libssl-dev 通用配置选项 优化配置选项 启动nginxcd /opt/nginx &amp;&amp; sbin/nginx 访问http://host:80 配置Web或者mail服务器根据nginx构建目标，可以将其配置称一个Web加速器、Web服务器、邮件代理，或者是集所有为一体。 邮箱代理配置选项 典型mail代理推荐配置： ./configure --with-mail --with-mail_ssl_module --with-openssl=openssl-1.0.1c 指定路径的配置选项 使用各种模块在nginx发布的版本中，除了http和mail模块意外，还有其它一些模块。这些模块在默认安装中没有被安装，但是可以在编译安装时适当地配置选项--with-&lt;module-name&gt;_module来启用相应的选项，如下表： 以上所有这些模块都是建立在Http模块的基础之上的。 网络加速器／代理推荐配置： ./configure --with-http_ssl_module --with-http_realip_module --with-http_geoip_module --with-http_stub_status_module --with-openssl=openssl-1.0.1c Web服务器推荐配置： ./configure --with-http_stub_status_module “不同之处在于他们面对的客户，处于Web加速角色时，会考虑到SSL请求的终结，也包括处理代理客户和基于客户来源决策。处于Web服务角色时，则仅需要提供默认文件访问能力。 我总是推荐启用stub_status模块，这是因为它提供了收集Nginx如何执行、对其度量的一个方法。” 不再使用的模块有些http模块通常情况下时激活的，但是可以通过配置--without-&lt;module-name&gt;_module来禁用它们。 禁用的配置选项： 查找并安装第三方模块方法步骤： 定位你想要使用的模块（在http://github.com或者是http://wiki.nginx.org/3rdPartyModules查找。 下载该模块。 解压缩源代码安装包。 如果有README文件，就阅读README文件，查看是否有依赖安装。 通过/configure-add-module=&lt;path&gt;选项配置使用该模块。 安装详见：http://wiki.nginx.org/HttpLuaModule#Installation 组合在一起中间可能会遇到一些文件的权限问题，这些都比较简单，用sudo给对应的文件修改权限即可。这里就不提了。 首先一些环境：$ export BUILD_DIR=`pwd` $ export Nginx_INSTALLDIR=/opt/nginx $ export VAR_DIR=/home/www/tmp 第三方模块：ngx_devel_kithttps://github.com/simpl/ngx_devel_kit.gitclone到BUILD_DIR下。 ngx_luahttps://github.com/openresty/lua-nginx-module.gitclone到BUILD_DIR下。 其中ngx_lua需要Lua Libraryhttp://stackoverflow.com/questions/10650904/build-nginx-with-lua-on-rpm-system先安装lua-devel包： sudo apt-get install libluajit-5.1-dev openssl与pcre为了解除nginx与系统的openssl/pcre的耦合，这里使用指定sourceDir的方式来配置 pcre下载地址：ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/ cd $BUILD_DIR/../ wget ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/pcre-8.37.tar.gz tar zxf pcre-8.37.tar.gz openssl官网：https://www.openssl.org/source/github地址：https://github.com/openssl/openssl.git 配置./configure \\ --prefix=${Nginx_INSTALLDIR} \\ --user=www \\ --group=www \\ --http-client-body-temp-path=${VAR_DIR}/client_body_temp \\ --http-proxy-temp-path=${VAR_DIR}/proxy_temp \\ --http-fastcgi-temp-path=${VAR_DIR}/fastcgi_temp \\ --without-http_uwsgi_module \\ --without-http_scgi_module \\ --without-http_browser_module \\ --with-openssl=${BUILD_DIR}/../openssl-1.0.1q \\ --with-pcre=${BUILD_DIR}/../pcre-8.37 \\ --with-http_ssl_module \\ --with-http_sub_module \\ --with-http_flv_module \\ --with-http_gzip_static_module \\ --with-http_gunzip_module \\ --with-http_secure_link_module \\ --with-http_stub_status_module \\ --add-module=${BUILD_DIR}/ngx_devel_kit \\ --add-module=${BUILD_DIR}/lua-nginx-module 效果 总结本章介绍了各种Nginx的有效模块，通过编译你自己的二进制文件，你可以定制Nginx能够为你提供哪些功能。构建和安装软件对于你来说应该不会陌生，所以在创造一个构建环境或确保所有依赖关系都存在上不会花很多时间。一个Nginx的安装应该是按照你的需要，能够随时启用或禁用模块，正如你看到的，启用或者是禁用一个模块应该感到很容易。 接下来我们将介绍几本的Nginx配置概述，以便感受一下在通常情况下Nginx是如何配置的。 ————翁英健 本文地址：http://wengyingjian.github.io/2016/01/09/nginx-note-install/ -End-","tags":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"},{"name":"服务器","slug":"服务器","permalink":"http://yoursite.com/tags/服务器/"},{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/tags/nginx/"}]},{"title":"Hexo博客搭建（二）-自动化及扩展功能","date":"2016-01-04T02:31:04.000Z","path":"2016/01/04/hexo-blog-helloWorld2/","text":"回顾在上一篇Hexo博客搭建中，我们已经通过Hexo让Github Page博客可以访问了。 本篇将会介绍一些高级一些的功能。 不过更多的还请参见官方文档：Hexo中文文档主题nexT文档 第一篇博客现在开始写第一篇博客。 新建源文件源文件都存放在source目录下：博客的.md源文件存放在站点目录下的source/_posts文件夹下。 方法1:在source/_posts文件夹下新建.md，或者在该目录下再拷贝一份。方法2:在站点根目录下使用hexo new filename命令通过创建模板自动在source/_posts 文件夹下创建博客源文件，效果如下： 还是推荐方法2的，因为能够使用模版来创建，模版文件为scaffolds/post.md可以编辑自己喜欢的模板。带有类别，标签的模板如下： title: {{ title }} description: {{ title }} date: {{ date }} tags: [tag1,tag2] categories: blog --- 发布博客假设现在博客已经写好了，要发布。 那么就需要做两件事情：1.首先告诉hexo将自己的源文件转化成对应的.html文件，并且存放在public目录下。执行命令如下（站点目录下）： hexo g 2.然后再将public目录下的资源push到github，执行命令如下（从站点目录下过来）： cd public git add . git commit -m &quot;a&quot; git push 简化流程在上述步骤中，发布博客所需要执行的命令明显是有些过于繁琐了：多么简单的事啊，非得要执行这么多的命令。而且其中的Git操作只是为了一个目的：将新的源文件放上去，都不需要版本控制的功能了，对于我来说只是一个仓库。 所以，作为懒人，必须的自动化。由于没怎么写过shell脚本，之前的java应用自动化部署工具也是用java写的。。。所以这次我还是准备用java写个jar包来执行。。然而失败了，以我现在的功力，行不通。。。或者说是没找到API。 shell脚本虽然没写过.sh脚本，但是linux的命令还是会敲的。于是简单的脚本诞生了：配合上$BLOG_HOME环境变量，再将脚本文件添加至环境变量PATH中。blog脚本地址 ~/.bash_profile中添加的配置： #blog export BLOG_HOME=&apos;/Users/wyj/git/wengyingjian.github.io&apos; PATH=${PATH}:~/sh/blog/ 当然，我的blog文件位于~/sh/blog/。 脚本功能示例 查看已有的博客文件： blog ls 新建博客文件（同时还在自己打开了，贴心否。。）： blog new fileName 删除博客文件(这里的文件都是不带.md后缀的)： blog rm fileName 发布博客（生成文件并自动提交） blog deploy 调试模式（文件修改了能够自动生成，可以边写边看http://localhost:4000）： blog debug 博客扩展功能导航栏外部链接比如说我以前的博客在csdn，希望在导航栏上加上一个csdn的链接。 由于我未找到使用超链接的方法，所以只能达到页面跳转而非新窗口打开的效果了。 添加导航菜单栏条目打开主题配置文件_config.yml，找到menu一栏，添加一项即可： 这个时候执行blog deploy，可以看到博客的导航栏变了，但并不是我们要的”csdn”，被强行加上了前缀有没有。。 其实这个前缀是在找不到对应的映射的时候添加的，编辑主题配置文件themes/next/languages/zh-Hans.yml（当然这里你使用的是什么语言环境就改哪个配置文件），也是找到menu，添加中文简体环境下的显示： 关于语言选择：这个在站点配置文件_config.yml中，通过language属性来指定，简体中文为zh-Hans。 导航菜单栏跳转现在导航栏的显示应该是正常了，现在我们让他跳转： 还记得之前在主题配置文件_config.yml中添上的menu.csdn:/csdn。这就说明点了这个菜单以后，去找source/csdn/index.md这个源文件；或者说是在hexo生成html文件以后去找public/csdn/index.html。贴上配置index.md源代码： title: csdn/ date: 2016-01-03 02:11:52 type: &quot;csdn&quot; comments: false layout: false --- &lt;script language=&quot;javascript&quot; type=&quot;text/javascript&quot;&gt; // 以下方式直接跳转 window.location.href=&apos;http://blog.csdn.net/q291611265&apos;; // 以下方式定时跳转 &lt;/script&gt; layout:false是关键，告诉hexo不要再用任何的模板来包装我了，下面的内容就是生成后html文件的内容。 其它的推荐一下：站内搜索、网站统计、分享／评论栏 添加一下还是很不错的。比较简单：http://theme-next.iissnan.com/third-party-services.html————翁英健 本文地址：http://wengyingjian.github.io/2016/01/04/hexo-blog-helloWorld2/ -End-","tags":[{"name":"helloWorld","slug":"helloWorld","permalink":"http://yoursite.com/tags/helloWorld/"},{"name":"hexo","slug":"hexo","permalink":"http://yoursite.com/tags/hexo/"},{"name":"自动化工具","slug":"自动化工具","permalink":"http://yoursite.com/tags/自动化工具/"}]},{"title":"Hexo博客搭建（一）－Github Page生效","date":"2016-01-03T09:00:12.000Z","path":"2016/01/03/hexo-blog-helloWorld/","text":"背景之前的博客没有目录，无意之中又看到http://arccode.net/的博客非常漂亮，所以就有了重构博客风格的想法，反正有价值的博客内容都能直接拷过来。 但是我找遍了http://arccode.net/的文章也没看到如何搭建的教程，无奈之下只好向作者发邮件求助。 幸运的是一个小时不到博主就给我回邮件了，并且告诉我模板的地址：https://github.com/iissnan/hexo-theme-next。再次感谢。 跟着里面的教程一步步走，虽然中间遇到了很多的问题，但是最终博客还是搭建起来了。 所以这里分享一下博客搭建的过程，以及常见的一些问题。希望对读者能够有所帮助。 安装Hexo点开https://github.com/iissnan/hexo-theme-next，发现是个Github 仓库，于是先去看README： 先去“在线预览”过把瘾，看看自己的博客会变成什么样的，果然效果是我满意的。果断点开“使用文档”开搞。 与教程不同的点教程http://theme-next.iissnan.com/five-minutes-setup.html 中第一步就是安装主题，而且还是“定位到Hexo站点目录下”。这显然是太快了，Hexo都还没安装了。 安装HexoHexo 的中文文档：https://hexo.io/zh-cn/docs/ 要想安装Hexo需要两个前提条件： 安装Git 安装Node.js 下面我针对Mac系统比较消息的谈谈安装的过程，其它系统我也没试过，只好各位自行google了。 Git安装git是不是Mac自带的我都忘了，反正写程序的话这个几乎是必备的了。实在没有，还嫌麻烦的，可以下载 安装程序 安装。 Node.js安装这个我的机器上没有，而且在安装的时候遇到了蛮大的问题。 安装方法1:安装程序先推荐一下绿色通道：下载安装程序 安装。 安装方法2：命令行这个需要用到wget，所以如果没有安装wget，那就先装一下。 安装wgethttp://coolestguidesontheplanet.com/install-and-configure-wget-on-os-x/方法1:下载安装程序安装。我的是10.11版本，下第一个就行了。 方法2:源码编译1.下载 1cd ~/Downloads 1curl -O http://ftp.gnu.org/gnu/wget/wget-1.15.tar.gz 2.解压 1tar -zxvf wget-1.15.tar.gz 1cd wget-1.15/ 3.配置安装 1./configure 中途可能会报错：1configure: error: --with-ssl was given, but GNUTLS is not available. wget需要SSL的支持，但是GNUTLS在大多数OS X系统上是没有的，所以就使用OpenSSL。 1./configure --with-ssl=openssl 1make 1sudo make install 完成了以后，wget就被安装到了 1/usr/local/bin/wget 4.清除源代码与压缩包 1rm -rf ~/Downloads/wget* 测试 1cd ~/Downloads 1wget http://ftp.gnu.org/gnu/wget/wget-1.15.tar.gz 方法3:HomeBrew方式安装。 命令行安装Node.js安装Node.js要走的几步： 安装nvm1$ curl https://raw.github.com/creationix/nvm/master/install.sh | sh 1$ wget -qO- https://raw.github.com/creationix/nvm/master/install.sh | sh 完成后重启终端，再安装Node.js。。一定要重启。1$ nvm install 4 首先，第一步没有出问题。第二步用wget，安装好了wget应该也没啥问题。第三步如果中途网络失败了多试几次。。 Hexo安装1$ npm install -g hexo-cli 如果中途网络失败了多试几次。安装的时候可能会报错，应该是权限的问题，前面加上sudo就行。 如果出现什么我这没提到的错误可以在下方留言，因为我在安装的时候没有截图，很多错误不好描述。 测试Hexo前提得是hexo安装好了。选一个用来存放博客的目录： 我的目录选在了~/git/wengyingjian.github.io/。千万不要被我这个站点的名称所迷惑了，当初叫了这个名字也是因为自己不知道，现在才发现不合情理。应该放在~/hexo/blog/下比较好。。 然后在终端输入： 1hexo init 就跟git init一样，将需要的一些文件啥的都创建好了。 目录结构就像是这个仓库：https://github.com/wengyingjian/wengyingjian.github.io-hexo.demo.git 然后运行一下： 1hexo s --debug hexo s就是hexo server的意思。 接下来就可以在浏览器访问http://127.0.0.1:4000 ###关于权限的一些问题在安装Hexo的时候，有些时候会报错，因为权限不足。遇到这种情况当然是通过在命令前面加上sudo来解决了。 我之前这样做的时候又引发了新的问题：在站点目录下很多自动创建文件的所有者为root，这样搞的我们每次执行相关的命令都要用到sudo。 在平常操作hexo s,hexo g,hexo new的时候，并不会涉及到站点以外的文件，如果还是此时报出了权限问题，我们可以将站点跟路径下所有文件的所有者改为当前用户： 1sudo chown -R user . 安装主题站点文件站点跟目录的文件应该是这个样子的上图中的一些文件目录可能你现在会没有，但是也差不多。 简要解释下： _config.yml：主要配置文件，刚才生成的”http://127.0.0.1:4000&quot;站点重要的配置信息全在这了。 db.json：一些数据存放的地方，不用数据库，用json存。 debug.log:刚才以debug模式启动的，日志信息就在这了。 node_modules:这个太复杂，不管它 package.json:关于hexo的一些说明，如版本啊、插件等元数据。 public:生成的站点，我们要访问，其实访问的html、css、js都在这里面了。 scaffolds:存放一些模版，后面再说。 source：写博客，博客的源代码就放在这个里面了。 themes：上面加阴影的是比较重要的，至于themes，下面说。 Themesthemes文件夹下存放的就是主体，打开可以看到里面有一个叫做langscape的主体。之前在”http://127.0.0.1:4000&quot;看到的那套皮肤就是langscape的主题。 现在，我们要换主题,换成nexT主题。 回到教程：http://theme-next.iissnan.com/five-minutes-setup.html 下载nexT主题其实就是用git克隆到本地。克隆到哪呢？就放在与langscape同级的目录。 12$ cd your-hexo-site$ git clone https://github.com/iissnan/hexo-theme-next themes/next 使用nexT主题告诉hexo，给我配上nexT的皮肤：找到站点目录下的_config.yml，将 theme的值改为next。 验证nexT主题1hexo s --debug 访问http://127.0.0.1:4000 说明在站点跟目录下，有个配置文件叫做_config.yml；在主题目录下，也有一个配置文件叫做_config.yml。为了方便区分，我们称前者为“站点配置文件”，后者为“主题配置文件”。 主题设置略参考http://theme-next.iissnan.com/ 第三方服务略参考http://theme-next.iissnan.com/ 生效Github博客现在站点、主题基本是有个样子了。先不去计较它的样子，让浏览器能够在Github博客上访问到，然后再慢慢去配置、丰富。 github创建仓库在github新建一个仓库。 比如说的我github地址为http://github.com/wengyingjian，那么我的仓库名称就叫做wengyingjian.github.io，对应的网址就是http://wengyingjian.github.io。 上传博客内容到github应该还记得，我的站点跟路径是~/git/wengyingjian.github.io。 但是，这并不是要上传文件的所在路径；这也是我之前犯的一个错。 那么要上传的内容在哪呢？这个我也找了好久，因为教程上并没有。 后来发现是在public文件夹下。 public文件夹下的文件资源已经是完全可用的了，以index.html为入口。所以把这个文件夹放上去是没有问题的。 我的site_dir为~/git/wengyingjian.github.io/，就以我的为例。 1234567cd ~/git/wengyingjian.github.iocd publicgit initgit remote add origin xxxx //github仓库地址git add .git commit -m \"initial commit\"git push origin master 此时访问http://wengyingjian.github.io应该就不是404了。 更多的在下一节说。大多数问题其实都能够在http://theme-next.iissnan.com/中看文档解决。 ————翁英健 本文地址：http://wengyingjian.github.io/2016/01/03/hexo-blog-helloWorld/ -End-","tags":[{"name":"helloWorld","slug":"helloWorld","permalink":"http://yoursite.com/tags/helloWorld/"},{"name":"hexo","slug":"hexo","permalink":"http://yoursite.com/tags/hexo/"}]},{"title":"Rabbitmq（七）－RPC","date":"2016-01-01T16:00:00.000Z","path":"2016/01/02/rabbitmq-rpc/","text":"翻译自：https://www.rabbitmq.com/tutorials/tutorial-six-java.html整理过的源代码(java-maven,workqueues-package)：https://github.com/wengyingjian/rabbitmq-tutorial.git 远程方法调用（RPC）(通过java客户端实现) 在Rabbitmq（三）－Work Queues中我们通过工作队列分发实现了多个消费者分担处理任务的功能。 但是，如果我们执行的任务是有返回结果的，而且我们还需要这个结果呢？这种情况就有点不同了，在术语上我们称之为远程方法调用或者是RPC。 在这篇教程中，我们准备实现一个远程调用的功能：一个客户端，还有一个可扩展的RPC服务器。然而我们手头并没有啥需要返回结果的需求，只好模拟一个了：让RPC服务器返回Fibonacci数列。 客户端接口要说明RPC服务器的工作原理，我们还需要创建一个简单的客户端接口。对外暴露一个call方法，然后调用这个call方法－－阻塞一段时间，直到接收到服务器的返回结果。 FibonacciRpcClient fibonacciRpc = new FibonacciRpcClient(); String result = fibonacciRpc.call(&quot;4&quot;); System.out.println( &quot;fib(4) is &quot; + result); 关于RPC需要注意的虽然RPC调用在计算机领域已经再平常不过了，但是如果程序员不知道一个方法的调用到底是本地调用还是（速度较慢的）远程调用的时候，可能就要出问题了。上述的这种情况会导致系统的不可预知性，而且还会给程序调试带来很大的麻烦。乱用、滥用RPC会使得程序的可维护性变的非常的差。 所以，可以考虑一下如下的建议： 始终要明确一个方法的调用是本地调用还是远程调用。给自己的代码写文档。让各个组件之间的依赖关系变的清晰明了。做好异常处理：如果远程调用的服务挂了，或者是执行超时了该如何处理。 你也可以尝试使用异步管道来取代RPC－－当任务执行完成的时候自动将结果推送到下一个运行环境之中。 回调队列总的来说，通过RabbitMQ的RPC还是比较简单的：客户端将请求消息发送过去，服务器将执行结果返回回来。为了能够接收这个服务器处过来的返回结果，我们发送过去的消息就需要是带有回调信息的。 callbackQueueName = channel.queueDeclare().getQueue(); BasicProperties props = new BasicProperties .Builder() .replyTo(callbackQueueName) .build(); channel.basicPublish(&quot;&quot;, &quot;rpc_queue&quot;, props, message.getBytes()); // ... then code to read a response message from the callback_queue ... 消息属性AMQP协议预定义了14个消息（message）携带的属性。但是除了以下的一些属性，其它的很少被用到： deliveryMode :将消息标记为持久态（值为2）或者是瞬时态（其它任何值）。有可能你还记得在Rabbitmq（三）－Work Queues中有提到过。 contentType :用于说明编码的格式。比如说使用Json的格式，那么可以设置为： application/json 。 replyTo :通常用于给回调队列命名。 correlationId :用于与请求的返回结果相关联。 写代码的时候需要引用如下： import com.rabbitmq.client.AMQP.BasicProperties; Correlation Id我们希望在所有的远程调用上都加上返回结果。然而这样做并不是很合理，还好有个更好的方法－－给它们都设置一个回调队列。 这就产生了一个新的问题，队列得到了返回结果以后并不知道这个结果所属的请求者是谁。这个时候 correlationId 就该出马了。我们把每个请求的 correlationId 设置一个唯一的值，然后得到返回结果的时候就能拿到这个值，由此就能给返回结果匹配上对应的请求者了。当 correlationId 的值未知的时候，通常我们会把这个消息丢弃掉－－因为它不属于任何的请求。 哪有可能你就要问了，为什么我们要在回调队列中把未知的消息给丢弃掉，而不是报错呢？这个就涉及到服务器竞争的问题了，如果碰巧遇到RPC服务器在我们收到了返回结果，但是还未给请求发送ack反馈的时候挂掉了。这种情况下服务器重启后请求会再次发送，所以我们的客户端就应该处理好返回结果重复的情况。 小结 RPC的工作流程： 客户端开启了后，创建了一个匿名的，唯一的回调队列。为了能够远程调用，客户端发送的消息需要带有2个参数：replyTo，设置回调的队列；correlationId，给每个请求设置唯一的标示。将请求发送给rpc_queue队列。RPC任务执行者（即server）监听该队列，等队列的请求过来的时候，它就将处理的结果返回给客户端，通过replyTo属性指定的那个队列。客户端等待回调队列返回的数据。当接收到消息时，会先检查correlationId属性，如果找到了匹配上的请求，那么就将结果返回给该应用。 写代码Fibonacci任务： private static int fib(int n) throws Exception { if (n == 0) return 0; if (n == 1) return 1; return fib(n-1) + fib(n-2); } 我们的Fibonacci函数假定所有的输入都是正整数（别指望他能够计算太大的数字，因为递归会让栈溢出的）。 RPCServer.java private static final String RPC_QUEUE_NAME = &quot;rpc_queue&quot;; ConnectionFactory factory = new ConnectionFactory(); factory.setHost(&quot;localhost&quot;); Connection connection = factory.newConnection(); Channel channel = connection.createChannel(); channel.queueDeclare(RPC_QUEUE_NAME, false, false, false, null); channel.basicQos(1); QueueingConsumer consumer = new QueueingConsumer(channel); channel.basicConsume(RPC_QUEUE_NAME, false, consumer); System.out.println(&quot; [x] Awaiting RPC requests&quot;); while (true) { QueueingConsumer.Delivery delivery = consumer.nextDelivery(); BasicProperties props = delivery.getProperties(); BasicProperties replyProps = new BasicProperties .Builder() .correlationId(props.getCorrelationId()) .build(); String message = new String(delivery.getBody()); int n = Integer.parseInt(message); System.out.println(&quot; [.] fib(&quot; + message + &quot;)&quot;); String response = &quot;&quot; + fib(n); channel.basicPublish( &quot;&quot;, props.getReplyTo(), replyProps, response.getBytes()); channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false); } 服务器的代码是比较直接的： 老规矩，先创建连接(Connection)、通道(Channel)，声明队列(Queue)。有些时候需要运行多个服务器进程，为了保证多个服务器能够比较均衡的处理任务，还需要通过channel.basicQos设置 prefetchCount。通过 basicConsume来进入队列，然后就开始跑while循环来等待返回结果出来，好进行下一步的工作。 RPCClient.java private Connection connection; private Channel channel; private String requestQueueName = &quot;rpc_queue&quot;; private String replyQueueName; private QueueingConsumer consumer; public RPCClient() throws Exception { ConnectionFactory factory = new ConnectionFactory(); factory.setHost(&quot;localhost&quot;); connection = factory.newConnection(); channel = connection.createChannel(); replyQueueName = channel.queueDeclare().getQueue(); consumer = new QueueingConsumer(channel); channel.basicConsume(replyQueueName, true, consumer); } public String call(String message) throws Exception { String response = null; String corrId = java.util.UUID.randomUUID().toString(); BasicProperties props = new BasicProperties .Builder() .correlationId(corrId) .replyTo(replyQueueName) .build(); channel.basicPublish(&quot;&quot;, requestQueueName, props, message.getBytes()); while (true) { QueueingConsumer.Delivery delivery = consumer.nextDelivery(); if (delivery.getProperties().getCorrelationId().equals(corrId)) { response = new String(delivery.getBody()); break; } } return response; } public void close() throws Exception { connection.close(); } 客户端代码略微的有点复杂： 开启连接(Connnection)、通道(Channel)，另外还需要声明一个用于答复的唯一的队列(Queue)。监听回调的队列，以便有结果返回时的感知。call方法调用意味着开启RPC请求。首先，生成一个唯一的correlationId，并且保存下来－－后面的while循环会通过它来寻找合适的返回结果。然后将消息给发送出去，消息需要带有两个属性：reployTo和correlationId。这个时候就只需要等待了，直到有匹配的返回信息。while循环的内容是非常简单的：对与所有过来的请求都检查一下correlationId是否我们要的那个，如果是的话，就将结果保存下来。最终，将得到的结果返回给用户。 客户端请求： RPCClient fibonacciRpc = new RPCClient(); System.out.println(&quot; [x] Requesting fib(30)&quot;); String response = fibonacciRpc.call(&quot;30&quot;); System.out.println(&quot; [.] Got &apos;&quot; + response + &quot;&apos;&quot;); fibonacciRpc.close(); ————翁英健 本文地址：http://wengyingjian.github.io/2016/01/02/rabbitmq-topics/ -End-","tags":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"http://yoursite.com/tags/rabbitmq/"},{"name":"消息队列","slug":"消息队列","permalink":"http://yoursite.com/tags/消息队列/"}]},{"title":"远程调用与本地调用","date":"2016-01-01T16:00:00.000Z","path":"2016/01/02/hessianrpc-调用与本地调用的比较/","text":"占坑 ————翁英健 本文地址：http://wengyingjian.github.io/2016/01/02/rabbitmq-topics/ -End-","tags":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"http://yoursite.com/tags/rabbitmq/"},{"name":"消息队列","slug":"消息队列","permalink":"http://yoursite.com/tags/消息队列/"}]},{"title":"Rabbitmq（六）－Topics","date":"2016-01-01T16:00:00.000Z","path":"2016/01/02/rabbitmq-topics/","text":"翻译自：https://www.rabbitmq.com/tutorials/tutorial-five-java.html整理过的源代码(java-maven,workqueues-package)：https://github.com/wengyingjian/rabbitmq-tutorial.git Topics(通过java客户端实现) 在前面的教程中我们改进了日志输出系统，将fanout的路由模式改为direct，从而实现了消费者端可选择的控制消息日志。 但是，direct类型也是有缺陷的：不能以一种标准来路由，只能指定具体的key。 在日志系统中，我们需要收集的并不仅仅是程序报出的问题，更多的是需要跟踪到导致问题的根源。这可能让我们想到unix日志工具syslog，它的能收集到来自onfo/warn/crit..,auth/crom/kern…两处的日志。 这样一来就很灵活了：我们可以选择要查看的日志的来源。 要达到这个效果，就得学习一个新的、稍微复杂一些的路由器类型topic。 Topic交换机发送至topic类型的交换机不是需要一个明确的routing_key，而是一些以.来分隔开的字符串，最好是能够说明message一些特征的单词，见名知意嘛。比如说：stock.usd.nyse,nyse.vmw,quick.orange.rabbit都是符合规范的。routing_key中放几个单词都是随便的，想要几个要几个，但是要求是总的大小要在255B以下。 另外还要有binding key。topic交换机背后的逻辑跟direct其实是非常相似的：带有指定routing key的消息会被路由到所有所有与其binding key匹配的队列中去。不同之处在于： *（星号）可以代表任何一个单词#（井号）可以代表任何0个或多个单词 举例说明：上图所示，我们要发送所有消息都是与动物相关的。这些消息的routing key由3个单词（2个点）组成。其中第一个单词代表动物的速度，第二个代表颜色，第三个代表类型：.. 然后创建了三种绑定：Q1- .orange. ;Q2 . .rabbit;Q3lazy.# 然后这些binding key的大致意思就是： Q1:与所有颜色为orange的动物打交道。Q2:与所有品种为rabbit的动物打交道。Q3:与所有速度lazy的动物打交道。 如果一个routing key为quick.orange.rabbit的消息发送出去，那么它会被Q1，Q2两个队列都接收到;lazy.orange.elephant会被Q1,Q2所接收。而quick.orange.fox只能被Q1接收，lazy.brown.fox只能被Q2接收。lazy.pink.rabbit虽然匹配上了Q2两次，但是只会发送一次到Q2，quick.brown.fox没找到匹配的自然就被丢弃了。 如果rounting key不符合上面binding key的格式呢？比如说 orange 和quick.orange.male.rabbit，它们是会被全部丢弃的，因为不匹配。 lazy.orange.male.rabbit这个虽然有4个单词，但是它确是与lazy.#匹配，所以它就能够被发送到Q2中去。 Topic类型的交换机他和其它交换机一样，只不过是多加了模式匹配的功能，从而更加强大了。 当一个队列的binding key 为#时：匹配所有的routing_key类型的消息，就跟fanout类型的交换机功能一样了。 如果*,#都没有在binding key中用到时，那么它就跟direct类型的交换机功能一样的。 写代码将 topic 类型的交换机运用到日志输出系统中，把日志的格式定为.。 EmitLogTopic.java public class EmitLogTopic { private static final String EXCHANGE_NAME = &quot;topic_logs&quot;; public static void main(String[] argv) throws Exception { ConnectionFactory factory = new ConnectionFactory(); factory.setHost(&quot;localhost&quot;); Connection connection = factory.newConnection(); Channel channel = connection.createChannel(); channel.exchangeDeclare(EXCHANGE_NAME, &quot;topic&quot;); String routingKey = getRouting(argv); String message = getMessage(argv); channel.basicPublish(EXCHANGE_NAME, routingKey, null, message.getBytes()); System.out.println(&quot; [x] Sent &apos;&quot; + routingKey + &quot;&apos;:&apos;&quot; + message + &quot;&apos;&quot;); connection.close(); } //... } ReceiveLogsTopic.java import com.rabbitmq.client.*; import java.io.IOException; public class ReceiveLogsTopic { private static final String EXCHANGE_NAME = &quot;topic_logs&quot;; public static void main(String[] argv) throws Exception { ConnectionFactory factory = new ConnectionFactory(); factory.setHost(&quot;localhost&quot;); Connection connection = factory.newConnection(); Channel channel = connection.createChannel(); channel.exchangeDeclare(EXCHANGE_NAME, &quot;topic&quot;); String queueName = channel.queueDeclare().getQueue(); if (argv.length &lt; 1) { System.err.println(&quot;Usage: ReceiveLogsTopic [binding_key]...&quot;); System.exit(1); } for (String bindingKey : argv) { channel.queueBind(queueName, EXCHANGE_NAME, bindingKey); } System.out.println(&quot; [*] Waiting for messages. To exit press CTRL+C&quot;); Consumer consumer = new DefaultConsumer(channel) { @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException { String message = new String(body, &quot;UTF-8&quot;); System.out.println(&quot; [x] Received &apos;&quot; + envelope.getRoutingKey() + &quot;&apos;:&apos;&quot; + message + &quot;&apos;&quot;); } }; channel.basicConsume(queueName, true, consumer); } } 运行参数说明接收所有的日志： ReceiveLogsTopic #接收kern日志： ReceiveLogsTopic kern. 接收 critical 日志： ReceiveLogsTopic .critical创建多个绑定： ReceiveLogsTopic kern. .critical 发送一条routing key为kern.critical的消息：EmitLogTopic kern.critical A critical kernel error ————翁英健 本文地址：http://wengyingjian.github.io/2016/01/02/rabbitmq-topics/ -End-","tags":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"http://yoursite.com/tags/rabbitmq/"},{"name":"消息队列","slug":"消息队列","permalink":"http://yoursite.com/tags/消息队列/"}]},{"title":"Rabbitmq（五）－Routing","date":"2015-12-31T16:00:00.000Z","path":"2016/01/01/rabbitmq-routing/","text":"翻译自：https://www.rabbitmq.com/tutorials/tutorial-four-java.html整理过的源代码(java-maven,workqueues-package)：https://github.com/wengyingjian/rabbitmq-tutorial.git 订阅/发布(通过java客户端实现) 在前面的教程中我们完成了一个简单的日志输出系统，实现了将消息广播给多个订阅者的功能。 在本篇教程中，我们在之前的基础上添加一些有趣的特性－－让订阅着可以选择只收到其中一部分的消息。举个例子：我们向屏幕输出所有的日志信息的同时，选择把错误的信息保存到硬盘上。 绑定在之前的例子中，已经有用过绑定了，代码如下： channel.queueBind(queueName, EXCHANGE_NAME, &quot;&quot;); “绑定”其实就是交换机与队列的一个对应关系。也可以这样理解：某个队列只对它绑定了的路由器过来的信息感兴趣。 绑定需要一个额外的routingKey参数，为了避免与basic_publish产生混淆，下面就称它为binding key。下面看下binding key是如何创建的： channel.queueBind(queueName, EXCHANGE_NAME, &quot;black&quot;); binding key作用还得取决于交换机，因为有的交换机回去寻找对于binding key的队列，而我们之前用的例子（fanout类型的交换机）根据无视这个值。 直接交换与之前日志输出系统相比较，现在要做的就是实现一个消息的过滤器，通过它们各自的需求来过滤指定类型的消息。还是上面的例子：我们需要通过过滤得到日志中是错误的消息，把它们给写到硬盘上，这样可以避免太多普通日志来浪费硬盘的空间。 之前用的是fanout交换机，这种交换机只能处理一些简单的广播事件，不够灵活。 利用图示解决方案：这里交换机X的类型是direct的，它绑定了2个队列：第一个队列Q1是以binding key=orange的设置绑定的；第二个队列Q2是以binding key=black+green的设置绑定的。 这样子设定的话，如果设置routing key为orange，那么就会路由到Q1，如果设置routing key为black或是green都会路由到Q2。其它的消息那就都被丢弃了。 多绑定一个binding key绑定多个队列也是被允许的。在这个案例中，我们要是再给交换机X添加一个绑定到Q1的binding key=black，这样达到的效果就更上篇里面的广播类似了：一个routing key=black的消息过来了，那么Q1，Q2都会收到。 生产者综上所述，我们只需要多加一个routing key参数，这样消费者就能够接收到它们希望接受到的消息了。 首先，创建一个路由器： channel.exchangeDeclare(EXCHANGE_NAME, &quot;direct&quot;); 然后，准备消息的发送： channel.basicPublish(EXCHANGE_NAME, severity, null, message.getBytes()); 为了简化，就把 severity 当做是 ‘info’, ‘warning’, ‘error’这几个级别。 消费者消费者代码与之前的就只有一个不同点：需要根据日志的级别 severity 来来绑定具体的队列。 String queueName = channel.queueDeclare().getQueue(); for(String severity : argv){ channel.queueBind(queueName, EXCHANGE_NAME, severity); } 代码 生产者EmitLogDirect.java public class EmitLogDirect { private static final String EXCHANGE_NAME = &quot;direct_logs&quot;; public static void main(String[] argv) throws java.io.IOException { ConnectionFactory factory = new ConnectionFactory(); factory.setHost(&quot;localhost&quot;); Connection connection = factory.newConnection(); Channel channel = connection.createChannel(); channel.exchangeDeclare(EXCHANGE_NAME, &quot;direct&quot;); String severity = getSeverity(argv); String message = getMessage(argv); channel.basicPublish(EXCHANGE_NAME, severity, null, message.getBytes()); System.out.println(&quot; [x] Sent &apos;&quot; + severity + &quot;&apos;:&apos;&quot; + message + &quot;&apos;&quot;); channel.close(); connection.close(); } //.. } 消费者ReceiveLogsDirect.java import com.rabbitmq.client.*; import java.io.IOException; public class ReceiveLogsDirect { private static final String EXCHANGE_NAME = &quot;direct_logs&quot;; public static void main(String[] argv) throws Exception { ConnectionFactory factory = new ConnectionFactory(); factory.setHost(&quot;localhost&quot;); Connection connection = factory.newConnection(); Channel channel = connection.createChannel(); channel.exchangeDeclare(EXCHANGE_NAME, &quot;direct&quot;); String queueName = channel.queueDeclare().getQueue(); if (argv.length &lt; 1){ System.err.println(&quot;Usage: ReceiveLogsDirect [info] [warning] [error]&quot;); System.exit(1); } for(String severity : argv){ channel.queueBind(queueName, EXCHANGE_NAME, severity); } System.out.println(&quot; [*] Waiting for messages. To exit press CTRL+C&quot;); Consumer consumer = new DefaultConsumer(channel) { @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException { String message = new String(body, &quot;UTF-8&quot;); System.out.println(&quot; [x] Received &apos;&quot; + envelope.getRoutingKey() + &quot;&apos;:&apos;&quot; + message + &quot;&apos;&quot;); } }; channel.basicConsume(queueName, true, consumer); } } ————翁英健 本文地址：http://wengyingjian.github.io/2016/01/01/rabbitmq-routing/ -End-","tags":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"http://yoursite.com/tags/rabbitmq/"},{"name":"消息队列","slug":"消息队列","permalink":"http://yoursite.com/tags/消息队列/"}]},{"title":"java性能优化（三）－JVM原理回顾","date":"2015-12-30T16:00:00.000Z","path":"2015/12/31/java-performance-jvm/","text":"之前在csdn上转载过一篇《JVM原理和优化》，关于jvm讲的还是很清晰透彻的。现在在做java性能优化的时候又要用到之前的知识，所以这里再整理回顾一下。图是盗的，字是辛辛苦苦自己码的。 内存模型 稍微（不专业地）解释一下： 方法区：存放元数据，比如class类，类反射的数据等等。虚拟机栈：java方法在执行的时候数据得存起来吧，存的时候学过数据结构的都知道是一个先进后出的栈结构。所以这个区域就是用来存放运行时方法调用的数据的。本地方法栈：java中会有jni本地方法的调用，本地方法运行也是需要栈来临时存放数据的呀。同上。堆：笼统的讲，java对象都放这里了。也是垃圾回收主要关心的地方。 垃圾回收内存模型我们就看方框里面的内容： 整个先分为PermSpace与右边的HeapSpace两大部分。PermSpace对应了上面的方法区，用来存放元数据；HeapSpace对应上面的堆，存对象。因为方法区存放的是元数据：类信息，反射信息，常量池等，所以这些资源一般很少需要释放，垃圾回收跟他们关系也不是特别大。 再将右边的堆区进行细分：年老代和新生代。根据编程的经验（以及数据表明），我们程序中所使用到的对象可以分为两大类：用完即死的和基本死不掉的。放在javaWeb中对应的分别是：普通的一些model对象（new了以后用完就没用了）与controller,service等对象（在spring中以单例存在，从第一次调用直到应用关闭一直存活）。所以对应的，我们把不同生命周期的对象放到不同的堆的位置中，长期存活的放在老年代，用完即弃的放在新生代，多去回收回收新生代的垃圾，年老代偶尔照顾到一下回收一下就行了。 再将新生代细分：Eden区、Survivor区（From区＋To区）上面说了将堆分为年老代和新生代两块来管理，但是想法很好，怎么实现？总不能让对象在产生的时候告诉jvm应该放到哪个区块吧，这样的垃圾回收不要也罢。一个比较好的，用来决定对象是应该放在年老代和新生代的策略，就是用事实说话。给这个对象一定的时间，如果它很长一段时间之内都不被丢弃，那就把它请到年老代。在程序实际的运行中，90%以上的对象都是用完就被丢弃掉的。所以如果把判断一个对象是否应该放入年老代的时间设置的过长，新生代会因为放置太多的对象而造成内存问题；如果时间设置的过短，那么这样进入年老代的对象不一定能够存活较长时间。具体为啥要再将新生代细分为Eden区、Survivor区（From区＋To区），我们在垃圾回收策略中讲。 垃圾回收策略图和上面的差不多。 new出一个对象来，这个对象就先放在年轻代的Eden区。 等到Eden区满了的时候，就执行一次垃圾回收（MinorGc），将存活的对象存放到Survivor区（中的From块），被丢弃的对象就直接清空了。这个时候Eden区就是干净的了。 新建对象，都是放到Eden区。Eden区再一次满了的时候，再执行一次垃圾回收（MinorGc），将Eden区以及Survivor区（From块）存活的对象移动到Survivor区（To块），被丢弃的对象也被清空了。这个时候Eden区是干净的，From区也是干净的。 这下Eden区又满了，再执行一次垃圾回收（MinorGc），将Eden区以及Survivor区（To块）存活的对象移动到Survivor区（From块），被丢弃的对象也被清空了。这个时候Eden区是干净的，To区也是干净的。 如此往复，就是把存活的对象在Survivor区在From块与To块之间来回的移动，筛选。经历了15次以后，如果这个对象还存活，那么恭喜你，下一次回收的时候，你如果还活着就可以被分配到年老代了，正式升级为元老。 以上解释了为何我们要将新生代细分为Eden区、Survivor区（From区＋To区） 但是垃圾回收还是要继续： 6.就这样一直的运行。终于有一天，年老代的空间也满了。这个时候就执行一次超级的垃圾回收（FullGc），将年老代、持久带、新生代无用的对象都给清理出去。 7.基本上，垃圾回收的过程算是介绍完了。上面的清理只能是清除不再被引用到的对象，所以如果有大量的对象一直被引用而忘记释放，最后年老代也被挤满了，垃圾回收也无济于事，所以抛出了Out Of Memory错误。 MinorGc与FullGc不同的垃圾回收器在执行MinorGc与FullGc的方法上有点不一样，但是最终达到的效果还是差不多的。总的来讲，MinorGc一般发生的频率比较高，耗时短；FullGc发生的频率低，耗时长。 什么时候发生FullGc 年老代满了。 持久带满了。 显式执行System.gc()。我们在远程监控的时候点击“执行gc”调用的也是这个方法，其实就是执行就是FullGc。 上一次GC之后Heap的各域分配策略动态变化。我们是可以通过参数指定各内存的大小等信息的；在程序的运行中，其实我们也可以动态的去修改它，只是很少这么做。在java默认的参数中，堆各部分的大小初始值和最大值是不一样的，所以通过程序运行需要占取多大的内存，各个部分的大小会自动作出动态的调整。 垃圾回收器以下内容摘自http://blog.csdn.net/kimylrong/article/details/18265807#t8 ————翁英健 本文地址：http://wengyingjian.github.io/2015/12/31/java-performance-jvm/ -End-","tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"},{"name":"jvm","slug":"jvm","permalink":"http://yoursite.com/tags/jvm/"},{"name":"性能","slug":"性能","permalink":"http://yoursite.com/tags/性能/"},{"name":"内存","slug":"内存","permalink":"http://yoursite.com/tags/内存/"}]},{"title":"java性能优化（四）－Tomcat优化案例","date":"2015-12-30T16:00:00.000Z","path":"2015/12/31/java-performance-demo/","text":"java远程实时监测：java性能优化（一）－远程监测gc日志离线收集：java性能优化（二）－gc日志收集与分析垃圾回收机制：java性能优化（三）－JVM原理回顾 下面来一个Tomcat性能调优的小案例。 说明 Tomcat用途：这个tomcat现在主要的作用是用来发布war包的。在之前的一些服务器相关博客中，搭建了一个jenkins+sonatype nexus+tomcat的持续构建环境。我们这里也只关心tomcat通过manager部署war包的性能。 测试方法：使用Jenkins一直往tomcat发送发布war包的请求，频率为5分钟一次，观察时间为30分钟左右。 日志分析工具：Gc Easy 收集日志具体的收集方法在java性能优化（二）－gc日志收集与分析提过了，所以此处就走个过程。 关闭tomcat服务器，移除之前的日志文件。 开启tomcat服务器，自动新建日志文件。 Jenkins开启5分钟一次的部署请求。 等待30分钟。 取出日志文件。 上GcEasy分析。 分析结果算下来30分钟gc所花费的时间为(1.54+1.29)/(34 60+32) (30*60)=2.46s。 (下面的跟着《Java性能优化权威指南的来》) 计算活跃数据大小活跃数据包括： 应用程序运行于稳定态时，老年代占用的Java堆大小； 应用程序运行于稳定态时，永久代占用的Java堆大小。 为了更好地度量应用程序的活跃数据大小，最好在多次Full Gc之后再查看Java堆的占用情况。 永久代活跃数据 元数据大小一般不怎么会波动，这里记下大小为35M。 老年代活跃数据 两张图一起看，第一张图中橙色的点代表的是FullGc，这样就能找到对应的第二张图中的FullGc。那么第二张图中的最低点对应的使用空间就是老年代的活跃数据大小，这里记下是33M。 计算应该分配的堆结论： metaSpace:35MoldSpace:33M 通用法则： 1.Java堆初始值-Xms和最大值-Xmx设置为老年代活跃数据的3～4倍。 -Xms120M -Xmx120M 2.永久代的初始值-XX:PermSize及最大值-XX:MaxPermSize应该比永久代活跃数据大1.2～1.5倍。 -XX:PermSize=48M -XX:MaxPermSize:48M 3.新生代空间应为老年代空间活跃数据的1～1.5倍。 -Xmn45M 设置新的参数tomcat找的是$CATALINA_HOME/bin/setenv.sh 加入： #opst for jvm export CATALINA_OPTS=&quot;$CATALINA_OPTS -Xms120M -Xmx120M&quot; export CATALINA_OPTS=&quot;$CATALINA_OPTS -XX:PermSize=48M -XX:MaxPermSize:48M&quot; export CATALINA_OPTS=&quot;$CATALINA_OPTS -Xmn45M&quot; 移除之前的log日志后启动： 新的结果算下来30分钟gc所花费的时间为(1.51+0.92)/(33 60+4) (30*60)=2.20s，比之前优化了0.2s。。。。 其实按时间算是不科学的，因为2次时间都为30s，而产生的对象数量并不一定是一样的啊。既然统计数据里面提供了byte生成总数以及byte生成速率，我们应该用这个计算才更加合理。 之前的：(1.54+1.29)/3.46=0.82s/gb(每用到1G的内存需要花费1.65秒的时间来回收它)优化后：(1.51+0.92)/3.82=0.64s/gb 多少也有了20%垃圾回收时间优化。。。 ————翁英健 本文地址：http://wengyingjian.github.io/2015/12/31/java-performance-demo/ -End-","tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"},{"name":"jvm","slug":"jvm","permalink":"http://yoursite.com/tags/jvm/"},{"name":"性能","slug":"性能","permalink":"http://yoursite.com/tags/性能/"},{"name":"内存","slug":"内存","permalink":"http://yoursite.com/tags/内存/"}]},{"title":"Rabbitmq（四）－Publish/Subscribe","date":"2015-12-30T16:00:00.000Z","path":"2015/12/31/rabbitmq-publish-subscribe/","text":"翻译自：https://www.rabbitmq.com/tutorials/tutorial-three-java.html整理过的源代码(java-maven,workqueues-package)：https://github.com/wengyingjian/rabbitmq-tutorial.git 订阅/发布(通过java客户端实现) 在前面的教程中我们创建了一个工作队列。并且认为RabbitMQ的工作机制是这样的：每个消息都被传送到了特定的消费者手里。在这一节，我们要做些不同的－－将一个消息传递给多个消费者。这种一个消息发送给多个接受者的模式我们称之为“订阅/发布”。 为了方便说明，我们准备构建一个简单的日志输出系统。该系统包含两部分的程序－－首先我们将消息发送出来，然后我们会接收到该消息并且将其打印出来。 在这个日志系统中，每个运行中的消费者都能够接受到消息。这样我们就能够一边运行一个消费者，让它把日志写到硬盘上；一边再运行一个消费者，让它把日志输出到控制台。 一句话总结：订阅/发布就是将要发布的消息广播给所有订阅者。 交换机在之前的几节里面，消息的发送和接收都是通过同一个队列（queue）的。下面就开始介绍RabbitMQ它真实的的消息发送模型。 首先，快速回顾一下之前的认知： 生产者：发送消息的应用队列：存储消息的缓存区消费者：接收消息的应用 RabbitMQ的核心思想就是：生产者并不直接把消息发送到队列中去。事实上，通常对于生产者来说它根本就不知道有队列这个东西，更不知道自己的消息会通过队列来传递。 真实的情况是：生产者只能把消息发送给一个交换机。那么交换机是什么呢？就是一个一边用来从生产者那接收消息，另外一边再将消息推送到队列中的东西。那么交换机必须得知道它接收到了消息以后该干什么：把它放到某个指定的队列中吗，还是放到很多很多个队列中，还是把它给丢弃了。到底该怎么做（说的专业一点叫“路由”），是由exchange type来决定的。 exchange type的种类都有：direct,topic，headers 和fanout 。我们就拿最后一个fanout来说，把它称声明为log吧 channel.exchangeDeclare(&quot;logs&quot;, &quot;fanout&quot;); fanout的交换类型，教程中让我通过它的名字猜猜是啥意思，怪我英文太差，实在太难，翻译都没找到。解释是这样的：该类型就是负责将所有它所接收到的消息都发送给所有它所知道的队列中，就是广播拉，这个也真是我们所需要的。 列出所有的交换机就用这个命令了： rabbitmqctl $ sudo rabbitmqctl list_exchanges Listing exchanges ... direct amq.direct direct amq.fanout fanout amq.headers headers amq.match headers amq.rabbitmq.log topic amq.rabbitmq.trace topic amq.topic topic logs fanout ...done. 在上面的列表中，能看到有amq.*的交换机，还有默认（无名称，第一个那个）的交换机。这些交换机都是默认就创建好了的。 无名称的交换机在之前的教程中，我们都不知道有交换机这个东西，但是却能够成功的发送消息，这又是怎么做到的呢？其实之前我们用的是默认的交换机，就是我们用空字符串“”定义的那个，就是下面这串代码： channel.basicPublish(&quot;&quot;, &quot;hello&quot;, null, message.getBytes()); 第一个参数指的就是交换机的名称。空字符串那就使用默认的无名称的那个交换机：如果我们声明了routingKey的话，然后消息会被交换机交换机路由到指定的队列中。 现在，我们可以把消息发送到指定的交换机中了： channel.basicPublish( &quot;logs&quot;, &quot;&quot;, null, message.getBytes()); 临时队列之前我们用的队列是有指定的名称的，还记得“hello”和“task_queue”？能够指定一个queue，让消费者知道应该从哪里取消息是至关重要的。 但是，这个和我们在本篇中要测试的这个没有啥关系。我们要得到结果是：消费者接收到了所有它所订阅的消息，而且不要不小心拿到其他人发送的不相关的消息。 首先，每次我们连接到RabbitMQ的时候，都需要得到一个新的队列。这样子做就能保证这个队列别人是不知道的，无关的消息不会进来。所以我们可以为这个queue指定一个随机的名称，或者干脆来让RabbitMQ服务器来帮我们指定这个名称得了，反正我们也不需要知道。 其次，每当我们关闭消费者与RabbitMQ连接的时候，队列要能够自动被删除。 在Java客户端中，我们可以通过无参的 queueDeclare()来创建一个临时的、独有的、能够自动删除的又能够自动生成名字的队列。 String queueName = channel.queueDeclare().getQueue(); 这个时候队列的名字就会长得千奇百怪了，比如说是这个样子的：amq.gen-JzTY20BRgKO-HjmUJj0wLg。 路由绑定我们的交换机和队列在前面已经创建好了：fanout型号的。现在要做的是在路由器与队列之间建立联系，告诉路由器该把消息往哪个队列发送，这里专业的术语叫做：绑定。 channel.queueBind(queueName, &quot;logs&quot;, &quot;&quot;); 现在，”logs”这个交换机就能够往我们的队列中发送消息了。 列出所有的绑定咋列，你猜，用啥命令。 rabbitmqctl list_bindings 开始写代码了啊 生产者这个和之前的也是类似的。 将日志信息发送到指定的交换机中而非无名称的默认交换机中。理论上来说，还需要提供一个 routingKey 。但是这里我们要做的是发布/订阅模式，所以选择的是fanout路由器，同时该路由器是无视队列名称的，反正是广播，谁都发送。 EmitLog.java: import java.io.IOException; import com.rabbitmq.client.ConnectionFactory; import com.rabbitmq.client.Connection; import com.rabbitmq.client.Channel; public class EmitLog { private static final String EXCHANGE_NAME = &quot;logs&quot;; public static void main(String[] argv) throws java.io.IOException { ConnectionFactory factory = new ConnectionFactory(); factory.setHost(&quot;localhost&quot;); Connection connection = factory.newConnection(); Channel channel = connection.createChannel(); channel.exchangeDeclare(EXCHANGE_NAME, &quot;fanout&quot;); String message = getMessage(argv); channel.basicPublish(EXCHANGE_NAME, &quot;&quot;, null, message.getBytes()); System.out.println(&quot; [x] Sent &apos;&quot; + message + &quot;&apos;&quot;); channel.close(); connection.close(); } //... } 消费者可以看到，connection连接建立后，下一步就是给交换机命名。这是非常必要的，因为我们无法将消息发送给一个没有名称的交换机。 如果交换机没有绑定队列的话，那么消息就会丢失掉；如果没有消费者在监听，那么我们可以安全地把消息给丢弃掉。 ReceiveLogs.java import com.rabbitmq.client.*; import java.io.IOException; public class ReceiveLogs { private static final String EXCHANGE_NAME = &quot;logs&quot;; public static void main(String[] argv) throws Exception { ConnectionFactory factory = new ConnectionFactory(); factory.setHost(&quot;localhost&quot;); Connection connection = factory.newConnection(); Channel channel = connection.createChannel(); channel.exchangeDeclare(EXCHANGE_NAME, &quot;fanout&quot;); String queueName = channel.queueDeclare().getQueue(); channel.queueBind(queueName, EXCHANGE_NAME, &quot;&quot;); System.out.println(&quot; [*] Waiting for messages. To exit press CTRL+C&quot;); Consumer consumer = new DefaultConsumer(channel) { @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException { String message = new String(body, &quot;UTF-8&quot;); System.out.println(&quot; [x] Received &apos;&quot; + message + &quot;&apos;&quot;); } }; channel.basicConsume(queueName, true, consumer); } } 最后运行的时候可以使用 rabbitmqctl list_bindings来验证一下RabbitMQ是否真的创建了绑定。当有2个ReceiveLogs.java 程序在跑的时候，你看到的返回信息应该是差不多这样的： $ sudo rabbitmqctl list_bindings Listing bindings ... logs exchange amq.gen-JzTY20BRgKO-HjmUJj0wLg queue [] logs exchange amq.gen-vso0PVvyiRIL2WoV3i48Yg queue [] ...done. ————翁英健 本文地址：http://wengyingjian.github.io/2015/12/30/rabbitmq-workqueues/ -End-","tags":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"http://yoursite.com/tags/rabbitmq/"},{"name":"消息队列","slug":"消息队列","permalink":"http://yoursite.com/tags/消息队列/"}]},{"title":"Rabbitmq（二）－远程连接失败问题","date":"2015-12-29T16:00:00.000Z","path":"2015/12/30/rabbitmq-qa-remote/","text":"上一篇讲（翻译）了在localhost的Hello World http://wengyingjian.github.io/2015/12/30/rabbitmq-helloworld/ 其实localhost环境上我也没试过，因为我的mq是直接装在远程服务器的，而java程序就在自己的pc机上执行。但是这一执行就出问题了，下面来看看这个问题。 问题 查找问题找日志文件。根据上一篇讲的，默认的日志存放在/var/log/rabbitmq/目录下。但是这个目录下有很多的文件，到底是哪个呢，看看最近的修改时间即可。 查看一下打印的是啥错误： 说是“guest”这个用户只支持localhost登陆。 解决问题解决方案：https://www.rabbitmq.com/access-control.html 我们可以修改一下rabbitmq.config文件，不限制guest用户的登陆。 配置文件的读取默认情况下，rabbitmq会去读取/etc/rabbitmq/rabbitmq.config这个文件。前提是/etc/rabbitmq/rabbitmq-env.conf文件中没有指定CONFIG_FILE的key。如果你希望rabbitmq读取的是/etc/rabbitmq/rabbitmq.config文件，有两种选择： 默认读取。 /etc/rabbitmq/rabbitmq-env.conf中指定CONFIG_FILE=/etc/rabbitmq/rabbitmq。千万注意，此处的”.config”后缀会自动添加。 配置文件的修改/etc/rabbitmq/rabbitmq.conf文件中应该有的内容： [{rabbit, [{loopback_users, []}]}]. 以上，不多也不少。 如果你的rabbitmq.conf文件是跟我一样从/usr/share/doc/rabbitmq-server/rabbitmq.config.example.gz里面读取出来的。那么编辑rabbitmq.conf，找到loopback_users ，注释掉那行。然后保存，重启。 其它的问题启动的时候失败了：失败了就看日志，发现是”]”附近哪里写错了。再回去看rabbitmq.config发现是多了一个逗号。最后是这个样子的： 改了没反应改了没反应，一般是因为rabbitmq找到rabbit-env.config里面的配置文件设置，然后再去找这个配置文件，结果没找到，于是就使用默认的配置了。 最后整理一下/etc/rabbitmq/目录下只需要一个文件&lt;rabbit.config。文件里面只需要以下内容： [{rabbit, [{loopback_users, []}]}]. ————翁英健 本文地址：http://wengyingjian.github.io/2015/12/30/rabbitmq-helloworld/ -End-","tags":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"http://yoursite.com/tags/rabbitmq/"},{"name":"消息队列","slug":"消息队列","permalink":"http://yoursite.com/tags/消息队列/"}]},{"title":"Rabbitmq（一）－Hello World","date":"2015-12-29T16:00:00.000Z","path":"2015/12/30/rabbitmq-helloworld/","text":"翻译自：https://www.rabbitmq.com/tutorials/tutorial-one-java.html整理过的源代码(java-maven,helloworld-package)：https://github.com/wengyingjian/rabbitmq-tutorial.git 须知本教程默认rabbitmq安装在localhost，默认的端口（5672）。如果有改动，则需调整。rabbitmq安装:http://wengyingjian.github.io/2015/12/30/server-rabbitmq-init/ 介绍RabbitMQ是一个消息传送者。它的目的非常明确：接受消息与传递消息。你可以把它想象成一个邮局：你把邮件丢到邮箱里面，那就能够明确保证最终邮件会被送到目的地。打个比方来说：RabbitMQ就是一个邮箱、邮局加上邮递员。RabbitMQ与邮局卫衣的区别就是mq它传递的不是信封，而是二进制的数据－信息。 术语RabbitMQ，以及一些常用的消息队列，都会使用到一些术语： 生产者（Producer）：负责发送消息的那个的程序就叫做生产者。我们用“P”来代表生产者，如下： 队列（Queue）就是邮箱的意思，就在RabbitMQ之中。尽管信息在RabbitMQ和应用程序之间来回传递，信息也是可以存放在队列（queue）之中的。队列的大小是没有限制的，你想要往里面存多少东西都可以。可以有很多很多的生产者（Producer）往同一个队列里面发送消息，也可以有很多很多的消费者（Consumer）从同一个队列里面取数据。队列的画法如下： 消费可以就把它理解为接收（数据）的意思。负责等待接收数据的程序我们把它叫做消费者（Consumer）。画法如下： 注意：生产者（Producer），消费者（Consumer），队列（Queue）不需要保证在同一台机器上。而且在大多数的应用中它们都不是在同一台机器上的。 Hello World!(通过java客户端实现)在本教程里面，我们将会用Java写两个程序：一个用于发送消息的生产者，和一个用于接收消息并且把消息打印出来的消费者。当然也会有注释。 示意图中，“P”就是生产者，“C”就是消费者。中间的匣子就是队列－RabbitMQ的缓冲区。 Java客户端jar包我们就从这里下载库包，然后检查签名。解压到工作区，然后拿过去用。。。 $ unzip rabbitmq-java-client-bin-*.zip $ cp rabbitmq-java-client-bin-*/*.jar ./ RabbitMQ的Java客户端在Maven中央仓库也有，groupId为com.rabbitmq，artifactId为 amqp-client 。（这里为就用maven项目来做了） 下面开始写代码。 生产者 我们会调用消息发送者去发送消息，消息接受者去接收消息。那么作为发送者，它要做的就是连上RabbitMQ，发送一个消息，然后退出。 在Send.java中，需要引入以下的包： import com.rabbitmq.client.ConnectionFactory; import com.rabbitmq.client.Connection; import com.rabbitmq.client.Channel; 设置queue的名字： public class Send { private final static String QUEUE_NAME = &quot;hello&quot;; public static void main(String[] argv) throws java.io.IOException { ... } } 然后创建一个与server的连接： ConnectionFactory factory = new ConnectionFactory(); factory.setHost(&quot;localhost&quot;); Connection connection = factory.newConnection(); Channel channel = connection.createChannel(); 这个Connection将scoket连接抽象化，帮我们完成了协议的认证、授权等等步骤。这里，我们建立了与localhost的消息传送者的连接。如果我们需要建立远程的连接，用ip地址替代掉”localhost”即可。下一步需要创建一个Channel，大多数的API都在这个接口上。必须声明要发送到哪个队列，然后才能够将消息发布出去： channel.queueDeclare(QUEUE_NAME, false, false, false, null); String message = &quot;Hello World!&quot;; channel.basicPublish(&quot;&quot;, QUEUE_NAME, null, message.getBytes()); System.out.println(&quot; [x] Sent &apos;&quot; + message + &quot;&apos;&quot;); 声明的queue只有在它不存在的时候才会被新建。消息的内容是一个byte数组，所以你随便怎么编码都行。最终，记得关闭连接： channel.close(); connection.close(); Send.java点击此处 什么，发送不了？如果你是第一次使用RabbitMQ，而且你并没有看到控制台打印”Send”消息，那么就会想到底哪里出了问题呢？有可能是消息传送者开启了，但是没有足够的剩余磁盘空间（默认来说它是需要至少1GB的空闲磁盘的），所以它就拒绝接收消息了。检查一下消息发送者的日志文件确认一下问题，如果必要的话可以减少一下空闲磁盘的要求。配置说明文档可以帮助你设置 disk_free_limit 参数。 消费者生产者的事已经完成了。消费者和生产者不大一样：生产者发送一下消息就好了，而消费者需要一直监听着，查看有没有新的消息过来，然后把消息打印出来。 Recv.java文件引入的类核Send差不多： import com.rabbitmq.client.ConnectionFactory; import com.rabbitmq.client.Connection; import com.rabbitmq.client.Channel; import com.rabbitmq.client.Consumer; import com.rabbitmq.client.DefaultConsumer; 这个额外的DefaultConsumer是Consumer接口的一个实现类，我们将用它来缓存服务器推送给我们消息。同样的代码： public class Recv { private final static String QUEUE_NAME = &quot;hello&quot;; public static void main(String[] argv) throws java.io.IOException, java.lang.InterruptedException { ConnectionFactory factory = new ConnectionFactory(); factory.setHost(&quot;localhost&quot;); Connection connection = factory.newConnection(); Channel channel = connection.createChannel(); channel.queueDeclare(QUEUE_NAME, false, false, false, null); System.out.println(&quot; [*] Waiting for messages. To exit press CTRL+C&quot;); ... } } 注意，我们在这里也声明了queue。因为我们很有可能是在sender程序运行之前就开始监听。也就是说Recv.java很可能是先运行的，所以我们需要保证这个queue是存在的。另外还要告诉服务器把消息从队列中传送过来。因为服务器过来的消息是异步的，所以我们提供了回调函数，在我们使用它们之前消息都会被先缓存起来。这就是DefaultConsumer实现类做的事情： Consumer consumer = new DefaultConsumer(channel) { @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException { String message = new String(body, &quot;UTF-8&quot;); System.out.println(&quot; [x] Received &apos;&quot; + message + &quot;&apos;&quot;); } }; channel.basicConsume(QUEUE_NAME, true, consumer); Recv.java点击此处 java程序怎么运行的我就不说了。。 ————翁英健 本文地址：http://wengyingjian.github.io/2015/12/30/rabbitmq-helloworld/ -End-","tags":[{"name":"helloWorld","slug":"helloWorld","permalink":"http://yoursite.com/tags/helloWorld/"},{"name":"rabbitmq","slug":"rabbitmq","permalink":"http://yoursite.com/tags/rabbitmq/"},{"name":"消息队列","slug":"消息队列","permalink":"http://yoursite.com/tags/消息队列/"}]},{"title":"Rabbitmq（三）－Work Queues","date":"2015-12-29T16:00:00.000Z","path":"2015/12/30/rabbitmq-workqueues/","text":"翻译自：https://www.rabbitmq.com/tutorials/tutorial-two-java.html整理过的源代码(java-maven,workqueues-package)：https://github.com/wengyingjian/rabbitmq-tutorial.git Work Queues(通过java客户端实现) 在第一篇教程中我们写了从队列中发送和读取消息的程序。本篇我们将创建一个Work Queue来将消息分发给消费者，当然这里的环境是有多个消费者的。使用Work Queue的主要目的是为了防止任务过于密集导致长时间的等待。取而代之的是我们把这些任务给编排好顺序，然后放着慢慢执行。我们把这个任务抽象为一个message来表示，然后再将message发送到queue当中。在后台运行的worker进程将会从queue中一个个取出任务，并且保证最终所有的任务都会被执行掉。当后台有多个worker进程的时候，这些任务由它们共同协作完成。这个概念在web应用中是尤其有用的，因为我们不可能在极短的http请求中完成一些非常复杂的任务。 准备在上一篇教程中，我们发送一个一个内容为”Hello World!”的字符串消息。现在我们要发送一些代表着复杂的任务的消息，然而我们并没有啥复杂的任务，但是为了模仿的像，就用Thread.sleep()函数来代替。我们就用符号.在字符串中出现的次数来表示任务的复杂度。举个例子，一个虚拟的任务Hello…就需要花费3秒钟时间。 然后需要略微的修改一下Send.java文件，允许消息的输入能够从命令行中读取。该程序将会把任务自动放入到工作队列中，所以就给这个命名为NewTask.java吧。。 String message = getMessage(argv); channel.basicPublish(&quot;&quot;, &quot;hello&quot;, null, message.getBytes()); System.out.println(&quot; [x] Sent &apos;&quot; + message + &quot;&apos;&quot;); 从命令行获取数据 private static String getMessage(String[] strings){ if (strings.length &lt; 1) return &quot;Hello World!&quot;; return joinStrings(strings, &quot; &quot;); } private static String joinStrings(String[] strings, String delimiter) { int length = strings.length; if (length == 0) return &quot;&quot;; StringBuilder words = new StringBuilder(strings[0]); for (int i = 1; i &lt; length; i++) { words.append(delimiter).append(strings[i]); } return words.toString(); } 旧的Recv.java程序也同样需要一些改动：根据字符串中.符号模拟出执行任务所需的时间来会处理传递过来的任务，将它命名为Worker.java final Consumer consumer = new DefaultConsumer(channel) { @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException { String message = new String(body, &quot;UTF-8&quot;); System.out.println(&quot; [x] Received &apos;&quot; + message + &quot;&apos;&quot;); try { doWork(message); } finally { System.out.println(&quot; [x] Done&quot;); } } }; channel.basicConsume(TASK_QUEUE_NAME, true, consumer); 模拟执行时间： private static void doWork(String task) throws InterruptedException { for (char ch: task.toCharArray()) { if (ch == &apos;.&apos;) Thread.sleep(1000); } } 测试使用任务队列最大的好处之一就是他能够轻松将业务并行执行。比如说我们需要统计一个程序的后台日志，那么只需要将要统计的日志发送到队列，然后添加几个worker来处理完成这些任务即可。首先，我们先将2个worker进程跑起来。我这里用的是eclipse，所以右键Worker.java选择”Run As Java Application”即可,跑2次。 两个程序控制台显示的应该都是一样的： 然后，在让NewTask.java制造一些任务出来。同样的方法，run一次NewTask.java。然后在设置run参数再跑一次，具体方法如下： 选择”Run Configurations” 设置参数左边选择”NewTask”这个类，右边选择”Arguments”，然后输入内容，为了防止手速过慢，多加几个点，一个点就是一秒。然后多运行几次，分别为task 2,3,4,5,6。。。 消费者端打印的日志基本是这样的： 默认的情况下，RabbitMQ会把每个消息以序列化的形式发送下一个消费者。平均的来说，每个消费者会得到相同数量的消息。这种分发消息的机制叫做”round-robin”。 消息感知（消费者挂了咋整）消费者拿到消息以后执行任务是需要时间的。那么，如果在执行的时候消费者程序挂了怎么办，这下这个任务可就失踪了啊。以我们目前的代码来看，一旦RabbitMQ将消息传送给消费者，那么这个消息就从队列内存中移除了。这种情况下，如果你把消费者进程给杀了，这个消息就消失了。总之，所有的这类从队列给到消费者，而消费者挂掉未能完成任务的消息都将失效，这是我们不想看到的。 我们想要达到的目的是，如果一个消费者挂掉了，而他手头的工作还没做完，那么由其它的消费者来代替他完成。总之任务必须完成。为了达到这个目的，RabbitMQ支持消息感知。实现方式如下：如果消费者完成了某个任务，就给队列返回一个ack信号。当队列接收到这个返回的信号了以后，说明这个任务是完成了的，此时才将这个任务真正的从队列中移除。 如果一个消费者在处理任务的时候挂掉了，导致没能返回ack信号，RabbitMQ会知道这个任务并没有被完全执行，所以会把这个任务再分发给其它的消费者。这样，即使工作中的消费者挂掉了，也能够确保所有消息准确无误的完成。这里并不需要设置任务执行的超时时间，如果消费者进程挂了，RabbitMQ会自动重新分发改消息。而在消费者进程没有挂的情况下，无论这个任务它执行了多久，都是被认为是没有问题的。 消息感知默认状态是开启的。在上面的例子中我们通过autoAck=true故意把它给关闭了。现在我们把它移出掉，这样就算消费者出了问题也不怕了。 channel.basicQos(1); final Consumer consumer = new DefaultConsumer(channel) { @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException { String message = new String(body, &quot;UTF-8&quot;); System.out.println(&quot; [x] Received &apos;&quot; + message + &quot;&apos;&quot;); try { doWork(message); } finally { System.out.println(&quot; [x] Done&quot;); channel.basicAck(envelope.getDeliveryTag(), false); } } }; 忘记感知回馈还是很容易会忘记在finally代码段里面填上感知回馈的，而且这样造成的后果也是极其严重的：当你的客户端退出的时候，消息就被重新分发了（而这看上去却像是random的重分发），这样RabbitMQ会消耗越来越多的内存，因为它没有收到”ack“回应，也不好释放队列中的消息。 为了能够调试该问题，可以使用rabbitmqctl来打印出未收到ack回应的一些消息的。 $ sudo rabbitmqctl list_queues name messages_ready messages_unacknowledged Listing queues ... hello 0 0 ...done. 消息持久化（MQ队列挂了咋整）现在考虑到了消费者挂了的情况，为了保证消息不丢失，我们也对该情况有了不错的解决方案。但是，如果RabbitMQ服务器挂掉了呢，咋整？ RabbitMQ要是挂掉了的话，所有在队列都没了，队列里面的消息就全丢失了。因为它们都存放在内存当中的嘛，所以解决方案就有了：把它们持久化到硬盘上。 首先我们要保证RabbitMQ不会丢失队列。为此，我们需要如下的代码来设置持久化： boolean durable = true; channel.queueDeclare(&quot;hello&quot;, durable, false, false, null); 嗯，这样的代码看上去是对的。但是如果你运行一下就会发现问题。问题出在哪呢？我们已经有了一个叫做“hello”的队列（在上面的demo中），而RabbitMQ不允许同样的队列拥有不同的配置，所以就报错了。因此我们需要换一个队列： boolean durable = true; channel.queueDeclare(&quot;task_queue&quot;, durable, false, false, null); 这种queue的设置在生产者和消费者两端都要设置。 这个时候我们已经确保了”task_queue”这个队列不会丢失了，即使RabbitMQ重启了。然而里面的消息并没有，所以我们还需要把传递的消息标记为持久化的，这个通过设置实现了BasicProperties接口的MessageProperties类中的 PERSISTENT_TEXT_PLAIN 属性来指定： import com.rabbitmq.client.MessageProperties; channel.basicPublish(&quot;&quot;, &quot;task_queue&quot;, MessageProperties.PERSISTENT_TEXT_PLAIN, message.getBytes()); 关于消息持久化需要注意的点标记消息持久化并不能完全的确保消息就一定不会丢失了。尽管RabbitMQ收到持久化消息到硬盘上的指令了，然而数据保存到硬盘上是需要时间的。也就是说在RabbitMQ接收到消息以后，持久化完成之前挂掉了，那消息还是丢失了。但是对于正常的使用来说，这样已经足够了。如果需要确保任务万无一失，那么可以参照publisher confirms 公正地分发你可能发现RabbitMQ分发消息的的方法和我们希望的并不完全一样。比如在一个有2个消费者的场景中，有的任务耗时很长，有的任务耗时很短，其中一个消费者已经累的执行不过来任务了，另外一个消费还在悠闲的没事情干。然而RabbitMQ并不知道这两个消费者谁忙谁闲，所以只能够平均的把任务分发给两个消费者来干。 导致这个问题的原因是RabbitMQ在消息进来的时候只负责分发消息，并不管到底消费者返回了多少个”ack”的消息。所以MQ一直盲目地把第n个消息分发给第n个消费者。 为了解决这个问题，我们可以使用 basicQos 方法，设置为prefetchCount = 1 。其实就是告诉RabbitMQ，不要一次性给消费者超过1个任务。换句话说，不再给某个消费者分发任务，直到这个消费者完成了手头的工作，并且给MQ返回”ack”消息了。这样，RabbitMQ就能够确保任务分发到的消费者肯定是空闲着的。 int prefetchCount = 1; channel.basicQos(prefetchCount); 关于queue size需要注意的点如果所有的消费者都很忙，那么你的queue队列很有可能会被填满。那么你就要注意了，要么多添加一些消费者，或者采用其它的措施。 综上，写代码(NewTask.java source)(Worker.java source) 想要了解更多的 Channel 或者是 MessageProperties 相关的方法的，请查看java文档 ————翁英健 本文地址：http://wengyingjian.github.io/2015/12/30/rabbitmq-workqueues/ -End-","tags":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"http://yoursite.com/tags/rabbitmq/"},{"name":"消息队列","slug":"消息队列","permalink":"http://yoursite.com/tags/消息队列/"}]},{"title":"服务器搭建（九）－Rabbitmq的安装配置","date":"2015-12-29T16:00:00.000Z","path":"2015/12/30/server-rabbitmq-init/","text":"资源官网上都有，就是英文瞅着怪累的。所以总结一下。 安装不同的系统，不同的安装方法：https://www.rabbitmq.com/download.html 下面就说下Debian/Ubuntu系统，我找到方法如下：https://www.rabbitmq.com/install-debian.html具体找的是： 下面，请允许我用蹩脚的英语来翻译一遍：1.要让apt-get命令能够下载这个资源，将这个资源加入其列表，即/etc/apt/sources.list文件。 echo &quot;deb http://www.rabbitmq.com/debian/ testing main&quot; &gt;&gt; /etc/apt/sources.list 2.为了防止警告啥的问题，将他们的公钥放到“信任的公钥”列表。 wget https://www.rabbitmq.com/rabbitmq-signing-key-public.asc sudo apt-key add rabbitmq-signing-key-public.asc 3.更新apt-get apt-get update 4.安装rabbitmq sudo apt-get install rabbitmq-server 安装完了就自动启动了 service rabbitmq-server status service rabbitmq-server stop service rabbitmq-server start 配置一些文件的默认位置https://www.rabbitmq.com/relocate.html这里只贴unix的，其它系统的在上面链接中也有。 配置文件https://www.rabbitmq.com/configure.html 1.环境变量文件:/etc/rabbitmq/rabbitmq-env.conf默认是没有的，需要自己创建。模版： #example rabbitmq-env.conf file entries #Rename the node NODENAME=bunny@myhost #Config file location for rabbitmq.config CONFIG_FILE=/etc/rabbitmq/rabbitmq 更多rabbitmq-env.conf相关信息：https://www.rabbitmq.com/man/rabbitmq-env.conf.5.man.html 2.环境变量设置 环境变量的优先级：首先采用命令行中shell的参数配置；其次采用rabbitmq-env.conf的配置；最后使用系统默认的配置。 一些变量： 3.rabbitmq.config文件配置https://www.rabbitmq.com/configure.html#configuration-file要求是erlang规范的，我也不会。模版：在/usr/share/doc/rabbitmq-server或者/usr/share/doc/rabbitmq-server-3.6.0/我这看到的是.gz的文件，所以把里面的内容放到/etc/rabbitmq/rabbitmq.config.example里面。 ————翁英健 本文地址：http://wengyingjian.github.io/2015/12/30/server-rabbitmq-init/ -End-","tags":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"http://yoursite.com/tags/rabbitmq/"},{"name":"消息队列","slug":"消息队列","permalink":"http://yoursite.com/tags/消息队列/"},{"name":"服务器","slug":"服务器","permalink":"http://yoursite.com/tags/服务器/"}]},{"title":"Github Page绑定自己的域名","date":"2015-12-28T16:00:00.000Z","path":"2015/12/29/Jekyll-bind-site/","text":"最近申请了一个（阿里云）域名，所以准备将自己的github.io的博客放到自己的域名下。跟着网上的教程做的时候遇到了不少的问题。最后终于成功了，这里整理一下。 域名解析处设置下面就拿我自己的域名举例。我的github page地址为http://wengyingjian.github.io，申请来的域名为http://wengyingjian.com。 登录域名解析的网站设置域名解析。拿阿里云的举例： 登录云服务器管理控制台，域名在这个地方。然后找到解析的入口 点击“解析”以后进入新的页面，找到下面的“添加解析”。 然后选择对应的参数：记录类型选”CNAME”,主机记录填”@”,记录值填上自己的github page地址。别忘了后面要多加一个”.”，我填的就是wengyingjian.github.io. 好了点击保存。如果显示成功那么这一步就算完成了，等待生效即可。但是默认情况下会报错，是不是出现了这样类似的错误？如果是的话，把下面主机记录带为”@”的解析全给删了就行了。 Github.io项目处设置找找项目的根路径，是不是有一个叫做CNAME的文件。里面存放的是这个项目能够被访问到的域名。我之前的是wengyingjian.github.io，现在要改成wengyingjian.com。不然就会404等着我。 关于CNAME常见的问题之前fork其它人的github page模版的时候，老是出现404。现在知道了，是忘记修改CNAME这个文件了。 ————翁英健 本文地址：http://wengyingjian.github.io/2015/12/29/Jekyll-bind-site/ -End-","tags":[{"name":"github","slug":"github","permalink":"http://yoursite.com/tags/github/"},{"name":"jekyll","slug":"jekyll","permalink":"http://yoursite.com/tags/jekyll/"},{"name":"域名","slug":"域名","permalink":"http://yoursite.com/tags/域名/"}]},{"title":"java性能优化（二）－gc日志收集与分析","date":"2015-12-28T16:00:00.000Z","path":"2015/12/29/java-performance-gclog/","text":"使用jvisualvm与jconsole能够实时监控java程序的运行状态。但是我们并不会一直盯着输入屏幕，或者说开着一个客户端一直抓取服务器的运行信息。相对来说，能够让java程序在运行的时候自动生成日志，然后我们再对生成的数据进行分析是比较不错的选择。 收集日志打印Gc日志的参数打印gc详细信息 -XX:+PringGCDetails 带有距离JVM开始运行的时间戳 -XX:+PrintGCTimeStamps 带有日历时间戳 -XX:+PringGCDateStamps 指定gc日志存放文件（不指定则控制台打印） -Xloggc:&lt;filename&gt; 针对高延迟问题调优HotSpot VM时，下面两个命令行选项特别有用，通过它们可以获得应用程序由于执行VM安全操作而阻塞的时间以及两个安全点操作之间应用程序运行的时间。 -XX:+PrintGCApplicationStoppedTime -XX:+PrintGCApplicationConcurrentTime 何谓安全操作：安全操作使JVM进入到一种状态：所有的java应用线程都被阻塞、执行本地代码的线程都被禁止返回VM执行Java代码。安全操作常用于虚拟机需要进行内部操作时，此时所有的Java线程都被显式地置于阻塞状态且不能修改Java堆的情况。 设置参数Tomcat$CATALINA_HOME/bin/setenv.sh文件加入： #opts for gc log export CATALINA_OPTS=&quot;$CATALINA_OPTS -XX:+PrintGCDetails&quot; export CATALINA_OPTS=&quot;$CATALINA_OPTS -XX:+PrintGCTimeStamps&quot; export CATALINA_OPTS=&quot;$CATALINA_OPTS -XX:+PrintGCDateStamps&quot; export CATALINA_OPTS=&quot;$CATALINA_OPTS -Xloggc:/gc_logs/tomcat.gc.log&quot; 当然，loggc的文件能够自给创建，目录得先创建好。 下同 Nexus$NEXUS_HOME/bin/jsw/conf/wrapper.conf文件 Jenkins/etc/default/jenkins文件。 从服务器获取日志文件使用scp命令。在客户端机器上： scp root@host:file_path local_dest 分析日志拿到了日志，拿眼睛看也是怪累的，而且不拿本教程对着看各个参数时什么意思还真不怎么看得懂。过段时间又忘了什么意思。。。 关键时“海量”的数据，眼睛哪看的过来，还需需要将日志转化成像jconsole、jvisualvm一样的图形化看着才方便。 gchistro这个工具好像听说比较强大，所以我也写上。 工程的地址在：https://java.net/projects/gchistosvn源码放在：https://svn.java.net/svn/gchisto~svn 但是我并不用svn，所以源码还是找我用svn的同学要过来的。因为里面引用的一些包没有，也懒得去下载。所以我把它转化成了一个maven项目，很不要脸的放在我的github上：https://github.com/wengyingjian/gchisto 然而，虽然它强大，但是我用它分析日志的时候并没有识别出来。我现在也没搞清楚是哪里出了问题，更加详细的情况是这样的：https://www.zhihu.com/question/38970263如果有会用的前辈还请指导指导。 gceasy推荐一个分析gc日志的网址：http://gceasy.io/只要上传日志文件就能够给出好多有用的分析数据出来。感觉还是很好用的。后面还会根据这个网站的日志分析做出性能调优。 ————翁英健 本文地址：http://wengyingjian.github.io/2015/12/29/java-performance-gclog/ -End-","tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"},{"name":"jvm","slug":"jvm","permalink":"http://yoursite.com/tags/jvm/"},{"name":"性能","slug":"性能","permalink":"http://yoursite.com/tags/性能/"},{"name":"内存","slug":"内存","permalink":"http://yoursite.com/tags/内存/"}]},{"title":"服务器搭建（七）－Jenkins的安装配置","date":"2015-12-27T16:00:00.000Z","path":"2015/12/28/server-jenkins-init/","text":"Hudson与Jenkinswiki:https://en.wikipedia.org/wiki/Jenkins_(software))Jenkins是从Hudson fork过来继续开发的。两者属于不同的分支，现在都保持着各自的更新。Jenkins是开源的，而Hudson以后可能会走向商业。 Jenkins安装https://wiki.jenkins-ci.org/display/JENKINS/Installing+Jenkins+on+Ubuntu懒得看英文的看下面： 安装wget -q -O - https://jenkins-ci.org/debian/jenkins-ci.org.key | sudo apt-key add - sudo sh -c &apos;echo deb http://pkg.jenkins-ci.org/debian binary/ &gt; /etc/apt/sources.list.d/jenkins.list&apos; sudo apt-get update sudo apt-get install jenkins 稍微解释下： 将Debian仓库包的key添加到系统（apt-key），用于自动化安装与更新。 将deb http://pkg.jenkins-ci.org/debian binary/添加至/etc/apt/sources.list文件中。 更新本地的包索引。 安装。 如果中间出错了先别管它，看下面的 安装所完成的事情(简） 安装Jenkins到机器。 添加Jenkins到service，开机自启动。 启动Jenkins。 如果安装成功，可以访问http://host:8080查看 更新sudo apt-get update sudo apt-get install jenkins 说明开机自启详细流程通过/etc/init.d/jenkins文件控制。 用户有个叫做“jenkins”的用户被自动创建了，专门用来跑Jenkins服务。 日志Jenkins相关的日志都在/var/log/jenkins/jenkins.log。所以在Jenkins中遇到了问题都可以找这个日志文件查看。 配置文件/etc/default/jenkins 端口默认是8080端口，所以如果你的tomcat也用了8080还启动了。在之前的安装过程中是会出现异常的。 修改端口 /etc/init.d/jenkins：在这里会对端口进行检查（开机自启）。需要修改下。 /etc/default/jenkins：这个是真正决定开启哪个端口的配置。也要修改。 问题：之前尝试了80端口，结果启动失败了。看了日志发现是权限不足。查了后发现原来linux对1024以下的端口有限制，只有root用户组才能启用。 ————翁英健 本文地址：http://wengyingjian.github.io/2015/12/28/server-jenkins-init/ -End-","tags":[{"name":"服务器","slug":"服务器","permalink":"http://yoursite.com/tags/服务器/"},{"name":"jenkins","slug":"jenkins","permalink":"http://yoursite.com/tags/jenkins/"},{"name":"maven","slug":"maven","permalink":"http://yoursite.com/tags/maven/"}]},{"title":"服务器搭建（八）－Jenkins集成demo","date":"2015-12-27T16:00:00.000Z","path":"2015/12/28/server-jenkins-demo/","text":"Jenkins与Hudson基本都是一样的。所以，参照：http://wengyingjian.github.io/2015/12/26/server-hudson-demo/ 有一个问题提一下在写上了git的ssh地址以后出现这个以下的提示： 嗯，是因为github那边没有本地的SSH公钥保存，不认识。 为什么呢，还记得http://wengyingjian.github.io/2015/12/28/server-jenkins-init/中提到jenkins是由jenkins用户运行的而非root。之前添加到github的ssh-key是root的。 所以，生成jenkins的公钥，放到github上。 ————翁英健 本文地址：http://wengyingjian.github.io/2015/12/28/server-jenkins-demo/ -End-","tags":[{"name":"服务器","slug":"服务器","permalink":"http://yoursite.com/tags/服务器/"},{"name":"jenkins","slug":"jenkins","permalink":"http://yoursite.com/tags/jenkins/"},{"name":"maven","slug":"maven","permalink":"http://yoursite.com/tags/maven/"}]},{"title":"Jenkins集成报错－用户权限问题","date":"2015-12-27T16:00:00.000Z","path":"2015/12/28/jenkins-qa-permission/","text":"在http://wengyingjian.github.io/2015/12/28/server-jenkins-init/我们安装配置好了Jenkins，并且知道jenkins是由一个叫做jenkins的用户运行的，而非root。在http://wengyingjian.github.io/2015/12/28/server-jenkins-demo/中集成的时候也遇到了关于用户的问题，并且解决了。 这次我在另外一台服务器上使用jenkins的时候出现了一个新的问题，也是关于jenkins用户的，还涉及到了权限。 问题表示checkout的时候权限不足。 原因为什么会权限不足呢，我也好奇怪，于是决定手动来试试。找到项目的git地址。然后手动执行一遍git指令试试：显示了同样的错误，的确是权限不足。参考了http://stackoverflow.com/questions/6692292/git-commit-problem-unable-to-append-to-git和http://stackoverflow.com/questions/2642836/git-error-unable-to-append-to-git-logs-refs-remotes-origin-master-permission的问题后，发现的确是出现了root用户的文件。 解决没办法，只好修改文件所有者了。切换到root后修改。完成后再checkout。OK成功。 还如何自动化感觉这下麻烦了，好好的jenkins在弄git的时候突然多出一个root才能搞得动的文件出来，然后自己还要用到。总不能每次都让我手动去修改吧。于是想从网上查找解决方案的，可惜没找到。再自己clone了一次，发现logs又还是jenkins所有的。 这次就当是基因突变了吧。。下次要是还遇到这个问题再说。。————翁英健 本文地址：http://wengyingjian.github.io/2015/12/28/jenkins-qa-permission/ -End-","tags":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"},{"name":"服务器","slug":"服务器","permalink":"http://yoursite.com/tags/服务器/"},{"name":"jenkins","slug":"jenkins","permalink":"http://yoursite.com/tags/jenkins/"},{"name":"git","slug":"git","permalink":"http://yoursite.com/tags/git/"}]},{"title":"java性能优化（一）－远程监测","date":"2015-12-26T16:00:00.000Z","path":"2015/12/27/java-performance-trace/","text":"昨天在服务器上搭建了hudson,sonatype nexus以后，整个服务器都不好了。卡的要死，tomcat都因为内存不足而自动关闭。 服务器信息配置 ubuntu-641G内存1CPU 虽然1G内存完全用不到64位，但是我也不知道我怎么就选了64位的系统。。 情况 超级卡，输入命令的时候都特别慢。 卡到瓶颈了tomcat就挂了，日志显示内存不足。 卡的时候ssh都连接不上，没有多余的内存来处理ssh了。只能在控制台重启。tomcat、nexus等我都设置成了开机自启，我甚至担心一启动内存又满了一直连不上。 然而cpu，网络啥的都没问题 查找问题 首先我用free命令查看了下，发现剩余空闲的内存就几十兆了。 然后用top命令查看了下，java占去了大部分的内存。其中tomcat，hudson，nexus用的都是java。尤其是tomcat，上面显示占了40+%的内存。 解决思路于是我就想，是不是可以通过控制java垃圾回收来达到优化内存的目的。我这1G内存的确是小了，加上默认的堆大小配置，所以问题应该是出在这里。 下面，当然是要先监控java内存了。之前用过jconsole和jvisualvm，但是只试过监测本地进程的。 监测Tomcat这个网上的方法可多了，我今天也调了一个上午，最后终于成功。 最简单的方法 $CATALINA_HOME/bin目录下新建setenv.sh文件 touch $CATALINA_HOME/bin/setenv.sh 文件中写入以下内容，保存重启tomcat export CATALINA_OPTS=”$CATALINA_OPTS -Djava.rmi.server.hostname=your-server-host-here” export CATALINA_OPTS=”$CATALINA_OPTS -Dcom.sun.management.jmxremote.port=8888” export CATALINA_OPTS=”$CATALINA_OPTS -Dcom.sun.management.jmxremote.ssl=false” export CATALINA_OPTS=”$CATALINA_OPTS -Dcom.sun.management.jmxremote.authenticate=false” echo “Using CATALINA_OPTS:$CATALINA_OPTS” 启动jconsole，在$JAVA_HOME/bin/目录下。选择远程host:port，账号密码不管它，连接即可。 一些说明Q:为什么是setenv.sh文件？A:我们知道tomcat启动调用的是bin/startup.sh脚本，然后又调用bin/catalina.sh脚本，所以我们打开bin/catalina.sh，里面有说明： Q:CATALINA_HOME与CATALINA_BASE一样吗？A:整个tomcat的目录我们可以根据作用把他们分为2个部分：1.支撑tomcat运行起来的，有bin、lib；2.用来运行app的，有conf、webapps。所以，可以在一台服务器上运行多个tomcat实例，但是公用一个tomcat，里面的bin、lib是不会变的。只需要再来一份conf、webapps等文件即可。CATALINA_HOME指向的就是bin、lib所在的目录，CATALINA_BASE指向的就是webapps、conf等所在目录。这里就一个tomcat实例，所以CATALINA_HOME、CATALINA_BASE就一样了。 Q:-Djava.rmi.server.hostname=host有什么作用？A:执行一下hostname -i发现返回的不是外网的ip。我返回的是内网的ip，网上也有返回的是127.0.0.1的。今天我出的主要的问题是远程连接的时候超时。网上有说到是因为服务器java会去找hostname -i返回的那个地址，所以就找不到了超时。如果是127.0.0.1也可以通过修改/etc/hosts来解决。但是还是在这边设置比较合理。。 其它的配置方法来到$JAVA_HOME/jre/lib/manager 这里存放的文件都是全局的java关于远程监控的配置文件。所有的java程序，都会先读这里的配置，然后再去读具体程序的具体配置。 jmxremote.password.template：这个是账户密码的模版文件，具体使用的时候就是复制过去，改改就行。里面也有说明。cp jmxremote.password.template jmxremote.password再将最后的2个帐号密码的注释去掉。但是之前我们在tomcat里面把帐号密码认证都去掉了，所以那样也可以。 management.properties:一些参数的配置都在这里了。com.sun.management.jmxremote.authenticate、com.sun.management.jmxremote.ssl这些都能在这里找到，不过这里配置的是全局的而已。 —2015-12-29补充—但是后来我试了在JAVA_HOME修改配置，但是并没有起作用。所以tomcat的话还是在setenv.sh文件中配置比较实在。 监测Nexus我的nexus安装在/usr/local/nexus-2.12.0-01/，所以我找到文件是/usr/local/nexus-2.12.0-01/bin/jsw/conf/wrapper.conf。即找到$NEXUS_HOME/bin/jsw/conf/wrapper.conf添加以下内容： wrapper.java.additional.5=-Djava.rmi.server.hostname=your_host_here wrapper.java.additional.6=-Dcom.sun.management.jmxremote.port=8888 wrapper.java.additional.7=-Dcom.sun.management.jmxremote.ssl=false wrapper.java.additional.8=-Dcom.sun.management.jmxremote.authenticate=false 当然是放在1、2、3、4后面。 监测Jenkins这里找的文件是/etc/default/jenkins。和上面的类似，加入以下的内容： #jmxremote JAVA_ARGS=&quot;$JAVA_ARGS -Dcom.sun.management.jmxremote.port=8889&quot; JAVA_ARGS=&quot;$JAVA_ARGS -Djava.rmi.server.hostname=121.42.174.165&quot; JAVA_ARGS=&quot;$JAVA_ARGS -Dcom.sun.management.jmxremote.ssl=false&quot; JAVA_ARGS=&quot;$JAVA_ARGS -Dcom.sun.management.jmxremote.authenticate=false&quot; ————翁英健 本文地址：http://wengyingjian.github.io/2015/12/27/java-performance-trace/ -End-","tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"},{"name":"jvm","slug":"jvm","permalink":"http://yoursite.com/tags/jvm/"},{"name":"性能","slug":"性能","permalink":"http://yoursite.com/tags/性能/"},{"name":"内存","slug":"内存","permalink":"http://yoursite.com/tags/内存/"}]},{"title":"服务器搭建（六）－Nexus私服的使用","date":"2015-12-26T16:00:00.000Z","path":"2015/12/27/server-nexus-demo/","text":"登录与界面nexus安装成功后，浏览器访问http://host:8081/nexus界面是这样子的：点击左上角的”LogIn”，使用默认的账号密码“admin－admin123”登录。 然后界面是这个样子的：左边多出来很多东西，点击“Repositories”可以看到一些仓库：这里一共有7个仓库，我们知道在我们用来编程的本地也有一个仓库，那么就把这8个仓库看作是8个本地的仓库放到了服务器上。 Repositories每一列显示的都是什么： Repository:仓库的名称，只是用来显示用的，叫啥都行，见名知意当然最好。 Type：repository的类型，这里有group、hosted、proxy、virtual，具体什么意思后面再说。 HealthCheck：各个仓库的健康状态。 Format：格式，maven1或者maven2的，就是版本吧。 Policy：是用来管理的Release还是Snapshot的。 Repository Status：仓库状态。 Repository Path：访问这个仓库对应的路径。 Type hosted：本地仓库，通常我们会部署自己的构件到这一类型的仓库 proxy：代理仓库，它们被用来代理远程的公共仓库，如maven中央仓库。 virtual：虚拟类型仓库的作用实际上是动态地将仓库内容格式转换，即也是为了服务maven1格式 group：仓库组，用来合并多个hosted/proxy仓库，通常我们配置maven依赖仓库组。 Nexus内置的仓库 Central: 代理Maven中央仓库 Releases: 一个策略为Release的宿主类型仓库，用来部署组织内部的发布版本构件 Snapshots: 一个策略为Snapshot的宿主类型仓库，用来部署组织内部的快照版本构件 3rd party: 一个策略为Release的宿主类型仓库，用来部署无法从公共仓库获得的第三方发布版本构件 Apache Snapshots: 一个策略为Snapshot的代理仓库，用来代理Apache Maven仓库的快照版本构件 Public Repositories:该仓库组将上述所有策略为Release的仓库聚合并通过一致的地址提供服务 下载索引选中”Central”仓库，选择”Configuration”选项卡，找到”Download Remote Indexes”，选择为true，默认为true。点击“save“保存。 然后右键”Central”仓库，选择“Repaire Index”，这样就nexus就自动下载远程的索引了。 这个可能需要等一段时间。 下载完成后，就可以试试左边的“Artifact Search“了，还有高级的”Advanced Search“。搜索方式非常多，可以根据关键字，类名，artifactId各种条件搜索。 私服的使用明确目的 本地maven能够到私服上来下载项目。 本地maven deploy的时候能将项目发布到私服上。 Nexus端建立仓库一、添加一个Hosted仓库填写主要的几项： id：就是一个仓库的身份证号。到时候会用到。 name：只是用来在这个面板上显示的，只要你看得懂。 provider：maven2 Repository Policy:只接受Release还是Snapshot也可以。 具体的可以看下框框右边的问号，鼠标放上面有提示。其它的都默认即可。弄完了保存。 二、将这个新的仓库添加到group组为什么要添加进组？因为添加进了组，客户端只要指定了这个组，就可以用到这个组里所有的仓库了。 点击”Public Repository”,选择”Configuration”，将右边的移到左边保存即可。如果右边为空，点击左上角的绿色的刷新按钮。 客户端配置访问私服一、配置从私服下载项目编辑~/.m2/settings.xml文件，如果没有，则新建。添加以下的代码： &lt;settings&gt; ... &lt;profiles&gt; &lt;profile&gt; &lt;id&gt;dev&lt;/id&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;wyj-nexus&lt;/id&gt; &lt;url&gt;http://aliyun:8081/nexus/content/groups/public/&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;/profile&gt; &lt;/profiles&gt; &lt;activeProfiles&gt; &lt;activeProfile&gt;dev&lt;/activeProfile&gt; &lt;/activeProfiles&gt; ... &lt;/settings&gt; 至于url，改成你们的私服Public Repository地址。这里将仓库先给写好，然后对应的profile叫做dev，再设置activeProfiles，告诉maven构建的时候就使用这个配置。 这个时候，已经可以从私服下载项目依赖了。 二、发布项目的私服1.还是编辑~/.m2/settings.xml,加入以下的代码 &lt;settings&gt; ... &lt;servers&gt; &lt;server&gt; &lt;id&gt;releases&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt; &lt;/server&gt; &lt;server&gt; &lt;id&gt;snapshots&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt; &lt;/server&gt; &lt;/servers&gt; ... &lt;/settings&gt; 我这里配置了2个仓库server，一个是id为releases的，一个是snapshots的。就是它们，到时候会把对应的代码放到这2个仓库对应的地方去。 2.还得再编辑项目的POM文件，加入以下代码： &lt;distributionManagement&gt; &lt;repository&gt; &lt;id&gt;releases&lt;/id&gt; &lt;name&gt;Nexus Release Repository&lt;/name&gt; &lt;url&gt;http://aliyun:8081/nexus/content/repositories/releases/&lt;/url&gt; &lt;/repository&gt; &lt;snapshotRepository&gt; &lt;id&gt;snapshots&lt;/id&gt; &lt;name&gt;Nexus Snapshot Repository&lt;/name&gt; &lt;url&gt;http://aliyun:8081/nexus/content/repositories/snapshots/&lt;/url&gt; &lt;/snapshotRepository&gt; &lt;/distributionManagement&gt; releases和snapshot分别去找不同的仓库放。 OK，运行mvn clean deploy，就能够在私服上对应仓库中找到发布上去的项目了。 其它的一些说明之前自己创建了一个仓库好像并没有用上。一般来说用用内置的几个就够了。而自己创建仓库能够加深我们对仓库一些属性的认识。 ————翁英健 本文地址：http://wengyingjian.github.io/2015/12/27/server-nexus-demo/ -End-","tags":[{"name":"服务器","slug":"服务器","permalink":"http://yoursite.com/tags/服务器/"},{"name":"maven","slug":"maven","permalink":"http://yoursite.com/tags/maven/"},{"name":"nexus","slug":"nexus","permalink":"http://yoursite.com/tags/nexus/"}]},{"title":"服务器搭建（五）－Nexus私服的安装与配置","date":"2015-12-25T16:00:00.000Z","path":"2015/12/26/server-nexus-init/","text":"1.下载nexus可是Google的亲儿子手机。所以搜索的时候一定得是sonatype nexus，不然找到手机去了。官网：http://www.sonatype.org/nexus/下载: wget https://sonatype-download.global.ssl.fastly.net/nexus/oss/nexus-2.12.0-01-bundle.tar.gz cp nexus-2.12.0-01-bundle.tar.gz /usr/local/ 2.解压配置 看到这个，我想大家应该能够猜出各个目录都是干啥的： bin目录存放一些命令的可执行文件。conf目录存放配置。lib存放依赖的包。*.txt证书与说明。logs日志目录。tmp临时产生文件的存放处。nexu：这个查看一下发现跟tomcat的web项目相似。把它看作是一个tomcat应用，它不放在tomcat下面是因为它自带了tomcat。话说之前还有nexus的war包安装形式，跟hudson一样，现在没了。。 启动nexus： bin/nexus console 看到这个问题，我就去找conf下的配置文件，结果找了半天没找到该改哪里。最后只好问google，原来这个东西在bin/nexus脚本里面。vim bin/nexus,找到#RUN_AS_USER，修改为RUN_AS_USER=root。保存后再执行bin/nexus console 访问：http://host:8081/nexus/,OK大功告成。 Nexus的一些其它命令相信这些英文足以说明对应的命令都是干啥的，再不知道，查字典。有了./nexus start，就可以在后台启动nexus了。 配置nexus为service服务官方文档献上：https://books.sonatype.com/nexus-book/reference/install-sect-service.html懒得看english的可以继续听我唠叨：1.拷贝bin/nexus到/etc/init.d目录下。 cp bin/nexus /etc/init.d/ 2.修改文件的属性 chmod 755 /etc/init.d/nexus chown root /etc/init.d/nexus 3.修改/etc/init.d/nexus文件 NEXUS_HOME=&quot;/usr/local/nexus-2.12.0-01&quot; RUN_AS_USER=root PIDDIR=&quot;/usr/local/nexus-2.12.0-01/wrapper.pidfile&quot; 4.如果没有JAVA_HOME的还得填上JAVA_HOME 原谅我不负责任的用了root，如果用其它用户，请参照官方文档。 service nexus start 奇迹般的显示了failed。不急 tail -n 100 logs/wrapper.log 显示之前设置的pidfile不存在，那就给他创建一个。再service nexus start 配置nexus开机自启在配置nexus为service服务的基础上。。由于我用的是ubuntu系统，所以centos，redhat等其它的系统还是参照上面的官方文档。 cd /etc/init.d update-rc.d nexus defaults service nexus start tail -f /usr/local/nexus/logs/wrapper.log 这东西启动非常慢，reboot马上访问不到，害得我以为设置失败了，网上查了各种方法。。 ————翁英健 本文地址：http://wengyingjian.github.io/2015/12/26/server-nexus-init/ -End-","tags":[{"name":"服务器","slug":"服务器","permalink":"http://yoursite.com/tags/服务器/"},{"name":"maven","slug":"maven","permalink":"http://yoursite.com/tags/maven/"},{"name":"nexus","slug":"nexus","permalink":"http://yoursite.com/tags/nexus/"}]},{"title":"服务器搭建（二）－ssh免密码登陆","date":"2015-12-25T16:00:00.000Z","path":"2015/12/26/server-ssh-login/","text":"ssh每次输密码也是麻烦，配置一下公钥可以实现免密码登陆，下面就来实现一下。 1.客户端机器生成公钥ssh-keygen -t rsa -P &apos;&apos; 对于所有的提示都是按回车。然后生成的公钥在~/.ssh/目录下，那个id_rsa.pub就是。这个跟git的ssh认证其实是一样的。 注意：以下的步骤都是在客户端机器上做的，但是是由于我的机器上已经有id_rsa.pub公钥的，所以在服务器上做是为了演示一遍。 复制一下公钥的内容，然后再去搞服务器。 2.服务器添加客户端公钥touch ~/.ssh/authorized_keys chmod 600 ~/.ssh/authorized_keys vim ~/.ssh/authorized_keys 粘贴进去保存即可为什么是~/.ssh/authorized_keys这个文件？虽然被注释起来了，说明这个是默认的，当然你也可以自己改下配置，然后存放到其他的文件里面去。 3.好了，效果就是这样的 4.感觉复制粘贴公钥的方法太low？ 省略之前的一些步骤客户端：复制到home目录下： scp ~/.ssh/id_rsa.pub root@host:. 服务器： cat ~/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys ————翁英健 本文地址：http://wengyingjian.github.io/2015/12/26/server-ssh-login/ -End-","tags":[{"name":"服务器","slug":"服务器","permalink":"http://yoursite.com/tags/服务器/"},{"name":"ssh","slug":"ssh","permalink":"http://yoursite.com/tags/ssh/"}]},{"title":"SpringBoot程序打包到tomcat服务器－demo","date":"2015-12-25T16:00:00.000Z","path":"2015/12/26/java-springboot-demo/","text":"最近在测试hudson持续集成。一切好像都没问题，war包发布到了webapps目录下，却不能访问。 工程地址:git@github.com:wengyingjian/test-hudson.git 一直以为是日志的问题之前因为日志的问题被蛇咬过－－http://wengyingjian.github.io/2015/12/24/java-404/所以这次看到$CATALINA_HOME/logs/catalina.out没有相关的日志输出，就觉得应该是程序挂掉。就是说，因为没有日志的原因，程序在启动的时候抛出了异常，而我们确看不到。所以才导致了404。 所以我到处去找log4j的配置文件，应该怎么写。试了好多种，都还是没有日志出来。当然更加还是404。 问题所在后来想想，这个问题说简单也简单。我也没干啥事，就是希望能够把一个spring－boot的demo项目启动起来而已。而且这个项目在本地用main方法启动是可以正常访问的。肯定是中间流程哪里出来问题。于是谷歌搜索“springboot 部署404“，最终找到了有帮助的博客：http://wiselyman.iteye.com/blog/2145442 原来springboot项目需要打成war包放到服务器下跟本地运行是不一样的，多了两步：1.pom文件添加依赖 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; 2.application类继承SpringBootServletInitializer @SpringBootApplication public class App extends SpringBootServletInitializer { public static void main(String[] args) { SpringApplication.run(App.class, args); } /** * (non-Javadoc) * * @see org.springframework.boot.context.web.SpringBootServletInitializer#configure(org.springframework.boot.builder.SpringApplicationBuilder) */ @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder builder) { return builder.sources(App.class); } } OK，这样就可以了。push，立即构建，完事。 ————翁英健 本文地址：http://wengyingjian.github.io/2015/12/26/java-springboot-demo/ -End-","tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"},{"name":"服务器","slug":"服务器","permalink":"http://yoursite.com/tags/服务器/"},{"name":"spring","slug":"spring","permalink":"http://yoursite.com/tags/spring/"}]},{"title":"服务器搭建（四）－hudson集成demo","date":"2015-12-25T16:00:00.000Z","path":"2015/12/26/server-hudson-demo/","text":"下面用hudson集成一个项目试试效果 首先得要有一个项目1.github仓库github新建一个仓库：git@github.com:wengyingjian/test-hudson.git2.新建项目，push简单的项目搭建好以后 git remote add origin git@github.com:wengyingjian/test-hudson.git //这里自己再弄个.gitignore git add --a git commit -m &quot;hudson test&quot; git push origin master 在hudson上配置 访问http://host:port/hudson 左上角“新建任务” 配置名称：hudson-test；自由风格设置自动丢弃过早的版本（保存10个）设置git仓库：设置构建触发的机制，这里的意思是10分钟检查一次，发现有更新则构建。告诉hudson构建的时候该干啥，这里告诉他调用mvn clean install关于容器部署的设置，后面再详细说下 左下角“save”。 左边菜单栏的“立即构建”。 Tomcat容器部署设置“Post-buildActions”处设置的是构建完了需要做的一些事情，如果发邮件、归档、自动部署等等。需要自动部署，一般是通过tomcat自动的manager来管理的。这个需要验证，在$CATALINA_HOME/conf/tomcat-users.xml文件里面配置即可。而且在host:port/处通过图形化也能够发布war包。 知道这个原理，就知道哪些配置是必须的了。 1.设置好tomcat管理账号密码 &lt;role rolename=&quot;manager-script&quot;/&gt; &lt;user username=&quot;hudson&quot; password=&quot;admin&quot; roles=&quot;manager-script&quot;/&gt; 2.告诉它tomcat在哪：由于我这里用的是用的同一台服务器，所以地址就是:http://localhost:80了。3.”WAR/EAR files”这个非常重要，如果配置错了，会找不到这个war包，而且关键还没有错误提示。怎么配呢，看提示：说是相对于workspace的相对路径。再看之前的日志：用cmd进去看看就知道了，原来war包就放在workspace/target/下。所以配置完了是这样的：点击“save”保存。构建成功后日志有这样的几行： 各种错误处理 查看日志构建的时候左边会出现这个框框，想要看控制台日志就点击一下右边的黑色小框框。 各种错误提示：解决：新问题解决：id_rsa.pub公钥的内容没有放到github的sshkeys中。而之前设置的git地址又是基于ssh的，所以此处认证需要加上。 提示：说明之前设置的user.email/username都无效了，只好自己敲命令设置一番了。 ————翁英健 本文地址：http://wengyingjian.github.io/2015/12/26/server-hudson-demo/ -End-","tags":[{"name":"helloWorld","slug":"helloWorld","permalink":"http://yoursite.com/tags/helloWorld/"},{"name":"服务器","slug":"服务器","permalink":"http://yoursite.com/tags/服务器/"},{"name":"hudson","slug":"hudson","permalink":"http://yoursite.com/tags/hudson/"}]},{"title":"服务器搭建（三）－hudson的配置","date":"2015-12-25T16:00:00.000Z","path":"2015/12/26/server-hudson-init/","text":"hudson（暂时）需要完成的功能： 1.自动拉取git代码2.自动maven打包3.自动发布tomcat服务器 安装插件访问http://host:8080/hudson的时候会先进入选择需要安装插件的界面。这里我选择了3个core插件，以及git、maven3、deploy to container插件。 点击右下角的install即可，开始等待。安装完成后点击finish进入首页。 如果后续需要添加插件点击“系统管理”－“管理插件” 系统设置几个我们要用到的地方配置一下。 ————翁英健 本文地址：http://wengyingjian.github.io/2015/12/26/server-hudson-init/ -End-","tags":[{"name":"服务器","slug":"服务器","permalink":"http://yoursite.com/tags/服务器/"},{"name":"hudson","slug":"hudson","permalink":"http://yoursite.com/tags/hudson/"}]},{"title":"服务器搭建（一）－基础资源的安装","date":"2015-12-24T16:00:00.000Z","path":"2015/12/25/server-init-install/","text":"前几天阿里云推送过来个广告邮件－－5折云服务器。正好最近在搞一些服务器相关的：sonatype nexus,hudson,nginx,redis等等。虽然在pc上也能搞，但是要是有个服务器肯定是不一样的。 今天搞来一个15天的阿里云试用服务器，用了一天感觉还行。然后就想把这个5折优惠券拿去用掉，结果才发现需要企业认证－－坑。还好我眼神好，看到了学生优惠，最后买了6个月的学生优惠包。下面就来分享下今天在初始化服务器上遇到的一些问题。 这里主要讲的是一些环境的安装与配置。 Java8 这里没有java8，所以想要java8还得需要其他的办法。于是从网上找到了下面的办法： 1. sudo apt-get update 2. sudo apt-get install software-properties-common python-software-properties 3. sudo add-apt-repository ppa:webupd8team/java 4. sudo apt-get install oracle-java8-installer 5. sudo apt-get install oracle-java8-set-default 这个1~5的步骤是我一步一个脚印摔出来的，一环扣一环，，还得先执行1。 最后安装成功：我记得上一台机器安装好后有JAVA_HOME的，结果这里没有。只好自己手动搞了。 vim /etc/profile 追加 #HOME--- #java export JAVA_HOME=/usr/lib/jvm/java-8-oracle/ 执行source /etc/profile 其实是成功的，但是在第二台服务器上搞的时候出现了问题：安装到一半卡住了。ctrl+c都按不了，于是我关闭了那个窗口。新建一个ssh连接去搞。结果我也不知道它锁的原理是啥，只好重启机器试试。然后是这样的：它说啥就是啥，然后我拷贝了它的命令，输入。嗯，最后好使了。 Tomcat8这个不要太熟悉。 cd /usr/local/ wget http://mirrors.noc.im/apache/tomcat/tomcat-8/v8.0.30/bin/apache-tomcat-8.0.30.tar.gz tar -zxvf apache-tomcat-8.0.30.tar.gz mv apache-tomcat-8.0.30 tomcat-8.0.30 设置一下HOME vim /etc/profile 追加 #HOME--- #tomcat export CATALINA_HOME=/usr/local/tomcat-8.0.30 执行source /etc/profile 设置开机自启 vim /etc/rc.local 在exit 0之前加入 /usr/local/tomcat-8.0.30/bin/startup.sh start Maven3我要装的是maven3版本，所以只好自己去官网找。 cd /usr/local wget http://apache.opencas.org/maven/maven-3/3.3.9/binaries/apache-maven-3.3.9-bin.tar.gz mv apache-maven-3.3.9 maven-3.3.9 配置： vim /etc/profile 追加 #HOME--- #maven export M2_HOME=/usr/local/maven-3.3.9 #PATH PATH=$M2_HOME/bin:$PATH export PATH 执行source /etc/profile&lt;/code Git我对这个比较随便。。 Hudson-latest左下角，点进去，找到链接复制。(还是国内的镜像快) wget http://mirrors.neusoft.edu.cn/eclipse/hudson/war/hudson-3.3.2.war 下载后 mv hudson-version.war $CATALINA_HOME/webapps/hudson.war 一些博客的收藏－2015-12-29补充－ redis安装：http://futeng.iteye.com/blog/2071867 mysql安装：http://blog.fens.me/linux-mysql-install/————翁英健 本文地址：http://wengyingjian.github.io/2015/12/25/server-init-install/ -End-","tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"},{"name":"服务器","slug":"服务器","permalink":"http://yoursite.com/tags/服务器/"},{"name":"git","slug":"git","permalink":"http://yoursite.com/tags/git/"},{"name":"maven","slug":"maven","permalink":"http://yoursite.com/tags/maven/"},{"name":"hudson","slug":"hudson","permalink":"http://yoursite.com/tags/hudson/"},{"name":"ubuntu","slug":"ubuntu","permalink":"http://yoursite.com/tags/ubuntu/"},{"name":"tomcat","slug":"tomcat","permalink":"http://yoursite.com/tags/tomcat/"}]},{"title":"404查错","date":"2015-12-23T16:00:00.000Z","path":"2015/12/24/java-404/","text":"请了几天的假。回到公司，刚好手头这个项目是新的，于是部署的时候连续出了2个404。搞得自己都蒙了。下面就今天的事情谈谈404出现的两种粗心情况。 1.log4j这个是在api模块出的问题。 现象： 日志文件没有任何信息。访问的时候提示404. 原因： 1.log4j配置文件在本地被删后不小心上传git。导致无法打印日志。2.配置文件出错是常有的错，app启动的时候抛出异常，启动失败，所以404。关键是无日志。 2.git分支这个是在service模块出的问题。 现象： 同上 原因： 1.部署的时候分支错误（master,develop,v2.01三个分支，应该用v2.01确使用了develop)2.分支不同导致controll所mapping的url不同，所以出现404.3.至于为什么没有日志，我看了下develop分支，上面的确是无log4j文件的。 ————翁英健 本文地址：http://wengyingjian.github.io/2015/12/24/java-404/ -End-","tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"},{"name":"404","slug":"404","permalink":"http://yoursite.com/tags/404/"}]},{"title":"Redis学习（三）－字符串","date":"2015-12-21T16:00:00.000Z","path":"2015/12/22/redis-learn-string/","text":"命令1.set SET key value 将key和value对应。如果key已经存在了，它会被覆盖，而不管它是什么类型。 返回:OK 时间复杂度：O(1) 2.get GET key 返回key的value。如果key不存在，返回特殊值nil。如果key的value不是string，就返回错误，因为GET只处理string类型的values。 返回：Bulk replies：key对应的value，或者nil（key不存在） 时间复杂度：O(1) 3.mset MSET key value [key value ...] 对应给定的keys到他们相应的values上。MSET会用新的value替换已经存在的value，就像普通的SET命令一样。如果你不想覆盖已经存在的values，请参看命令MSETNX。MSET是原子的，所以所有给定的keys是一次性set的。客户端不可能看到这种一部分keys被更新而另外的没有改变的情况。 返回：OK 时间复杂度：O(N)，这里N是要set的key的个数。 4.mget MGET key [key ...] 返回所有指定的key的value。对于每个不对应string或者不存在的key，都返回特殊值nil。正因为此，这个操作从来不会失败。 返回：多返回值: 指定的key对应的values的list 时间复杂度：O(N) 5.setnx SETNX key value 如果key不存在，就设置key对应字符串value。在这种情况下，该命令和SET一样。当key已经存在时，就不做任何操作。SETNX是SET if not exists。 返回：数字，只有以下两种值： 1 如果key被set0 如果key没有被set 时间复杂度：O(1) 设计模式：使用SETNX来实现锁 SETNX lock_key 锁过期时间（当前时间＋锁持续时间＋1） 返回1:说明这key为lock_key的这个对象不存在，那么就可以拿到锁了。返回0:说明key为lock_key的这个对象已经存在了，已经被其他操作锁住；这个时候我们可以选择用循环，等待锁释放，或者是使用非阻塞的方法，先去做其他的事情。 处理死锁：因为我们设置的value是该锁的过期时间，所以如果出现死锁，我们可以根据value的值与当前的unix-time做比较：若时间已经超过了锁的过期时间，则使用DEl key操作将该对象移除，再调用SETNX。这里出现了一个竞争的问题：如果有多个客户端同时想要获取一个过期的锁，就是都想把它给删了，但是万一把后来的SETNX删了怎么办。 客户端c1,c2读取key为lock_key的锁，并与当前的时间做比较。它们在调用SETNX的时候都得到了返回值0，因为此时这个锁被客户端c3所持有，而c3在设置了该锁以后程序就挂掉了（无法解锁了）。c1一看，时间到了，于是就调用DEL lock_key把锁给删了。c1删完了，想这下锁应该归我了，于是调用了SETNX XXX，成功返回1。c2也在同样的时间做了跟c1同样的事情。结果出错了：c2把c1的锁给删了，然后去做自己的事情。。。这个时候就是c1，c2两个人都获取到了锁。 天降c4,让它来解决这个问题c4发送SETNX lock_key请求，想要获取到锁。但是此时挂掉的c3持有着锁啊，所以c4的到返回值是0。于是聪明的c4调用GET lock_key来查看这个锁是否过期了：如果没有，那就sleep一下再看。如果这个锁过期了呢？c4会执行以下这个命令:GETSET lock_key 锁过期时间（当前时间＋锁持续时间＋1）回顾一下getset的工作内容：set kv并且返回对应的value如果有另外一个客户端，比如说c5，它在c4之前调用了GETSET命令获取到了锁。那么c4在调用GETSET的时候会发现返回的时间是未过期的。这个时候虽然c4把锁的过期时间往后推了一些，但也不是啥问题。重要提示：为了使的锁的算法鲁棒性更强，持有锁的客户端在调用DEL来释放锁之前都要先检查该锁是否过期了。就拿上面挂掉的客户端c3来说，万一他不是真的挂了呢，只是中间遇到点问题，所以执行的速度慢了，超过了锁的过期时间。等到他执行完程序，准备来释放锁的时候，锁早就被后来的程序以过期的名义给删掉了，这个时候c3要是直接用DEL来释放锁，那可就把后来程序的锁给删了。 6.setex SETEX key seconds value 设置key对应字符串value，并且设置key在给定的seconds时间之后超时过期。这个命令等效于执行下面的命令： SET mykey value EXPIRE mykey seconds SETEX是原子的，也可以通过把上面两个命令放到MULTI/EXEC块中执行的方式重现。相比连续执行上面两个命令，它更快，因为当Redis当做缓存使用时，这个操作更加常用。 返回：状态码 时间复杂度：O(1) 5.psetex PSETEX key milliseconds value 同setex，唯一的不同点是psetex使用毫秒为单位，而setex为秒。 6.msetnx MSETNX key value [key value ...] 对应给定的keys到他们相应的values上。只要有一个key已经存在，MSETNX一个操作都不会执行。 由于这种特性，MSETNX可以实现要么所有的操作都成功，要么一个都不执行，这样可以用来设置不同的key，来表示一个唯一的对象的不同字段。MSETNX是原子的，所以所有给定的keys是一次性set的。客户端不可能看到这种一部分keys被更新而另外的没有改变的情况。 返回：数字，只有以下两种值： 1 如果所有的key被set0 如果没有key被set(至少其中有一个key是存在的) 时间复杂度：O(N)，这里N是要set的key的个数。 7.setrange SETRANGE key offset value 这个命令的作用是覆盖key对应的string的一部分，从指定的offset处开始，覆盖value的长度。如果offset比当前key对应string还要长，那这个string后面就补0以达到offset。不存在的keys被认为是空字符串，所以这个命令可以确保key有一个足够大的字符串，能在offset处设置value。注意，offset最大可以是229-1(536870911),因为redis字符串限制在512M大小。如果你需要超过这个大小，你可以用多个keys。警告：当set最后一个字节并且key还没有一个字符串value或者其value是个比较小的字符串时，Redis需要立即分配所有内存，这有可能会导致服务阻塞一会。在一台2010MacBook Pro上，set536870911字节（分配512MB）需要～300ms，set134217728字节(分配128MB)需要～80ms，set33554432比特位（分配32MB）需要～30ms，set8388608比特（分配8MB）需要8ms。注意，一旦第一次内存分配完，后面对同一个key调用SETRANGE就不会预先得到内存分配。 模式正因为有了SETRANGE和类似功能的GETRANGE命令，你可以把Redis的字符串当成线性数组，随机访问只要O(1)复杂度。这在很多真实场景应用里非常快和高效。 返回：数字：该命令修改后的字符串长度 时间复杂度：O(1)，不考虑拷贝新字符串的开销。通常这个字符串非常小，所以均摊代价为O(1)。如果考虑的话，复杂度就是O(M)，M是参数value的长度。 8.getset GETSET key value 自动将key对应到value并且返回原来key对应的value。如果key存在但是对应的value不是字符串，就返回错误。 设计模式：GETSET可以和INCR一起使用实现支持重置的计数功能。举个例子：每当有事件发生的时候，一段程序都会调用INCR给key mycounter加1，但是有时我们需要获取计数器的值，并且自动将其重置为0。这可以通过GETSET mycounter “0”来实现 时间复杂度：O(1) 9.decr DECR key 对key对应的数字做减1操作。如果key不存在，那么在操作之前，这个key对应的值会被置为0。如果key有一个错误类型的value或者是一个不能表示成数字的字符串，就返回错误。这个操作最大支持在64位有符号的整型数字。 返回：Integer：减小之后的value 时间复杂度：O(1) 10.decrby DECRBY key decrement 将key对应的数字减decrement。如果key不存在，操作之前，key就会被置为0。如果key的value类型错误或者是个不能表示成数字的字符串，就返回错误。这个操作最多支持64位有符号的正型数字。 返回：Integer：减小之后的value 时间复杂度：O(1) 11.incr INCR key 对key对应的数字做加1操作。如果key不存在，那么在操作之前，这个key对应的值会被置为0。如果key有一个错误类型的value或者是一个不能表示成数字的字符串，就返回错误。这个操作最大支持在64位有符号的整型数字。提醒：这是一个string操作，因为Redis没有专用的数字类型。key对应的string都被解释成10进制64位有符号的整型来执行这个操作。Redis会用相应的整数表示方法存储整数，所以对于表示数字的字符串，没必要为了用字符串表示整型存储做额外开销。 返回：Integer：增加之后的value 时间复杂度：O(1) 12.incrby INCRBY key increment 将key对应的数字加decrement。如果key不存在，操作之前，key就会被置为0。如果key的value类型错误或者是个不能表示成数字的字符串，就返回错误。这个操作最多支持64位有符号的正型数字。 返回：Integer：增加之后的value 时间复杂度：O(1) 13.incrbyfloat INCRBYFLOAT key increment 将key对应的数字加increment。如果key不存在，操作之前，key就会被置为0。如果key的value类型错误或者是个不能表示成数字的字符串，就返回错误。如果value为int，添加float后也会出现小数点。小数点以后最后的0会被省略。这个操作最多支持64位有符号的正型数字。 返回：Bulk reply：增加之后的value 时间复杂度：O(1) 14.getrange GETRANGE key start end 警告：这个命令是被改成GETRANGE的，在小于2.0的Redis版本中叫SUBSTR。 返回key对应的字符串value的子串，这个子串是由start和end位移决定的（两者都在string内）。可以用负的位移来表示从string尾部开始数的下标。所以-1就是最后一个字符，-2就是倒数第二个，以此类推。这个函数处理超出范围的请求时，都把结果限制在string内。 返回：Bulk replies 时间复杂度：O(1)，这里的N是返回的string的长度。复杂度是由返回的字符串长度决定的，但是因为从一个已经存在的字符串创建一个子串是很容易的，所以对于较小的字符串，可以认为是O(1)的复杂度。 15.strlen STRLEN key 返回key的string类型value的长度。如果key对应的非string类型，就返回错误。 返回：整型数字：key对应的字符串value的长度，或者0（key不存在） 16.append APPEND key value 如果 key 已经存在，并且值为字符串，那么这个命令会把 value 追加到原来值（value）的结尾。如果 key 不存在，那么它将首先创建一个空字符串的key，再执行追加操作，这种情况 APPEND 将类似于 SET 操作。 返回：Integer：append后字符串值（value）的长度。 时间复杂度：O(1) 17.bitcount BITCOUNT key [start end] 计算 key 对应值的位数如果存在start end，则计算指定范围位数不存在，则默认计算整个valule的位数start,end:-1表示倒数第一个，-2表示倒数第二个，以此类推如果key不存在，则当空字符串处理，返回0 返回：Integer：append后字符串值（value）的长度。 时间复杂度：O(N) ————翁英健 本文地址：http://wengyingjian.github.io/2015/12/22/redis-learn-string/ -End-","tags":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"},{"name":"缓存","slug":"缓存","permalink":"http://yoursite.com/tags/缓存/"},{"name":"redis","slug":"redis","permalink":"http://yoursite.com/tags/redis/"}]},{"title":"Redis学习（二）－常用命令","date":"2015-12-19T16:00:00.000Z","path":"2015/12/20/redis-learn-commands/","text":"前言假设现在你已经安装好了redis（服务器），下面我们来玩玩它。 把redis想象成mysql： 我们之前安装的是redis服务器，就好比是mysql服务器。现在要与服务器交互，就需要一个客户端。mysql可以用mysql -uuser -ppassword进入，那么redis可以用redis-cli进入。进入了以后跳出跟mysql相似的界面。我们就跟操作mysql一样来操作redis。mysql有增删改查，redis也有。只不过是mysql支持的是表结构；redis支持的是string,list,set,sortedset,hash数据结构。所以语法会不一样一些。 使用命令redis来启动redis客户端： 我们可以给$REDIS_HOME/src/redis-cli取个别名叫做redis。或者是将$REDIS_HOME/src/添加到环境变量PATH中，只不过命令变成了redis-cli。 编辑~/.bash_profile（我的redis安装目录为/usr/local/redis-3.0.5/，）插入以下： #redis enviroment REDIS_HOME=/usr/local/redis-3.0.5 PATH=${PATH}:$REDIS_HOME/src/ alias redis=&apos;redis-cli&apos; export REDIS_HOME export PATH source ~/.bash_profile命令激活。 常用命令stringset key value //设置key对应的值为string类型的value mset key1 value1 … keyN valueN //一次设置多个key值 mget key1 key2 … keyN //一次获取多个key incr key //对key的值做加加操作，并返回新的值 decr key //同上，减操作 incrby key integer //同incr，加指定值 decrby key integer //同dear，减制定值 append key value //给制定key的字符串追加value substr key start end //返回截取过的key的字符串值 list双向链表lpush key string //在key对应list的头部添加字符串元素 rpop key //从list的尾部删除元素，并返回删除元素 llen key //返回 key对应list的长度，key不存在返回0，如果key对应类型不是list返回错误 lrange key start end //返回制定区间内的元素，下标从0开始 rpush key string //同上，在尾部添加 lpop key //从list的头部删除元素，并返回删除元素 ltrim key start end //截取list，保留制定区间内元素。 setsadd key member //添加一个string元素到key对应的set集合中，成功返回1；如果元素已经在集合中，返回0；key对应的set不存在返回错误 srem key member [member] //从key对应set中移除给定元素，成功返回1. smove p1 p2 member //从p1对应set中移除member并添加到p2对应set中 scard key //返回set的元素个数 sismember key member //判断member是否在set中 sinter key1 key2…keyN //返回所有给定的key的交集 sunion key1 key2…keyN //返回所有给定的key的并集 sdiff key1 key2…keyN //返回所有给定的key的差集 smembers key // 返回key对应set的所有元素，结果是无序的 sorted setzadd key score member //添加元素到集合，元素在集合中存在则更新对应score zrem key member //删除置顶元素：1.表示成果；0.表示元素不存在 zincrby key incr menber //按照incr幅度增加对应member的score值，返回score值 zrank key member //返回制定元素在集合中的排名（下标），集合中跟元素是按score从小到大排序的。 zrevrank key member //同上，但是集合中元素是按照score从大到小排序的。 zrange key start end //类似lrange操作从集合中去指定区间的元素。返回的是有序结果 zrevrank key start end //同上，返回结果是按score逆序的 zcard key //返回集合中元素个数 zscore key element // 返回给定元素对应的score zremrangebyrank key min max //删除集合中排名在给定区间的元素 ————翁英健 本文地址：http://wengyingjian.github.io/2015/12/20/redis-learn-commands/ -End-","tags":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"},{"name":"缓存","slug":"缓存","permalink":"http://yoursite.com/tags/缓存/"},{"name":"redis","slug":"redis","permalink":"http://yoursite.com/tags/redis/"}]},{"title":"利用java小工具实现半自动化部署v2.0","date":"2015-12-17T16:00:00.000Z","path":"2015/12/18/java-deploy2/","text":"回顾接着http://wengyingjian.github.io/2015/12/17/java-deploy的讲。 已有的功能小工具所能完成的功能就是自动化的部署，帮我们做了2件事： 1.sftp传文件。 2.自动ssh上去，输出服务器日志到控制台。 需要的操作 1.将工具包（这里时deploy.jar）放到一个固定的目录（这里是~/deploy/）。 2.修改~/.bash_profile文件，加入 #alias for deploy alias deploy=&apos;java -jar ~/deploy/deploy.jar&apos; 这样长串的命令只要deploy就行了。 3.在命令行中输入 deploy qa 其它 一、问题: 1.有bug，我今天真正用工具类的时候才发现： 由于properties文件的加载方式为: Thread.currentThread().getContextClassLoader().getResourceAsStream(&quot;&quot;); 所以它加载的是&quot;~/deploy/&quot;路径下的qa-deploy.properties（因为deploy.jar就放在这）。 cp,mv的时候会有确认的提示，这个比较简单，只要修改一下命令即可。 2.工具的功能有点少： 开发这个工具的目的，不能忘了。 是为了省去ssh以及sftp的命令，以及输入密码啥的重复的操作。 所以可以考虑将能够用到ssh，sftp功能的都自动化一下。 3.部署的时候却少备份，而且代码结构也比较乱。 比如说我部署了以后发现新的版本不行，需要换回原来的版本。 所以说在覆盖之前最好备份。 二、新版本 1.为了解决上述的问题，今天也比较空，所以我把上面的版本做了升级。 2.但是之前的版本比较简单，功能也都有了。所以我在git上给上一个版本打了一个tag，叫1.0-version。 3.在https://github.com/wengyingjian/java-deploy-util.git上我还把打好的jar包放进去了，deploy.jar是v1.0的；deploy-2.0-version.jar就是最新版本的。 4.获取到1.0-version. 下载代码: git clone https://github.com/wengyingjian/java-deploy-util.git 进入目录： cd java-deploy-util 查看标签： git tag 回到tag历史： git checkout 1.0-version 新版本一、功能1.deploy 传输：sftp传输本机上的指定文件到服务器的 . 目录下 备份：（服务器上）将旧的app.war从webapp下cp到 . 目录下，并且命令为 old-app.war。 部署：（服务器上）将新的app.war从 . 目录下cp到webapps下。 重命名：（服务器上）将 . 目录下的新的app.war重命名为new-app.war 2.shell 直接开放shell功能，只不过不用输入各种复杂的命令来开启shell功能。 3.manual 这个是针对备份用的。在deploy中应该也看到了，最终在 . 目录会有2个文件 old-app.war 以及 new-app.war。想要哪个就把哪个放到webapps下。 4.log 有些时候只想看下日志，又不想敲那么多命令。就用它了。 二、用法1.deploy 这个发布一下，只需要知道配置文件即可了。 2.shell 也只需要配置文件即可 3.manual 除了配置文件，还得知道是要将 new 还是 old 放上去 4.log 也只需要配置文件即可 综上。 1.需要配置文件。2.需要选择模式（不然我怎么知道是deploy,shell,manual还是log）。3.manual还需要 new / old。 所以，在~/.bash_profile中加入 alias deploy=&apos;java -jar ~/deploy/deploy.jar&apos; alias deploy-log=&apos;java -jar -Dmode=log ~/deploy/deploy.jar&apos; alias deploy-shell=&apos;java -jar -Dmode=shell ~/deploy/deploy.jar&apos; alias deploy-manual=&apos;java -jar -Dmode=manual ~/deploy/deploy.jar&apos; 至于manual，只要deploy-manual a.properties new即可。 三、另外。还加入了友好的提示。配置文件没指定，提示你输入。 manual没选定放谁，提示你输入。 现在已经基本不会抛出异常了。 最后，我说完了。希望对你们有用。。。github地址https://github.com/wengyingjian/java-deploy-util.git ————翁英健 本文地址：http://wengyingjian.github.io/2015/12/18/java-deploy2 -End-","tags":[{"name":"自动化工具","slug":"自动化工具","permalink":"http://yoursite.com/tags/自动化工具/"},{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"},{"name":"部署","slug":"部署","permalink":"http://yoursite.com/tags/部署/"}]},{"title":"如何在Github上写博客（二）－开写","date":"2015-12-16T16:00:00.000Z","path":"2015/12/17/Jekyll-helloWorld2/","text":"在上一篇http://wengyingjian.github.io/2015/12/16/Jekyll-helloWorld中已经简要介绍了Jekyll的运作原理。 接下来再来谈谈怎么修改。 一、_config.yml1.对着英文的意思改：这里应该解决掉了90%的问题。2.说说下面这一块: douban_username: twitter_username: github_username: wengyingjian facebook_username: 100010800551067 weibo_username: 5206672203 zhihu_username: weng-ying-jian-6 这个结合着footer.html中的一段代码块看（这里就截一段）： {% if site.twitter_username %} {% endif %} 聪明的你应该也猜到了，效果就是下面这个： 实现：判断一下site.twitter_username是否有值，没有就跑到endif处；有则显示中间的一段html代码，至于怎么实现的，代码肯定藏在css，js之间，就不去翻了。 二、navigate 可以看到网页的右上角标签，about、archive、tags各占了席之地。 其实只要知道，右上角对应的tag就是跟目录下的xxx.md就行了（上一篇中好像也提到了）。 里面的内容还是比较易懂的，自己DIY起来比较方便。 三、开始写博客要求有三点： 文件路径：放到_post文件夹下 文件名：必须是yyyy-MM-dd-title-subtitle.md，复杂的我也不会，现在也懒得去搞。“约定优先于配置”，挺好的，就照着这个写。 内容格式： --- layout: post title: title date: 2015-12-16 categories: blog tags: [tag1,tag2] description: desc --- 只要照着上面的格式写，一般就没问题，tag什么的自动就有了。 我喜欢在里面放个template.md要用的时候复制一份出来改改就行了。 －以上，讲完了。有啥问题欢迎留言，发现问题劳烦纠正。 ————翁英健 本文地址：http://wengyingjian.github.io/2015/12/16/Jekyll-helloWorld2 -End-","tags":[{"name":"github","slug":"github","permalink":"http://yoursite.com/tags/github/"},{"name":"jekyll","slug":"jekyll","permalink":"http://yoursite.com/tags/jekyll/"},{"name":"helloWorld","slug":"helloWorld","permalink":"http://yoursite.com/tags/helloWorld/"}]},{"title":"利用java小工具实现半自动化部署","date":"2015-12-16T16:00:00.000Z","path":"2015/12/17/java-deploy/","text":"说明环境 开发者操作系统：mac服务器操作系统：linux项目环境：maven，java 问题 每次写完程序发布到服务器，都需要：1、将war包传过去。2、输出服务器日志。 之前做好了基于maven插件的自动化部署功能，但是由于工程用的是公司nexus私服，（不知道啥原因下载不了相关组件）自定义插件用不了。 需求 在maven插件的基础上新做一个可执行java小程序，用它来替代复杂的远程登录操作。 动手1.新建java项目2.创建folder，命名为lib；顺着maven插件找相关的依赖，到~/.m2/repository/目录下把相关的jar包都拷贝到lib，然后添加到buildPath。3.将核心的程序拷过来，进行改造。 改造原先是maven插件，一些需要的配置从pom.xml中读。现在是可执行java文件（jar包），一些配置从命令行中读取。但是需要的配置太多，服务器ip、密码、文件路径、tomcat位置、日志文件等信息。“约定优先于配置”，所以统一将这些配置写到classpath:deploy.properties中。 由于一个项目可能对应多个服务器（qa、stage），所以classpath下应该有多个.properties配置文件，选哪个，到时候从命令行输入，这个还是比较简单的。比如说我要部署到qa上，就执行 java -jar deploy.jar qa 但是感觉前面要输入的东西有点多，既然是类linux操作系统，那么就用alias，将java -jar deploy.jar浓缩一下。编辑~/.bash_profile，加入： alias deploy= &apos;java -jar ~/deploy/deploy.jar&apos; 这个可执行的jar包当然是放在~/deploy/目录下。最后在每个项目部署的时候，只要配置一下qa-deploy.properties（一次配置，永久可用），运行一下deploy qa即可。 github地址https://github.com/wengyingjian/java-deploy-util.git ————翁英健 本文地址：http://wengyingjian.github.io/2015/12/17/java-deploy -End-","tags":[{"name":"自动化工具","slug":"自动化工具","permalink":"http://yoursite.com/tags/自动化工具/"},{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"},{"name":"部署","slug":"部署","permalink":"http://yoursite.com/tags/部署/"}]},{"title":"开篇","date":"2015-12-15T16:00:00.000Z","path":"2015/12/16/essay-helloWorld/","text":"Hello World我要说的第一句话，当然就是 1Hello World! //新的环境终于搭建好了，好兴奋 我从哪里来 我是一枚小程序猿。 之前在csdn上写过一段时间的博客。 后来又在cnblogs上写了一段时间的随笔，这个随笔就是想到啥写啥的那种。 前几天看博客的时候偶然发现偶然 xxx.github.io 的域名。 突然眼前一亮，这个域名好刺眼，这不就是为要的逼格吗。 然后我就屁颠屁颠的跑过来了。 我要到哪去直接的回答 我当然是来写博客的啊，share ideas ！ 怎么写 之前csdn上写的比较多，都是纯技术。 所以有些时候经常就是自己写的嗨了，搞得读者看起来一头雾水。（我改） 后来在cnblogs上系的比较上，记的是一天的流水账，当然啥都有。 所以很难才能找到几篇有价值的。（再改） csdn的博客：我会提供之前的链接。 cnblogs的博客：这边的量比较少，所以我准备整理整理移植到这边。真好两边都是markdown的，也方便。 这里的博客 我会尽量改掉以前的毛病： 1.自己写的嗨，全然不顾读者（自己回过头看的时候也算是读者）。 2.记些毫无意义的流水账。 尽量做到条理清晰，观点清晰，技术点清晰。 我的讲话到此结束，谢谢各位！ ————翁英健 本文地址：http://wengyingjian.github.io/essay-helloWorld -End-","tags":[{"name":"随笔","slug":"随笔","permalink":"http://yoursite.com/tags/随笔/"}]},{"title":"如何在Github上写博客（一）－读懂","date":"2015-12-15T16:00:00.000Z","path":"2015/12/16/Jekyll-helloWorld/","text":"前言 之前为了高逼格（就是在github上写博客），可费了一番周折。 网上的教程一半是从自己创建项目开始的，但是我觉得这个方法门槛太高，因为我到现在也没有把Jekyll等必要的环境安装好（就算装好了后面也不一定容易呢）。那windows用户就更难玩了。 还有另外的一半是fork一下成品的github repository，然后没有然后了。 我就是fork了以后，能够访问到url，但是自己要写博客呢，怎么办？ 所以，我把这几天熟悉到的一些东西分享一下，希望能够帮助到想要在github上写博客的朋友，尽可能少走点弯路嘛。 如果哪里说错了，还有劳在评论中提出。 HelloWorld步骤 1.fork一个现成的仓库&lt;–点它，点它！ 2.点击”Settings”，修改 Repository name。比如我的github用户名为wengyingjain，就把仓库名改为wengyingjian.github.io.把它改成你自己的名字。 3.保存以后即可访问：wengyingjian.github.io 你也可以看这里:https://pages.github.com/，选择”User or organization site”，然后跟着提示来。 2015-12-29补充在文件的根目录有个叫做“CNAME”的文件。里面放的是域名，不需要http://。这个里面的值一定要改成与自己的域名相匹配，一般是yourname.github.io，否则会报404。 另外，如果你希望github page能够绑定到自己的域名的时候，需要将CNAME里面的值改为自己的域名。关于绑定域名参见： http://wengyingjian.github.io/2015/12/29/Jekyll-bind-site 小结 这里主要讲到了两点： 1.repository name要设置对，xxx.github.io 2.访问xxx.github.io的时候进的是 index.html . 看懂文件目录是干啥的这里先贴一个关于文件目录说明的地址：http://beiyuu.com/github-pages，往下拉到“Jekyll模版系统”。 万一你懒得点开呢？所以我在这里结合网上的，自己再“添油加醋”的说几句。 1.文件目录： > |-- _config.yml |-- _includes |-- _layouts | |-- default.html | `-- post.html |-- _posts | |-- 2007-10-29-why-every-programmer-should-play-nethack.textile | `-- 2009-04-26-barcamp-boston-4-roundup.textile |-- _site `-- index.html > > 不是这样的，也应该基本是这样的。 2.各个文件的简要说明 _config.yml 配置文件你懂的，就是存放一些不用看代码改着方便的东西，设置好之后就不用关心了。 _includes 可以用来存放一些小的可复用的模块，方便通过{-% include file %-}进行引用(请无视”-“)。这条命令会调用_includes/file文件。 _layouts 这是模板文件存放的位置。其实就是定义：首页长啥样的；一级页面长啥样的；二级页面长啥样的。 _posts 博客放在这个目录，自动就能够访问的到。不过他的命名有严格的规定，必须是yyyy-MM-dd-title-subtitle.MARKUP格式，比如2015-12-16-Jekyll-helloWorld.md(这里用md也行)。 _site 这个是Jekyll生成的最终的文档，不用去关心。最好把他放在你的.gitignore文件中忽略它。 其他文件夹 你可以创建任何的文件夹，在根目录下面也可以创建任何文件，假设你创建了project文件夹，下面有一个github-pages.md的文件，那么你就可以通过yoursite.com/project/github-pages访问的到，如果你是使用一级域名的话。文件后缀可以是.html或者markdown或者textile。这里还有很多的例子：https://github.com/jekyll/jekyll/wiki/Sites 稍微看下源文件最重要的是方法! 我捣鼓了几天，发现了解它最好的方法就是一边看源文件，一边进入页面，右键“源代码”。 下面跟着我来看下 1.入口是index.html，所以我们就从index.html开始 > --- layout: page //这里找的是/_layouts/page.html,用的是page的模版。 description: \"From 2014-11-23 To Now\" // 查看页面源代码可知这个就是head中的一个说明 --- > > {% for post in paginator.posts %} //这里是个for循环，遍历_posts中的所有文件，显示出来呗 {{ post.title }} {% if post.subtitle %} //title,subtitle上面提过了。 {{ post.subtitle }} {% endif %} {{ post.content | strip_html | truncate:150 }} Posted by {% if post.author %}{{ post.author }}{% else %}{{ site.title }}{% endif %} on {{ post.date | date: \"%B %-d, %Y\" }} > {% endfor %} > {% if paginator.total_pages > 1 %} //这里根据页数判断是否显示“上一页”，“下一页” {% if paginator.previous_page %} &larr; Newer Posts {% endif %} {% if paginator.next_page %} Older Posts &rarr; {% endif %} {% endif %} index.html基本就是这么个样子的，但是在实际的页面中，html代码比这个要丰富的多。 所以下面需要请出/_layouts/page.html,上面提到了index.html用到了这个模版，还记得吧！ 2./_layouts/page.html 这里我就贴一下前三行，后面的都是一些html的head，css，js等东西，你们都懂得。 > --- layout: default --- > > > page又用到了/layouts/default.html，这个层层继承啊，那我们再去看看default把。 顺带一句：post也是用到了/layouts/default.html,同样的道理。 3./layouts/default.html > > {% include head.html %} //这里用到了之前之前说的，把/_include/head.html拿过来了。 //head.html一看名字就知道，写的是一些html中head通用的：link,meta等 > > {% include nav.html %} //然后是把/_include/nav.html拿过来了，navigate导航呗， //瞅瞅右上角的HOME,TAG等东西，就是它们！ > {{ content }} // 中间放内容 > {% include footer.html %} //下面再放一些装饰，这里是facebook,weibo等联系方式。 > > > >4.／includes/footer.html 这里面有很多代码，就截一个主要的看下 > {% if site.twitter_username %} //中间所有的内容是否出现取决于这个if是否同意。 {% endif %} > > 这里用到了2个引用的变量：site.twitter_username、site.twitter_username。 这些东西都是从哪拿的呢？_config.yml! 5._config.yml 我不说了，都看得懂 6.／includes/nav.html 打开文件一看，也没看出啥啊。 但是我们要相信真理，相信右上角的导航是由这个文件生出来的。 仔细看，发现里面也有一个for循环 > {% for page in site.pages %}{% if page.title %} {{ page.title }} {% endif %}{% endfor %} > >没错了就是它，我们在右上角看到的是：HOME\\ABOUT\\ARCHIVE\\TAGS，正好在跟目录也有对应的几个.md文件。 所以说，site.pages指的应该就是跟目录下的.md文件。 想起了各种内置：jsp内置对象、maven内置变量。。。 总结我所看到的、会的，基本都说了。希望读者看下来，能够对Jekyll模版有个大概的认知。 现在我们已经读懂了它，下一步就可以去修改它了，让它变成自己的博客。 对了，干货献上： http://jekyllthemes.org/ 各种主题随便挑，不过能不能用，还得看造化。 ————翁英健 本文地址：http://wengyingjian.github.io/2015/12/16/Jekyll-helloWorld -End-","tags":[{"name":"github","slug":"github","permalink":"http://yoursite.com/tags/github/"},{"name":"jekyll","slug":"jekyll","permalink":"http://yoursite.com/tags/jekyll/"},{"name":"helloWorld","slug":"helloWorld","permalink":"http://yoursite.com/tags/helloWorld/"}]},{"title":"Redis学习（一）－安装与配置","date":"2015-12-09T16:00:00.000Z","path":"2015/12/10/redis-learn-install/","text":"下载可以自己去http://download.redis.io/上下载。 也可以直接用我这个链接http://download.redis.io/releases/redis-3.0.5.tar.gz,现在是能用的，以后会不会迁移说不定。 命令： wget http://download.redis.io/releases/redis-3.0.5.tar.gz 安装命令： mv redis-3.0.5.tar.gz /usr/local/ tar -zxvf redis-3.0.5.tar.gz cd redis-3.0.5 make 文件目录1../src： redis-benchmark//用于压力测试 redis-cli// redis客户端 redis-server//redis服务器 2..: redis.conf // 主要配置文件 启动redis命令： src/redis-server 但是这个是前台运行的，ctrl+c就没了，不能干其他的事情。改成后台运行： vi redis.conf no改成yes: 然后再指定配置文件运行 ok完成 ————翁英健 本文地址：http://wengyingjian.github.io/2015/12/10/redis-learn-install/ -End-","tags":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"},{"name":"缓存","slug":"缓存","permalink":"http://yoursite.com/tags/缓存/"},{"name":"redis","slug":"redis","permalink":"http://yoursite.com/tags/redis/"}]},{"title":"商品超卖问题","date":"2015-12-02T16:00:00.000Z","path":"2015/12/03/store59-creditmall-chaomai/","text":"来到公司后一直在弄积分商城。偶尔也会想到这个问题：高并发的情况下，商品会不会超卖呢？？ 说明我刚来的时候，积分商城已经有了自家优惠券的功能，整个商城就2件商品：满5减1 &amp; 满10减2. 我要做的第一个功能就是添加新的功能：第三方优惠券（其实就是跟我饿了么什么的一样啦）。 自家的优惠券是通过模版生成的，给用户一个兑换码；第三方优惠券是从数据库里拿的（第三方给的），同样是给用户一个兑换码。 具体实现的思路就是： 找到这个商品，然后通过这个商品的某个字段来找到对应的兑换码，这里的兑换码会有很多，那么给他一张就行了。 发兑换码肯定是分为2步的：1.从库里面取一张。2.将取出的这一张状态标记为已使用。这里会出现一个问题，并发的情况下，也就是1.2步之间如果打个断点，那么2个人会得到相同的一张兑换码，而且第二次update的时候是对数据库没有影响的。 这里的解决方法就有很多了： 1.sql不怕累的： 来个存储过程； 2.java不怕累的： 根据update返回的结果是1还是0（有没有有效的update），来各种判断各种处理； 3.不怕慢的： 把2个操作放在同一个事务里面，， 其实我最早的想法就是这样的，因为以前做项目没啥效率要求，我也一直觉得这样很好。 但是数据看的读写是分离的，从代码里面就能看到读的slave是不带事务的，至于他们使用的是否为同一个数据库，还得看生产环境上怎么配。 当时我就想把这里读的那个也换成master来，然后加个事务，这样基本就可以了。但是阿勇似乎不满意，表示如果把读加上了事务会非常的慢，所以被否定了。。。 现在想想也是很有道理，这个能否实现还得看事务隔离级别的设置，而隔离级别要是满足了说不定运行起来还真的阻塞的哭了。。 4.最终的实现方案： 我们最后用的是redis，阿勇提出的方案。也就是说并发我不管了，给redis管。 所有的优惠券统一从redis中取，如果redis中没有，那就一次性从数据库中拿出5条来。 使用了这个方法，让我对redis的了解多了不少。后面商品修改的时候，由于redis中的缓存也让我吃了不少苦－－－就是找不到问题所在，最后发现原来问题出在缓存没清。。。 小结第三方优惠券的处理方案：把优惠券放倒缓存中，然后统一从缓存中取。 后来商城的抢购活动有一次第三方提供了10件衬衫，要求我们搞个抢购。 当时给的时间也不多，也没准备改啥代码，就插了10条数据到第三方兑换券的数据库，把衬衫当做第三方优惠券来看，然后最后哪10个人抢到了再从兑换记录里面找。 之前用redis处理了并发的问题，所以对于这个抢购还是比较自信的。。最终也是没有出现问题。 v3.0要求添加抽奖功能也就是后天要上线的新功能，这两天可把我给忙坏了;当时听到要添加抽奖功能的消息时，可把我给高兴坏了，可有好玩的东西写了。 当时脑袋里浮现出来的就是各种贵重物品抽抽抽，产品也说到时候抽iphone啥的。 这个可千万要小心，抽奖这事可别抽1个iphone搞出10个同时中奖来。。。 我的想法时这样的： 第三方券能够通过实实在在存在的券来控制，而其它的东西，没有实际存在的券，该怎么实现并发不出问题呢？ 第一个想法还是用缓存，这次把商品的剩余数量给放到redis中来，把分布式的并发交给redis来处理，每次get and 减一 嘛。 这个功能redis里好像是有，但是我在spring-data的redis封装里面我没找到对应的方法。 于是我就想去找找以前的自家优惠券是怎么写的，怎么控制不超买的，因为这个通过模版生成的东西也是通过商品的剩余数量来控制的，也并没有实际存在的券。 代码看完了，也没发现哪里控制了并发，更没发现哪里用到了缓存。 喜出望外，为啥？因为我发现了阿勇代码的问题，终于可以修复一下他的代码来表现一下自己了。 于是我去网上搜有关 抢购超卖 的处理方案，基本上就是 1.缓存，就是我上面说的 2.消息队列，应该就是序列化吧，别抢，都给我排队去 3.存储过程，我都懒得看。因为我知道我看明白了我也懒得写那么长的sql的 4.update table set a=a-1 where a&gt;=1 and id =x ，行锁 这里我选择了第4中方法，因为阿勇说，不需要用缓存，使用sql就能完成，有行锁。 网上的说法是，请求量很大的时候行锁会使数据库压力非常大。 我也觉得很有道理，不过想想我们积分商城的访问量，就先用这个简单的把，哪天访问量吃不消的，让我改成缓存也好说。 一顿改翻了一下原来的代码，发现并发是肯定会出问题的，为此我还测试了下，打了个断点，的确出问题了。 之前的sql是这样写的: update table set a=a-1 where id =x 然后剩余数量这字段还是unsigned的，所以报了out of range的错，这明显就是要超卖，而数据库缺报错了，不过2个用户都提示兑换成功了。。 sql改了后，还是有问题，为啥，因为有了返回值，但是代码中没用上啊。 之前的剩余数量可以说就是用来标记一下还有多少个，用来平常用用的。 现在我把它提到了方法的第一行，判断返回值是否为0，多了一个处理并发的功能。 小结简单处理并发： update table set a=a-1 where a&gt;=1 and id =x 根据返回结果来看，如果为0，表示卖完了。不为0再继续下面的操作 ————翁英健 本文地址：http://wengyingjian.github.io/2015/12/03/store59-creditmall-chaomai/ -End-","tags":[{"name":"缓存","slug":"缓存","permalink":"http://yoursite.com/tags/缓存/"},{"name":"商品超卖","slug":"商品超卖","permalink":"http://yoursite.com/tags/商品超卖/"},{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/tags/数据库/"}]}]